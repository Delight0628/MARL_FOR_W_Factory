# Wå·¥å‚ç”Ÿäº§è°ƒåº¦å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿ

<div align="center">

**åŸºäºMAPPOç®—æ³•çš„æ™ºèƒ½å·¥å‚ç”Ÿäº§è°ƒåº¦ç³»ç»Ÿ**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow 2.15](https://img.shields.io/badge/TensorFlow-2.10-orange.svg)](https://www.tensorflow.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[English](#) | [ä¸­æ–‡](README_CN.md)

</div>

---

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®æ¦‚è¿°](#-é¡¹ç›®æ¦‚è¿°)
- [æ ¸å¿ƒæŠ€æœ¯](#-æ ¸å¿ƒæŠ€æœ¯)
- [ç³»ç»Ÿæ¶æ„](#-ç³»ç»Ÿæ¶æ„)
- [ç¯å¢ƒè®¾è®¡](#-ç¯å¢ƒè®¾è®¡)
- [MAPPOç®—æ³•å®ç°](#-mappoç®—æ³•å®ç°)
- [è®­ç»ƒæµç¨‹](#-è®­ç»ƒæµç¨‹)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [æ€§èƒ½è¯„ä¼°](#-æ€§èƒ½è¯„ä¼°)
- [æŠ€æœ¯äº®ç‚¹](#-æŠ€æœ¯äº®ç‚¹)
- [é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„)

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

### é¡¹ç›®èƒŒæ™¯

æœ¬é¡¹ç›®æ—¨åœ¨è§£å†³**å¤šå“ç§ã€å°æ‰¹é‡**ç”Ÿäº§æ¨¡å¼ä¸‹çš„æ™ºèƒ½å·¥å‚è°ƒåº¦é—®é¢˜ã€‚Wå·¥å‚ä½œä¸ºå…¸å‹çš„ç°ä»£å®¶å…·åˆ¶é€ ä¼ä¸šï¼Œé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š

- ğŸ­ **5ç§å·¥ä½œç«™**ï¼šå¸¦é”¯æœºã€äº”è½´åŠ å·¥ä¸­å¿ƒã€ç ‚å…‰æœºã€ç»„è£…å°ã€åŒ…è£…å°
- ğŸ“¦ **4ç§äº§å“**ï¼šé»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œã€æ©¡æœ¨ä¹¦æŸœã€æ¾æœ¨åºŠæ¶ã€æ¨±æ¡ƒæœ¨æ¤…å­
- ğŸ”„ **å¤æ‚å·¥è‰ºè·¯çº¿**ï¼šæ¯ç§äº§å“3-5é“å·¥åºï¼Œå…±äº«è®¾å¤‡èµ„æº
- â° **ä¸¥æ ¼äº¤æœŸè¦æ±‚**ï¼šå¤šè®¢å•å¹¶è¡Œï¼Œéœ€æƒè¡¡å®Œå·¥æ—¶é—´ä¸å»¶æœŸæƒ©ç½š
- âš¡ **åŠ¨æ€æ‰°åŠ¨**ï¼šè®¾å¤‡æ•…éšœã€ç´§æ€¥æ’å•ç­‰çªå‘äº‹ä»¶

### æ ¸å¿ƒç›®æ ‡

é€šè¿‡**å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰**è®­ç»ƒä¸€ç»„ååŒå·¥ä½œçš„æ™ºèƒ½ä½“ï¼Œå®ç°ï¼š

1. **æœ€å°åŒ–æ€»å®Œå·¥æ—¶é—´ (Makespan)**
2. **æœ€å¤§åŒ–è®¾å¤‡åˆ©ç”¨ç‡ (Utilization)**  
3. **æœ€å°åŒ–è®¢å•å»¶æœŸ (Tardiness)**
4. **æå‡åŠ¨æ€äº‹ä»¶é²æ£’æ€§**

---

## ğŸ”¬ æ ¸å¿ƒæŠ€æœ¯

### æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|------|
| æ·±åº¦å­¦ä¹ æ¡†æ¶ | TensorFlow | 2.15.0 | ç¥ç»ç½‘ç»œæ„å»ºä¸è®­ç»ƒ |
| å¼ºåŒ–å­¦ä¹ ç®—æ³• | MAPPO | Custom | å¤šæ™ºèƒ½ä½“ç­–ç•¥ä¼˜åŒ– |
| ç¯å¢ƒæ¥å£ | PettingZoo | 1.24+ | å¤šæ™ºèƒ½ä½“ç¯å¢ƒæ ‡å‡† |
| ç¦»æ•£äº‹ä»¶ä»¿çœŸ | SimPy | 4.0+ | å·¥å‚ç‰©ç†è¿‡ç¨‹æ¨¡æ‹Ÿ |
| å¹¶è¡Œè®¡ç®— | ProcessPoolExecutor | Python 3.8+ | å¤šè¿›ç¨‹æ•°æ®é‡‡é›† |
| å¯è§†åŒ–åº”ç”¨ | Streamlit | 1.30+ | äº¤äº’å¼è°ƒåº¦æ¼”ç¤º |

### ç®—æ³•ç‰¹æ€§

- âœ… **é›†ä¸­å¼Critic + åˆ†å¸ƒå¼Actor (CTDE)**ï¼šåˆ©ç”¨å…¨å±€ä¿¡æ¯è®­ç»ƒï¼Œåˆ†å¸ƒå¼æ‰§è¡Œ
- âœ… **ä¸¤é˜¶æ®µæ¸è¿›å¼è®­ç»ƒ**ï¼šåŸºç¡€æ³›åŒ– â†’ åŠ¨æ€é²æ£’æ€§
- âœ… **è¯¾ç¨‹å­¦ä¹ æ”¯æŒ**ï¼šä»ç®€å•ä»»åŠ¡é€æ­¥æå‡éš¾åº¦
- âœ… **è‡ªé€‚åº”ç†µè°ƒæ•´**ï¼šåŠ¨æ€å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨
- âœ… **å¤šä»»åŠ¡æ··åˆè®­ç»ƒ**ï¼šé˜²æ­¢ç¾éš¾æ€§é—å¿˜
- âœ… **GAEä¼˜åŠ¿å‡½æ•°ä¼°è®¡**ï¼šæå‡æ ·æœ¬æ•ˆç‡

---

## ğŸ§© MAPPOæ¨¡å—åŒ–æ¶æ„

### è®¾è®¡ç†å¿µ

ä¸ºæå‡ä»£ç å¯ç»´æŠ¤æ€§å’Œå¤ç”¨æ€§ï¼Œè®­ç»ƒç®—æ³•é‡‡ç”¨**åˆ†å±‚æ¨¡å—åŒ–è®¾è®¡**ï¼Œå°†åŸå…ˆçš„å•ä½“è„šæœ¬æ‹†åˆ†ä¸º5ä¸ªèŒè´£æ¸…æ™°çš„æ¨¡å—ï¼š

```
æ¨¡å—ç»„ç»‡ï¼ˆè‡ªåº•å‘ä¸Šï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ppo_marl_train.py                  â”‚  â† è®­ç»ƒå…¥å£ï¼ˆ154è¡Œï¼‰
â”‚  èŒè´£ï¼šå‚æ•°è§£æã€æµç¨‹å¯åŠ¨            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ è°ƒç”¨
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ppo_trainer.py                     â”‚  â† è®­ç»ƒå™¨ä¸»ç±»ï¼ˆ1818è¡Œï¼‰
â”‚  èŒè´£ï¼š                              â”‚
â”‚  â€¢ ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ç®¡ç†                â”‚
â”‚  â€¢ è¯¾ç¨‹å­¦ä¹ ä¸è‡ªé€‚åº”ç†µ                â”‚
â”‚  â€¢ æ¨¡å‹ä¿å­˜ä¸è¯„ä¼°                    â”‚
â”‚  â€¢ TensorBoardç›‘æ§                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“ ä¾èµ–         â†“ ä¾èµ–        â†“ ä¾èµ–
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ppo_      â”‚  â”‚ppo_      â”‚  â”‚ppo_      â”‚
â”‚network.pyâ”‚  â”‚buffer.py â”‚  â”‚worker.py â”‚
â”‚          â”‚  â”‚          â”‚  â”‚          â”‚
â”‚Actor-    â”‚  â”‚GAEä¼˜åŠ¿   â”‚  â”‚å¹¶è¡Œç»éªŒ  â”‚
â”‚Critic    â”‚  â”‚å‡½æ•°è®¡ç®—  â”‚  â”‚é‡‡é›†      â”‚
â”‚ç½‘ç»œæ¶æ„  â”‚  â”‚          â”‚  â”‚          â”‚
â”‚(457è¡Œ)   â”‚  â”‚(128è¡Œ)   â”‚  â”‚(304è¡Œ)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ¨¡å—èŒè´£è¯´æ˜

| æ¨¡å— | ä»£ç é‡ | æ ¸å¿ƒèŒè´£ | å…³é”®ç±»/å‡½æ•° |
|------|--------|----------|------------|
| **ppo_marl_train.py** | 154è¡Œ | è®­ç»ƒå…¥å£ | `main()` - å‚æ•°è§£æã€æµç¨‹å¯åŠ¨ |
| **ppo_trainer.py** | 1818è¡Œ | è®­ç»ƒä¸»æ§ | `SimplePPOTrainer` - å®Œæ•´è®­ç»ƒæµç¨‹ç®¡ç† |
| **ppo_network.py** | 457è¡Œ | ç¥ç»ç½‘ç»œ | `PPONetwork` - Actor-Criticæ¶æ„ |
| **ppo_buffer.py** | 128è¡Œ | ç»éªŒç®¡ç† | `ExperienceBuffer` - GAEè®¡ç®— |
| **ppo_worker.py** | 304è¡Œ | å¹¶è¡Œé‡‡é›† | `run_simulation_worker()` - å¤šè¿›ç¨‹ä»¿çœŸ |

### æ¨¡å—äº¤äº’æµç¨‹

```
è®­ç»ƒå¾ªç¯ä¸­çš„æ•°æ®æµï¼š

1. SimplePPOTrainer åˆå§‹åŒ–
   â”œâ”€ åˆ›å»º PPONetwork (Actor + Critic)
   â””â”€ åˆå§‹åŒ– ProcessPoolExecutor

2. æ¯ä¸ªè®­ç»ƒå›åˆ
   â”œâ”€ æå–ç½‘ç»œæƒé‡
   â”‚   â””â”€ network.actor.get_weights()
   â”‚       network.critic.get_weights()
   â”‚
   â”œâ”€ å¹¶è¡Œé‡‡é›†ç»éªŒï¼ˆ4ä¸ªworkerï¼‰
   â”‚   â””â”€ ppo_worker.run_simulation_worker()
   â”‚       â”œâ”€ åˆ›å»ºç¯å¢ƒå®ä¾‹
   â”‚       â”œâ”€ é‡å»ºç½‘ç»œå¹¶åŠ è½½æƒé‡
   â”‚       â”œâ”€ è¿è¡Œnum_stepsæ­¥ä»¿çœŸ
   â”‚       â””â”€ è¿”å› ExperienceBuffer
   â”‚
   â”œâ”€ èšåˆæ‰€æœ‰workeræ•°æ®
   â”‚   â””â”€ buffer.get_batch() â†’ GAEè®¡ç®—
   â”‚
   â””â”€ ç­–ç•¥æ›´æ–°
       â””â”€ network.update() â†’ PPOæŸå¤±ä¼˜åŒ–
```

### æ¨¡å—åŒ–ä¼˜åŠ¿

âœ… **èŒè´£åˆ†ç¦»**ï¼šæ¯ä¸ªæ¨¡å—ä¸“æ³¨å•ä¸€èŒè´£ï¼Œé™ä½è€¦åˆåº¦  
âœ… **æ˜“äºæµ‹è¯•**ï¼šå¯ç‹¬ç«‹æµ‹è¯•ç½‘ç»œã€ç¼“å†²ã€Workerç­‰ç»„ä»¶  
âœ… **ä»£ç å¤ç”¨**ï¼šç½‘ç»œå’Œç¼“å†²æ¨¡å—å¯ç”¨äºå…¶ä»–MARLé¡¹ç›®  
âœ… **å¹¶è¡Œå¼€å‘**ï¼šå›¢é˜Ÿå¯åŒæ—¶å¼€å‘ä¸åŒæ¨¡å—  
âœ… **è°ƒè¯•å‹å¥½**ï¼šé—®é¢˜å®šä½æ›´ç²¾ç¡®ï¼ˆå¦‚Workerå´©æºƒã€ç½‘ç»œæ¢¯åº¦å¼‚å¸¸ï¼‰

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     è®­ç»ƒç®¡ç†å±‚ (Training Layer)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ auto_train.pyâ”‚  â”‚TensorBoard   â”‚  â”‚Checkpoint    â”‚      â”‚
â”‚  â”‚ è‡ªåŠ¨åŒ–è®­ç»ƒ    â”‚  â”‚å®æ—¶ç›‘æ§       â”‚  â”‚æ¨¡å‹ç®¡ç†       â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            MAPPOç®—æ³•å±‚ (æ¨¡å—åŒ–æ¶æ„ - mappo/)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  ppo_marl_train.py (è®­ç»ƒå…¥å£)                       â”‚     â”‚
â”‚  â”‚    â†“                                                â”‚     â”‚
â”‚  â”‚  ppo_trainer.py (SimplePPOTrainer)                  â”‚     â”‚
â”‚  â”‚    â”œâ”€ ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ç®¡ç†                            â”‚     â”‚
â”‚  â”‚    â”œâ”€ è¯¾ç¨‹å­¦ä¹ ä¸è‡ªé€‚åº”ç†µ                            â”‚     â”‚
â”‚  â”‚    â””â”€ TensorBoardç›‘æ§                               â”‚     â”‚
â”‚  â”‚    â†“ â†“ â†“ (ä¾èµ–ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—)                         â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚     â”‚
â”‚  â”‚  â”‚ppo_      â”‚ppo_      â”‚ppo_      â”‚                â”‚     â”‚
â”‚  â”‚  â”‚network.pyâ”‚buffer.py â”‚worker.py â”‚                â”‚     â”‚
â”‚  â”‚  â”‚Actor-    â”‚GAEä¼˜åŠ¿   â”‚å¹¶è¡Œç»éªŒ  â”‚                â”‚     â”‚
â”‚  â”‚  â”‚Criticç½‘ç»œâ”‚å‡½æ•°è®¡ç®—  â”‚é‡‡é›†      â”‚                â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚           â†“ (state, reward)          â†‘ (action)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PettingZooæ¥å£å±‚ (w_factory_env.py)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  WFactoryEnv (ParallelEnv)                          â”‚     â”‚
â”‚  â”‚  â”œâ”€ è§‚æµ‹ç©ºé—´æ„å»º (132ç»´)                            â”‚     â”‚
â”‚  â”‚  â”œâ”€ åŠ¨ä½œç©ºé—´æ˜ å°„ (MultiDiscrete)                    â”‚     â”‚
â”‚  â”‚  â””â”€ å¥–åŠ±è®¡ç®—ä¸è¿”å›                                  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚           â†“ (control signals)       â†‘ (sim state)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          SimPyä»¿çœŸå±‚ (WFactorySim Class)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  ç¦»æ•£äº‹ä»¶ä»¿çœŸæ ¸å¿ƒ                                    â”‚     â”‚
â”‚  â”‚  â”œâ”€ èµ„æºç®¡ç† (simpy.Resource)                       â”‚     â”‚
â”‚  â”‚  â”œâ”€ é˜Ÿåˆ—ç³»ç»Ÿ (simpy.Store)                          â”‚     â”‚
â”‚  â”‚  â”œâ”€ é›¶ä»¶æµè½¬ (_part_process)                        â”‚     â”‚
â”‚  â”‚  â”œâ”€ è®¾å¤‡æ•…éšœ (_equipment_failure_process)           â”‚     â”‚
â”‚  â”‚  â””â”€ ç´§æ€¥æ’å• (_emergency_order_process)             â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          é…ç½®å±‚ (w_factory_config.py)                        â”‚
â”‚  å·¥ä½œç«™é…ç½® | äº§å“è·¯çº¿ | è®¢å•æ•°æ® | å¥–åŠ±ç³»ç»Ÿ | è®­ç»ƒå‚æ•°       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MAPPOç½‘ç»œæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Actor Network (åˆ†å¸ƒå¼æ‰§è¡Œ)                 â”‚
â”‚  è¾“å…¥: å±€éƒ¨è§‚æµ‹ (132ç»´)                                       â”‚
â”‚    â†“                                                         â”‚
â”‚  Dense(1024) + ReLU + Dropout(0.1)                          â”‚
â”‚    â†“                                                         â”‚
â”‚  Dense(512) + ReLU + Dropout(0.1)                           â”‚
â”‚    â†“                                                         â”‚
â”‚  Dense(256) + ReLU + Dropout(0.1)                           â”‚
â”‚    â†“                                                         â”‚
â”‚  MultiHead Output (10 heads Ã— 11 actions/head)              â”‚
â”‚  â”œâ”€ Head 1: Softmax(11) â†’ å€™é€‰å·¥ä»¶1çš„æ¦‚ç‡åˆ†å¸ƒ                â”‚
â”‚  â”œâ”€ Head 2: Softmax(11) â†’ å€™é€‰å·¥ä»¶2çš„æ¦‚ç‡åˆ†å¸ƒ                â”‚
â”‚  â””â”€ ...                                                      â”‚
â”‚  è¾“å‡º: åŠ¨ä½œæ¦‚ç‡åˆ†å¸ƒ (æ”¯æŒæ— æ”¾å›é‡‡æ ·)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Critic Network (é›†ä¸­å¼è®­ç»ƒ)                 â”‚
â”‚  è¾“å…¥: å…¨å±€çŠ¶æ€ (global_state + agent_one_hot)               â”‚
â”‚    â†“                                                         â”‚
â”‚  Dense(1024) + ReLU + Dropout(0.1)                          â”‚
â”‚    â†“                                                         â”‚
â”‚  Dense(512) + ReLU + Dropout(0.1)                           â”‚
â”‚    â†“                                                         â”‚
â”‚  Dense(256) + ReLU + Dropout(0.1)                           â”‚
â”‚    â†“                                                         â”‚
â”‚  Dense(1) â†’ çŠ¶æ€ä»·å€¼ä¼°è®¡ V(s)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸŒ ç¯å¢ƒè®¾è®¡

### è§‚æµ‹ç©ºé—´ (132ç»´)

ç¯å¢ƒä¸ºæ¯ä¸ªæ™ºèƒ½ä½“æä¾›ä¸°å¯Œçš„è§‚æµ‹ä¿¡æ¯ï¼Œç»“æ„å¦‚ä¸‹ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [1] Agentè‡ªèº«ç‰¹å¾ (8ç»´)                                     â”‚
â”‚      â”œâ”€ èº«ä»½one-hot (5ç»´): [1,0,0,0,0] è¡¨ç¤ºå¸¦é”¯æœº            â”‚
â”‚      â”œâ”€ è®¾å¤‡å®¹é‡ (1ç»´): å½’ä¸€åŒ–å®¹é‡å€¼                          â”‚
â”‚      â”œâ”€ è®¾å¤‡ç¹å¿™ç‡ (1ç»´): å½“å‰ç¹å¿™ç¨‹åº¦                        â”‚
â”‚      â””â”€ æ•…éšœçŠ¶æ€ (1ç»´): 0=æ­£å¸¸, 1=æ•…éšœ                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [2] å…¨å±€å®è§‚ç‰¹å¾ (4ç»´)                                      â”‚
â”‚      â”œâ”€ æ—¶é—´è¿›åº¦ (1ç»´): current_time / SIMULATION_TIME      â”‚
â”‚      â”œâ”€ WIPç‡ (1ç»´): åœ¨åˆ¶å“æ•°é‡ / æ€»è®¢å•æ•°                   â”‚
â”‚      â”œâ”€ ç“¶é¢ˆæ‹¥å µåº¦ (1ç»´): æœ€é•¿é˜Ÿåˆ—é•¿åº¦å½’ä¸€åŒ–                  â”‚
â”‚      â””â”€ å¹³å‡é˜Ÿåˆ—é•¿åº¦ (1ç»´): æ‰€æœ‰é˜Ÿåˆ—å¹³å‡é•¿åº¦                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [3] å½“å‰é˜Ÿåˆ—æ‘˜è¦ (30ç»´)                                     â”‚
â”‚      6ç§ç‰¹å¾ Ã— 5ç§ç»Ÿè®¡é‡ (min, max, mean, std, median)       â”‚
â”‚      ç‰¹å¾ç±»å‹:                                               â”‚
â”‚      â”œâ”€ å‰©ä½™å·¥åºæ•°                                           â”‚
â”‚      â”œâ”€ å‰©ä½™åŠ å·¥æ—¶é—´                                         â”‚
â”‚      â”œâ”€ å½“å‰å·¥åºæ—¶é—´                                         â”‚
â”‚      â”œâ”€ ä¸‹æ¸¸æ‹¥å µåº¦                                           â”‚
â”‚      â”œâ”€ ä¼˜å…ˆçº§                                               â”‚
â”‚      â””â”€ æ˜¯å¦æœ€ç»ˆå·¥åº                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [4] å€™é€‰å·¥ä»¶è¯¦ç»†ç‰¹å¾ (90ç»´)                                 â”‚
â”‚      10ä¸ªå€™é€‰å·¥ä»¶ Ã— 9ç»´ç‰¹å¾/å·¥ä»¶                             â”‚
â”‚      å·¥ä»¶ç‰¹å¾:                                               â”‚
â”‚      â”œâ”€ exists (1ç»´): å€™é€‰å·¥ä»¶æ˜¯å¦å­˜åœ¨                        â”‚
â”‚      â”œâ”€ å‰©ä½™å·¥åºæ•° (1ç»´): å½’ä¸€åŒ–                             â”‚
â”‚      â”œâ”€ å‰©ä½™åŠ å·¥æ—¶é—´ (1ç»´): å½’ä¸€åŒ–                           â”‚
â”‚      â”œâ”€ å½“å‰å·¥åºæ—¶é—´ (1ç»´): å½’ä¸€åŒ–                           â”‚
â”‚      â”œâ”€ ä¸‹æ¸¸æ‹¥å µåº¦ (1ç»´): ä¸‹ä¸€å·¥ä½é˜Ÿåˆ—é•¿åº¦                    â”‚
â”‚      â”œâ”€ ä¼˜å…ˆçº§ (1ç»´): 1/2/3 â†’ å½’ä¸€åŒ–                         â”‚
â”‚      â”œâ”€ æ˜¯å¦æœ€ç»ˆå·¥åº (1ç»´): 0/1æ ‡å¿—ä½                        â”‚
â”‚      â”œâ”€ äº§å“ç±»å‹one-hot (1ç»´): 4ç§äº§å“ç¼–ç                    â”‚
â”‚      â””â”€ â­æ—¶é—´å‹åŠ›æ„ŸçŸ¥ (1ç»´): (due_date - current_time) / ...â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
æ€»ç»´åº¦: 8 + 4 + 30 + 90 = 132ç»´
```

**å…³é”®è®¾è®¡ç†å¿µ**ï¼š

1. **å¤šæ ·æ€§å€™é€‰é‡‡æ ·**ï¼šæ··åˆEDD(ç´§æ€¥ä¼˜å…ˆ)ã€SPT(çŸ­ä½œä¸šä¼˜å…ˆ)ã€éšæœºé‡‡æ ·ï¼Œæä¾›æ¢ç´¢ç©ºé—´
2. **æ—¶é—´å‹åŠ›æ„ŸçŸ¥**ï¼šåŸºäºç‰©ç†æ—¶é—´å…³ç³»è®¡ç®—ï¼Œéå¯å‘å¼ä½œå¼Š
3. **å‹ç¼©å½’ä¸€åŒ–**ï¼šä½¿ç”¨ `y = x/norm / (1 + x/norm)` é¿å…ç‰¹å¾é¥±å’Œ

### åŠ¨ä½œç©ºé—´ (MultiDiscrete)

æ¯ä¸ªæ™ºèƒ½ä½“çš„åŠ¨ä½œç©ºé—´ä¸º `MultiDiscrete([11, 11, ..., 11])` (10ä¸ªå¤´)ï¼š

```
åŠ¨ä½œç©ºé—´è®¾è®¡:
â”œâ”€ 0: IDLE (ç©ºé—²ç­‰å¾…)
â”œâ”€ 1-10: é€‰æ‹©å€™é€‰å·¥ä»¶1-10è¿›è¡ŒåŠ å·¥
â””â”€ é‡‡ç”¨æ— æ”¾å›é‡‡æ ·æœºåˆ¶ï¼Œé¿å…å¤šå¤´é€‰æ‹©ç›¸åŒå·¥ä»¶
```

**æ— æ”¾å›é‡‡æ ·æœºåˆ¶**ï¼š

```python
# ä¼ªä»£ç ç¤ºä¾‹
for head_i in range(num_heads):
    masked_probs = probs_i * (1 - selected_mask)
    action_i = sample_from(masked_probs)
    selected_mask[action_i] = 1  # æ ‡è®°å·²é€‰
```

### å¥–åŠ±ç³»ç»Ÿ (ç¨ å¯†ã€ç›®æ ‡å¯¼å‘)

å¥–åŠ±å‡½æ•°é‡‡ç”¨ä¸‰å±‚è®¾è®¡ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç¬¬ä¸€å±‚ï¼šä»»åŠ¡å®Œæˆå¥–åŠ± (ä¸»å¯¼ä¿¡å·)                              â”‚
â”‚  â”œâ”€ é›¶ä»¶å®Œæˆå¥–åŠ±: +80                                        â”‚
â”‚  â””â”€ å…¨éƒ¨å®Œæˆå¥–åŠ±: +500 (æ‰€æœ‰é›¶ä»¶å®Œæˆæ—¶)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ç¬¬äºŒå±‚ï¼šæ—¶é—´è´¨é‡å¥–åŠ± (æ¬¡è¦ä¿¡å·)                              â”‚
â”‚  â”œâ”€ æŒ‰æ—¶å®Œæˆå¥–åŠ±: +80 (é›¶ä»¶åœ¨äº¤æœŸå†…å®Œæˆ)                      â”‚
â”‚  â””â”€ å»¶æœŸæƒ©ç½š: -10 Ã— tardiness_minutes                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ç¬¬ä¸‰å±‚ï¼šè¿‡ç¨‹å¡‘å½¢å¥–åŠ± (å¼•å¯¼ä¿¡å·)                              â”‚
â”‚  â”œâ”€ è¿›åº¦å¡‘å½¢: +0.1 Ã— progress_made                           â”‚
â”‚  â”œâ”€ ç´§æ€¥åº¦é™ä½: +0.1 Ã— urgency_reduction                     â”‚
â”‚  â”œâ”€ ä¸å¿…è¦ç©ºé—²æƒ©ç½š: -1.0                                     â”‚
â”‚  â”œâ”€ æ— æ•ˆåŠ¨ä½œæƒ©ç½š: -0.5                                       â”‚
â”‚  â””â”€ è´Ÿæ¾å¼›æ—¶é—´æƒ©ç½š: -0.1 Ã— max(0, -slack_time)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è®¾è®¡ç†å¿µ**ï¼šå¯†é›†å³æ—¶åé¦ˆ + é•¿æœŸç›®æ ‡å¯¼å‘

---

## ğŸ§  MAPPOç®—æ³•å®ç°

### ç®—æ³•æ¡†æ¶

MAPPO (Multi-Agent Proximal Policy Optimization) é‡‡ç”¨ **CTDE (Centralized Training with Decentralized Execution)** èŒƒå¼ï¼š

- **è®­ç»ƒé˜¶æ®µ**ï¼šCriticä½¿ç”¨å…¨å±€çŠ¶æ€ + æ™ºèƒ½ä½“IDæ¡ä»¶åŒ–
- **æ‰§è¡Œé˜¶æ®µ**ï¼šActorä»…ä½¿ç”¨å±€éƒ¨è§‚æµ‹ï¼Œæ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²

### æ ¸å¿ƒç»„ä»¶

#### 1. PPOæŸå¤±å‡½æ•°

```python
# ActoræŸå¤± (Clipped Surrogate Objective)
ratio = exp(log_Ï€_new(a|s) - log_Ï€_old(a|s))
clipped_ratio = clip(ratio, 1-Îµ, 1+Îµ)
L_actor = -min(ratio Ã— A, clipped_ratio Ã— A) - Î² Ã— H(Ï€)

# CriticæŸå¤± (Value Function MSE)
L_critic = (V(s) - V_target)Â²

# å…¶ä¸­:
# A: GAEä¼˜åŠ¿å‡½æ•°
# Î²: ç†µç³»æ•° (è‡ªé€‚åº”è°ƒæ•´)
# Îµ: è£å‰ªæ¯”ç‡ (0.2)
```

#### 2. GAEä¼˜åŠ¿å‡½æ•°ä¼°è®¡

```python
# Generalized Advantage Estimation
Î´_t = r_t + Î³ Ã— V(s_{t+1}) - V(s_t)
A_t = Î´_t + Î³Î» Ã— A_{t+1}

# è¶…å‚æ•°:
# Î³ (gamma) = 0.99 : æŠ˜æ‰£å› å­
# Î» (lambda_gae) = 0.95 : GAEå¹³æ»‘å‚æ•°
```

#### 3. è‡ªé€‚åº”ç†µè°ƒæ•´

```python
# é˜²æ­¢ç­–ç•¥è¿‡æ—©æ”¶æ•›çš„è‡ªé€‚åº”æœºåˆ¶
if performance_stagnant for N episodes:
    entropy_coeff *= (1 + boost_factor)  # æå‡æ¢ç´¢
elif completion_rate > 95%:
    entropy_coeff *= 0.995  # é™ä½æ¢ç´¢ï¼Œç²¾ç»†åŒ–ç­–ç•¥
```

### è®­ç»ƒé…ç½®å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|----|----|
| **ç½‘ç»œç»“æ„** | [1024, 512, 256] | 3å±‚å…¨è¿æ¥ |
| **å­¦ä¹ ç‡è°ƒåº¦** | 8e-5 â†’ 1e-6 | å¤šé¡¹å¼è¡°å‡ |
| **PPO Epochs** | 12 | æ¯æ‰¹æ•°æ®æ›´æ–°12æ¬¡ |
| **Mini-batches** | 4 | æ‰¹æ¬¡å†…åˆ†4ä¸ªå°æ‰¹ |
| **Clip Ratio** | 0.2 | PPOè£å‰ªå‚æ•° |
| **åˆå§‹ç†µç³»æ•°** | 0.5 | æ¢ç´¢å¼ºåº¦ |
| **æ¢¯åº¦è£å‰ª** | 1.0 | é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ |
| **ä¼˜åŠ¿è£å‰ª** | 5.0 | ç¨³å®šè®­ç»ƒ |
| **å¹¶è¡ŒWorkers** | 4 | æ•°æ®é‡‡é›†è¿›ç¨‹æ•° |

---

## ğŸ“ˆ è®­ç»ƒæµç¨‹

### ä¸¤é˜¶æ®µæ¸è¿›å¼è®­ç»ƒç­–ç•¥

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µä¸€ï¼šåŸºç¡€æ³›åŒ–è®­ç»ƒ (Foundation Phase)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ç›®æ ‡ï¼šæŒæ¡éšæœºè®¢å•ç¯å¢ƒä¸‹çš„æ³›åŒ–è°ƒåº¦èƒ½åŠ›                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  å¯é€‰ï¼šè¯¾ç¨‹å­¦ä¹  (Curriculum Learning)             â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”œâ”€ é˜¶æ®µ1: 40%è®¢å• â†’ ç›®æ ‡åˆ†æ•°0.80, é›¶å»¶æœŸ         â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”œâ”€ é˜¶æ®µ2: 80%è®¢å• â†’ ç›®æ ‡åˆ†æ•°0.80, å»¶æœŸ<225min   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€ é˜¶æ®µ3: 100%è®¢å• â†’ ç›®æ ‡åˆ†æ•°0.72, å»¶æœŸ<450min  â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  è®­ç»ƒç­–ç•¥ï¼š                                               â”‚  â”‚
â”‚  â”‚  â”œâ”€ 75% workers: éšæœºè®¢å• (5-8è®¢å•, æ¯å•3-12ä»¶)         â”‚  â”‚
â”‚  â”‚  â””â”€ 25% workers: BASE_ORDERS (ç¨³å®šé”šç‚¹ï¼Œé˜²é—å¿˜)         â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  æ¯•ä¸šæ ‡å‡†ï¼š                                               â”‚  â”‚
â”‚  â”‚  â”œâ”€ ç»¼åˆè¯„åˆ† > 0.70                                     â”‚  â”‚
â”‚  â”‚  â”œâ”€ å®Œæˆç‡ > 95%                                        â”‚  â”‚
â”‚  â”‚  â”œâ”€ å»¶æœŸ < 450min                                       â”‚  â”‚
â”‚  â”‚  â””â”€ è¿ç»­8æ¬¡è¾¾æ ‡                                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µäºŒï¼šåŠ¨æ€äº‹ä»¶é²æ£’æ€§è®­ç»ƒ (Generalization Phase)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ç›®æ ‡ï¼šåœ¨åŠ¨æ€æ‰°åŠ¨ä¸‹ä¿æŒè°ƒåº¦æ€§èƒ½                          â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  è®­ç»ƒç­–ç•¥ï¼š                                               â”‚  â”‚
â”‚  â”‚  â”œâ”€ 75% workers: éšæœºè®¢å• + åŠ¨æ€äº‹ä»¶                     â”‚  â”‚
â”‚  â”‚  â”‚   â”œâ”€ è®¾å¤‡æ•…éšœ (MTBF=24h, MTTR=30min)                â”‚  â”‚
â”‚  â”‚  â”‚   â””â”€ ç´§æ€¥æ’å• (åˆ°è¾¾ç‡0.1/h)                          â”‚  â”‚
â”‚  â”‚  â””â”€ 25% workers: BASE_ORDERS (ä¿æŒåŸºå‡†æ€§èƒ½)             â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  å®Œæˆæ ‡å‡†ï¼š                                               â”‚  â”‚
â”‚  â”‚  â”œâ”€ ç»¼åˆè¯„åˆ† > 0.60                                     â”‚  â”‚
â”‚  â”‚  â”œâ”€ å®Œæˆç‡ > 80%                                        â”‚  â”‚
â”‚  â”‚  â””â”€ è¿ç»­10æ¬¡è¾¾æ ‡                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è®­ç»ƒç›‘æ§ä¸æ—¥å¿—

è®­ç»ƒè¿‡ç¨‹ä¸­å®æ—¶ç›‘æ§ä»¥ä¸‹æŒ‡æ ‡ï¼š

```
ğŸ”‚ è®­ç»ƒå›åˆ 145/1000 | å¹³å‡å¥–åŠ±: 1245.3
   (æ¯ä¸ªworkerå¥–åŠ±: [1234, 1256, 1240, 1251], å®Œæˆå…¨éƒ¨: 4/4)
   | ActoræŸå¤±: 0.0234 | â±ï¸æœ¬è½®ç”¨æ™‚: 45.2s (CPUé‡‡é›†: 38.1s, GPUæ›´æ–°: 7.1s)
   | æœ¬å›åˆä»»åŠ¡: [éšæœºè®¢å•+åŠ¨æ€äº‹ä»¶]Ã—4workers(å‡å¥–:1245.3)

ğŸ“Š æ­¤å›åˆKPIè¯„ä¼° - æ€»å®Œå·¥æ—¶é—´: 478.5min  
   | è®¾å¤‡åˆ©ç”¨ç‡: 87.3% | è®¢å•å»¶æœŸæ—¶é—´: 125.4min 
   | å®Œæˆé›¶ä»¶æ•°: 41/42 | é˜¶æ®µ: 'åŠ¨æ€äº‹ä»¶é²æ£’æ€§è®­ç»ƒ'
   | è¯„ä¼°ç¯å¢ƒ:[éšæœºè®¢å•+æ•…éšœâœ“+æ’å•âœ“]

ğŸš¥ å›åˆè¯„åˆ†: 0.683 (å…¨å±€æœ€ä½³: 0.721)(æ³›åŒ–é˜¶æ®µæœ€ä½³: 0.695)
   âœ… æ³›åŒ–å¼ºåŒ–é˜¶æ®µæœ€ä½³! æ¨¡å‹ä¿å­˜è‡³: models/1028_1342/1028_1342_general_train_best_actor.h5

ğŸ”® å½“å‰è®­ç»ƒè¿›åº¦: 14.5% | å½“å‰æ—¶é—´ï¼š13:45:23 | é¢„è®¡å®Œæˆæ—¶é—´: 18:32:15
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

```bash
# Pythonç‰ˆæœ¬
Python 3.8+

# æ ¸å¿ƒä¾èµ–
tensorflow>=2.15.0
numpy>=1.24.0
gymnasium>=0.29.0
pettingzoo>=1.24.0
simpy>=4.0.0
streamlit>=1.30.0  # å¯è§†åŒ–åº”ç”¨
matplotlib>=3.7.0
```

### å®‰è£…æ­¥éª¤

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/your-repo/MARL_FOR_W_Factory.git
cd MARL_FOR_W_Factory

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. éªŒè¯å®‰è£…
python -c "import tensorflow as tf; print(f'TensorFlow {tf.__version__} installed')"
```

### è®­ç»ƒæ¨¡å‹

#### æ–¹å¼1: ä½¿ç”¨è‡ªåŠ¨åŒ–è®­ç»ƒè„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# å¯åŠ¨è‡ªåŠ¨åŒ–è®­ç»ƒç®¡ç†å™¨
python auto_train.py

# åŠŸèƒ½ï¼š
# - è‡ªåŠ¨åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ¨¡å‹ç›®å½•
# - å®æ—¶ç›‘æ§è®­ç»ƒè¿›ç¨‹
# - è‡ªåŠ¨ä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹
# - åå°è¿è¡ŒTensorBoard
```

#### æ–¹å¼2: æ‰‹åŠ¨è®­ç»ƒ

```bash
# åŸºç¡€è®­ç»ƒï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
python mappo/ppo_marl_train.py

# æŒ‡å®šä¿å­˜è·¯å¾„
python mappo/ppo_marl_train.py \
    --models-dir ./my_models \
    --logs-dir ./my_logs
```

#### æ–¹å¼3: è‡ªå®šä¹‰é…ç½®è®­ç»ƒ

ç¼–è¾‘ `environments/w_factory_config.py` ä¿®æ”¹è®­ç»ƒå‚æ•°ï¼š

```python
# ç¤ºä¾‹ï¼šè°ƒæ•´è®­ç»ƒæµç¨‹
TRAINING_FLOW_CONFIG = {
    "foundation_phase": {
        "graduation_criteria": {
            "target_score": 0.75,  # æé«˜æ¯•ä¸šæ ‡å‡†
            "target_consistency": 10,
        },
        # ... æ›´å¤šé…ç½®
    }
}

# ç¤ºä¾‹ï¼šè°ƒæ•´ç½‘ç»œç»“æ„
PPO_NETWORK_CONFIG = {
    "hidden_sizes": [2048, 1024, 512],  # æ›´å¤§çš„ç½‘ç»œ
    "entropy_coeff": 0.6,  # æ›´å¼ºçš„æ¢ç´¢
}
```

### ç›‘æ§è®­ç»ƒ

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir=mappo/tensorboard_logs --port=6006

# æµè§ˆå™¨è®¿é—®
http://localhost:6006
```

TensorBoardæ˜¾ç¤ºæŒ‡æ ‡ï¼š
- è®­ç»ƒæŸå¤±æ›²çº¿ (Actor Loss, Critic Loss)
- ç­–ç•¥ç†µå˜åŒ–
- KPIæŒ‡æ ‡ (Makespan, Utilization, Tardiness)
- ç»¼åˆè¯„åˆ†è¶‹åŠ¿

---

## ğŸ“Š æ€§èƒ½è¯„ä¼°

### è¯„ä¼°æ¨¡å‹

```bash
# è¯„ä¼°å•ä¸ªæ¨¡å‹
python evaluation.py --model-path models/best_model/actor.h5

# å®Œæ•´è¯„ä¼°ï¼ˆåŒ…å«å¯å‘å¼åŸºçº¿å¯¹æ¯”ï¼‰
python evaluation.py \
    --model-path models/best_model/actor.h5 \
    --comprehensive \
    --generate-gantt \
    --output-dir results/

# ç”Ÿæˆç”˜ç‰¹å›¾å¯è§†åŒ–
python evaluation.py \
    --model-path models/best_model/actor.h5 \
    --generate-gantt
```

### è¯„ä¼°æŒ‡æ ‡

è¯„ä¼°è„šæœ¬ä¼šè¾“å‡ºä»¥ä¸‹KPIï¼š

| æŒ‡æ ‡ | è¯´æ˜ | ç›®æ ‡ |
|------|------|------|
| **Makespan** | æ€»å®Œå·¥æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰ | â†“ è¶Šå°è¶Šå¥½ |
| **Mean Utilization** | å¹³å‡è®¾å¤‡åˆ©ç”¨ç‡ | â†‘ è¶Šé«˜è¶Šå¥½ |
| **Total Tardiness** | æ€»å»¶æœŸæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰ | â†“ è¶Šå°è¶Šå¥½ |
| **Completed Parts** | å®Œæˆé›¶ä»¶æ•° | â†‘ è¾¾åˆ°100% |
| **Comprehensive Score** | ç»¼åˆè¯„åˆ† (0-1) | â†‘ è¶Šé«˜è¶Šå¥½ |

ç»¼åˆè¯„åˆ†è®¡ç®—å…¬å¼ï¼š

```python
score = (
    completion_rate * 0.40 +      # å®Œæˆç‡æƒé‡40%
    tardiness_score * 0.35 +       # å»¶æœŸè´¨é‡35%
    makespan_score * 0.15 +        # æ•ˆç‡15%
    utilization_score * 0.10       # åˆ©ç”¨ç‡10%
)
```

### å¯¹æ¯”åŸºçº¿ç®—æ³•

ç³»ç»Ÿå†…ç½®å¤šç§å¯å‘å¼ç®—æ³•ä½œä¸ºåŸºçº¿ï¼š

- **FIFO** (First In First Out): å…ˆåˆ°å…ˆæœåŠ¡
- **EDD** (Earliest Due Date): æœ€æ—©äº¤æœŸä¼˜å…ˆ
- **SPT** (Shortest Processing Time): æœ€çŸ­åŠ å·¥æ—¶é—´ä¼˜å…ˆ
- **CR** (Critical Ratio): ç´§æ€¥åº¦æ¯”ç‡ä¼˜å…ˆ

```bash
# è¯„ä¼°EDDå¯å‘å¼
python evaluation.py --heuristic EDD

# å¯¹æ¯”æ‰€æœ‰æ–¹æ³•
python evaluation.py --comprehensive --model-path models/best_model/actor.h5
```

### è°ƒè¯•å·¥å…·

```bash
# è¯¦ç»†è¡Œä¸ºåˆ†æ
python debug_marl_behavior.py \
    --model-path models/best_model/actor.h5 \
    --max-steps 600 \
    --snapshot-interval 100

# è¾“å‡ºï¼š
# - æ¯ä¸ªæ™ºèƒ½ä½“çš„å†³ç­–è¿‡ç¨‹
# - å€™é€‰å·¥ä»¶æ¦‚ç‡åˆ†å¸ƒ
# - è§‚æµ‹å‘é‡è§£ç 
# - å…³é”®å†³ç­–ç‚¹åˆ†æ
```

---

## âœ¨ æŠ€æœ¯äº®ç‚¹

### 1. é›†ä¸­å¼è®­ç»ƒåˆ†å¸ƒå¼æ‰§è¡Œ (CTDE)

**è®¾è®¡ç†å¿µ**ï¼š

- **è®­ç»ƒæ—¶**ï¼šCriticåˆ©ç”¨å…¨å±€ä¿¡æ¯ï¼ˆåŒ…å«æ‰€æœ‰æ™ºèƒ½ä½“çŠ¶æ€ï¼‰è¯„ä¼°ä»·å€¼
- **æ‰§è¡Œæ—¶**ï¼šActorä»…ä¾èµ–å±€éƒ¨è§‚æµ‹ï¼Œæ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²

**å®ç°ç»†èŠ‚**ï¼š

```python
# Criticè¾“å…¥ï¼šå…¨å±€çŠ¶æ€ + æ™ºèƒ½ä½“ID
global_state = concatenate([
    raw_global_state,  # å…¨å±€å®è§‚ä¿¡æ¯
    agent_one_hot      # å½“å‰æ™ºèƒ½ä½“æ ‡è¯†
])

# Actorè¾“å…¥ï¼šä»…å±€éƒ¨è§‚æµ‹
local_obs = get_state_for_agent(agent_id)
```

### 2. MultiDiscreteåŠ¨ä½œç©ºé—´ + æ— æ”¾å›é‡‡æ ·

**é—®é¢˜**ï¼šå¤šä¸ªæ™ºèƒ½ä½“å¯èƒ½åŒæ—¶é€‰æ‹©å¤„ç†åŒä¸€ä¸ªå·¥ä»¶

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# é€å¤´é‡‡æ ·ï¼Œå·²é€‰åŠ¨ä½œè¢«å±è”½
for head_i in range(num_heads):
    masked_probs = original_probs * (1 - mask)
    action_i = sample(masked_probs)
    mask[action_i] = 1  # æ ‡è®°å·²é€‰
```

### 3. å¤šä»»åŠ¡æ··åˆè®­ç»ƒ

**é˜²æ­¢ç¾éš¾æ€§é—å¿˜**ï¼š

```python
# æ¯ä¸ªè®­ç»ƒå›åˆ
if episode % 4 == 0:
    # 25%çš„å›åˆä½¿ç”¨BASE_ORDERSï¼ˆç¨³å®šé”šç‚¹ï¼‰
    orders = BASE_ORDERS
else:
    # 75%çš„å›åˆä½¿ç”¨éšæœºè®¢å•ï¼ˆæ³›åŒ–è®­ç»ƒï¼‰
    orders = generate_random_orders()
```

### 4. è‡ªé€‚åº”ç†µè°ƒæ•´

**åŠ¨æ€å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨**ï¼š

```python
# åœæ»æ£€æµ‹
if no_improvement_for(patience_episodes):
    entropy_coeff *= (1 + boost_factor)  # å¢å¼ºæ¢ç´¢
    
# è¿‡åº¦æ¢ç´¢æ£€æµ‹
elif completion_rate > 95%:
    entropy_coeff *= decay_rate  # æ”¶æ•›ç­–ç•¥
```

### 5. å‹ç¼©å½’ä¸€åŒ–æŠ€æœ¯

**é¿å…ç‰¹å¾é¥±å’Œ**ï¼š

```python
# ä¼ ç»Ÿå½’ä¸€åŒ–ï¼šx/norm â†’ å¯èƒ½>>1å¯¼è‡´é¥±å’Œ
# å‹ç¼©å½’ä¸€åŒ–ï¼šy = (x/norm) / (1 + x/norm) â†’ å§‹ç»ˆåœ¨(0,1)
def compressed_normalize(x, norm):
    normalized = x / norm
    return normalized / (1 + normalized)
```

### 6. å¹¶è¡Œç¯å¢ƒé‡‡é›†

**æå‡æ•°æ®æ•ˆç‡**ï¼š

```python
# ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œè¿è¡Œ4ä¸ªç¯å¢ƒ
with ProcessPoolExecutor(max_workers=4) as pool:
    futures = [
        pool.submit(run_worker, network_weights, config)
        for _ in range(4)
    ]
    experiences = [f.result() for f in futures]
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
MARL_FOR_W_Factory/
â”œâ”€â”€ environments/                    # ç¯å¢ƒæ¨¡å—
â”‚   â”œâ”€â”€ w_factory_env.py            # PettingZooç¯å¢ƒ + SimPyä»¿çœŸ
â”‚   â””â”€â”€ w_factory_config.py         # ç»Ÿä¸€é…ç½®æ–‡ä»¶ï¼ˆå•ä¸€çœŸç†æºï¼‰
â”‚
â”œâ”€â”€ mappo/                           # MAPPOç®—æ³•ï¼ˆæ¨¡å—åŒ–æ¶æ„ï¼‰
â”‚   â”œâ”€â”€ ppo_marl_train.py           # è®­ç»ƒå…¥å£ä¸»è„šæœ¬ (154è¡Œ)
â”‚   â”œâ”€â”€ ppo_trainer.py              # è®­ç»ƒå™¨ä¸»ç±» (1818è¡Œ)
â”‚   â”œâ”€â”€ ppo_network.py              # Actor-Criticç½‘ç»œ (457è¡Œ)
â”‚   â”œâ”€â”€ ppo_buffer.py               # ç»éªŒç¼“å†²ä¸GAEè®¡ç®— (128è¡Œ)
â”‚   â”œâ”€â”€ ppo_worker.py               # å¹¶è¡ŒWorkerè¿›ç¨‹ (304è¡Œ)
â”‚   â”œâ”€â”€ ppo_models/                 # æ¨¡å‹ä¿å­˜ç›®å½•
â”‚   â””â”€â”€ tensorboard_logs/           # TensorBoardæ—¥å¿—
â”‚
â”œâ”€â”€ app/                             # å¯è§†åŒ–åº”ç”¨
â”‚   â”œâ”€â”€ app_scheduler.py            # Streamlitäº¤äº’ç•Œé¢
â”‚   â””â”€â”€ custom_products.json        # è‡ªå®šä¹‰äº§å“é…ç½®
â”‚
â”œâ”€â”€ auto_train.py                    # è‡ªåŠ¨åŒ–è®­ç»ƒç®¡ç†å™¨
â”œâ”€â”€ evaluation.py                    # æ¨¡å‹è¯„ä¼°è„šæœ¬
â”œâ”€â”€ debug_marl_behavior.py          # è°ƒè¯•å·¥å…·
â”‚
â”œâ”€â”€ requirements.txt                 # Pythonä¾èµ–
â”œâ”€â”€ README.md                        # é¡¹ç›®è¯´æ˜ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â””â”€â”€ .gitignore                       # Gitå¿½ç•¥è§„åˆ™
```

### æ ¸å¿ƒæ–‡ä»¶è¯´æ˜

#### ç¯å¢ƒä¸ä»¿çœŸ
| æ–‡ä»¶ | ä»£ç é‡ | æ ¸å¿ƒåŠŸèƒ½ |
|------|--------|---------|
| `w_factory_env.py` | ~1720è¡Œ | SimPyä»¿çœŸ + PettingZooæ¥å£ |
| `w_factory_config.py` | ~550è¡Œ | å…¨å±€é…ç½®ï¼ˆå·¥ä½œç«™/è®¢å•/å¥–åŠ±/è®­ç»ƒå‚æ•°ï¼‰ |

#### MAPPOç®—æ³•æ¨¡å—ï¼ˆæ¨¡å—åŒ–æ¶æ„ï¼‰
| æ–‡ä»¶ | ä»£ç é‡ | æ ¸å¿ƒåŠŸèƒ½ |
|------|--------|---------|
| `ppo_marl_train.py` | 154è¡Œ | **è®­ç»ƒå…¥å£** - å‚æ•°è§£æã€æµç¨‹å¯åŠ¨ |
| `ppo_trainer.py` | 1818è¡Œ | **è®­ç»ƒå™¨ä¸»ç±»** - ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ã€è¯¾ç¨‹å­¦ä¹ ã€è‡ªé€‚åº”ç†µã€æ¨¡å‹ä¿å­˜ |
| `ppo_network.py` | 457è¡Œ | **ç¥ç»ç½‘ç»œ** - Actor-Criticæ¶æ„ã€CTDEèŒƒå¼ã€MultiDiscreteæ”¯æŒ |
| `ppo_buffer.py` | 128è¡Œ | **ç»éªŒç¼“å†²** - æ•°æ®å­˜å‚¨ã€GAEä¼˜åŠ¿å‡½æ•°è®¡ç®— |
| `ppo_worker.py` | 304è¡Œ | **å¹¶è¡ŒWorker** - å¤šè¿›ç¨‹ç¯å¢ƒé‡‡é›†ã€è®¾å¤‡ç®¡ç† |

#### è¯„ä¼°ä¸åº”ç”¨
| æ–‡ä»¶ | ä»£ç é‡ | æ ¸å¿ƒåŠŸèƒ½ |
|------|--------|---------|
| `evaluation.py` | ~790è¡Œ | æ¨¡å‹è¯„ä¼° + å¯å‘å¼å¯¹æ¯” + ç”˜ç‰¹å›¾ |
| `debug_marl_behavior.py` | ~446è¡Œ | è¯¦ç»†è¡Œä¸ºåˆ†æ + å†³ç­–è¿‡ç¨‹å¯è§†åŒ– |
| `app_scheduler.py` | ~1330è¡Œ | Streamlitå¯è§†åŒ–åº”ç”¨ |
| `auto_train.py` | ~303è¡Œ | è‡ªåŠ¨åŒ–è®­ç»ƒç®¡ç†å™¨ |

---

## ğŸ¨ å¯è§†åŒ–åº”ç”¨

### å¯åŠ¨äº¤äº’å¼è°ƒåº¦ç³»ç»Ÿ

```bash
streamlit run app/app_scheduler.py
```

### åº”ç”¨åŠŸèƒ½

1. **æ¨¡å‹é€‰æ‹©**
   - è‡ªåŠ¨æ‰«æå·²è®­ç»ƒæ¨¡å‹
   - æ”¯æŒå¤šæ£€æŸ¥ç‚¹åˆ‡æ¢

2. **è®¢å•é…ç½®**
   - å†…ç½®BASE_ORDERS
   - æ”¯æŒè‡ªå®šä¹‰è®¢å•
   - å®æ—¶éªŒè¯è®¢å•åˆç†æ€§

3. **è°ƒåº¦æ‰§è¡Œ**
   - ä¸€é”®å¯åŠ¨ä»¿çœŸ
   - å®æ—¶è¿›åº¦æ˜¾ç¤º
   - KPIå®æ—¶æ›´æ–°

4. **ç»“æœå¯è§†åŒ–**
   - ç”˜ç‰¹å›¾å±•ç¤ºï¼ˆè®¾å¤‡ç»´åº¦/è®¢å•ç»´åº¦ï¼‰
   - è®¾å¤‡åˆ©ç”¨ç‡æŸ±çŠ¶å›¾
   - KPIå¯¹æ¯”é›·è¾¾å›¾

5. **æ•°æ®å¯¼å‡º**
   - ä¸‹è½½è°ƒåº¦å†å²ï¼ˆCSVï¼‰
   - ä¿å­˜ç”˜ç‰¹å›¾ï¼ˆPNGï¼‰

---

## ğŸ”§ æ¨¡å—åŒ–ä½¿ç”¨ç¤ºä¾‹

### ç‹¬ç«‹ä½¿ç”¨å„æ¨¡å—

æ¨¡å—åŒ–è®¾è®¡å…è®¸æ‚¨ç‹¬ç«‹ä½¿ç”¨å„ä¸ªç»„ä»¶ï¼Œæˆ–é›†æˆåˆ°è‡ªå·±çš„é¡¹ç›®ä¸­ï¼š

#### ç¤ºä¾‹1: ç‹¬ç«‹ä½¿ç”¨PPONetwork

```python
from mappo.ppo_network import PPONetwork
import gymnasium as gym
import tensorflow as tf

# åˆ›å»ºç½‘ç»œå®ä¾‹
state_dim = 132
action_space = gym.spaces.MultiDiscrete([11] * 10)
global_state_dim = 50
lr = 1e-4

network = PPONetwork(
    state_dim=state_dim,
    action_space=action_space,
    lr=lr,
    global_state_dim=global_state_dim
)

# ä½¿ç”¨ç½‘ç»œè¿›è¡Œæ¨ç†
state = tf.random.normal([1, state_dim])
global_state = tf.random.normal([1, global_state_dim])
action, value, log_prob = network.get_action_and_value(state, global_state)
```

#### ç¤ºä¾‹2: ç‹¬ç«‹ä½¿ç”¨ExperienceBuffer

```python
from mappo.ppo_buffer import ExperienceBuffer

# åˆ›å»ºç¼“å†²åŒº
buffer = ExperienceBuffer()

# å­˜å‚¨ç»éªŒ
for step in range(100):
    buffer.store(
        state=observation,
        global_state=global_obs,
        action=action,
        reward=reward,
        value=value,
        action_prob=log_prob,
        done=done,
        truncated=truncated
    )

# è®¡ç®—GAEå¹¶è·å–è®­ç»ƒæ‰¹æ¬¡
states, global_states, actions, old_probs, advantages, returns = buffer.get_batch(
    gamma=0.99,
    lam=0.95,
    next_value_if_truncated=last_value
)
```

#### ç¤ºä¾‹3: è‡ªå®šä¹‰å¹¶è¡ŒWorker

```python
from mappo.ppo_worker import run_simulation_worker
from concurrent.futures import ProcessPoolExecutor

# å‡†å¤‡ç½‘ç»œæƒé‡
network_weights = {
    'actor': network.actor.get_weights(),
    'critic': network.critic.get_weights()
}

# å¹¶è¡Œè¿è¡Œå¤šä¸ªworker
with ProcessPoolExecutor(max_workers=4) as pool:
    futures = []
    for i in range(4):
        future = pool.submit(
            run_simulation_worker,
            network_weights=network_weights,
            state_dim=state_dim,
            action_space=action_space,
            num_steps=1000,
            seed=42 + i,
            global_state_dim=global_state_dim,
            network_config=network_config,
            curriculum_config={'worker_id': i}
        )
        futures.append(future)
    
    # æ”¶é›†ç»“æœ
    results = [f.result() for f in futures]
```

---

## ğŸ”§ é«˜çº§é…ç½®

### è¯¾ç¨‹å­¦ä¹ é…ç½®

åœ¨ `w_factory_config.py` ä¸­å¯ç”¨è¯¾ç¨‹å­¦ä¹ ï¼š

```python
TRAINING_FLOW_CONFIG = {
    "foundation_phase": {
        "curriculum_learning": {
            "enabled": True,  # å¼€å¯è¯¾ç¨‹å­¦ä¹ 
            "stages": [
                {
                    "name": "å…¥é—¨é˜¶æ®µ",
                    "orders_scale": 0.4,  # 40%è®¢å•é‡
                    "time_scale": 1.0,
                    "graduation_criteria": {
                        "target_score": 0.80,
                        "min_completion_rate": 100.0,
                        "target_consistency": 10
                    }
                },
                # æ›´å¤šé˜¶æ®µ...
            ]
        }
    }
}
```

### åŠ¨æ€äº‹ä»¶é…ç½®

```python
# è®¾å¤‡æ•…éšœ
EQUIPMENT_FAILURE = {
    "enabled": True,           # å¯ç”¨æ•…éšœ
    "mtbf_hours": 24,          # å¹³å‡24å°æ—¶æ•…éšœä¸€æ¬¡
    "mttr_minutes": 30,        # å¹³å‡30åˆ†é’Ÿä¿®å¤
}

# ç´§æ€¥æ’å•
EMERGENCY_ORDERS = {
    "enabled": True,           # å¯ç”¨ç´§æ€¥è®¢å•
    "arrival_rate": 0.1,       # æ¯å°æ—¶0.1ä¸ª
    "priority_boost": 0,       # ä¼˜å…ˆçº§æå‡
}
```

### å¥–åŠ±æƒé‡è°ƒæ•´

```python
REWARD_CONFIG = {
    "part_completion_reward": 100.0,  # æé«˜å®Œæˆå¥–åŠ±
    "tardiness_penalty_scaler": -15.0,  # åŠ é‡å»¶æœŸæƒ©ç½š
    "unnecessary_idle_penalty": -2.0,  # åŠ é‡ç©ºé—²æƒ©ç½š
    # ...
}
```

---

## ğŸ“ è®­ç»ƒæœ€ä½³å®è·µ

### 1. é˜¶æ®µåŒ–è®­ç»ƒç­–ç•¥

```
æ¨èæµç¨‹ï¼š
1. è¯¾ç¨‹å­¦ä¹ ï¼ˆå¯é€‰ï¼‰ â†’ 40% â†’ 80% â†’ 100% è®¢å•é‡
2. åŸºç¡€æ³›åŒ–è®­ç»ƒ â†’ éšæœºè®¢å• + 25% BASE_ORDERSé”šç‚¹
3. åŠ¨æ€é²æ£’æ€§è®­ç»ƒ â†’ è®¾å¤‡æ•…éšœ + ç´§æ€¥æ’å•
```

### 2. è¶…å‚æ•°è°ƒä¼˜å»ºè®®

| åœºæ™¯ | å»ºè®®è°ƒæ•´ |
|------|---------|
| **è®­ç»ƒä¸ç¨³å®š** | â†“ å­¦ä¹ ç‡ (5e-5), â†‘ æ¢¯åº¦è£å‰ª (0.5) |
| **æ”¶æ•›è¿‡æ…¢** | â†‘ åˆå§‹ç†µç³»æ•° (0.6), â†‘ PPO epochs (15) |
| **è¿‡æ‹ŸåˆBASE_ORDERS** | â†‘ éšæœºè®¢å•æ¯”ä¾‹ (90%), â†“ BASEé”šç‚¹ (10%) |
| **åŠ¨æ€äº‹ä»¶æ€§èƒ½å·®** | å»¶é•¿é˜¶æ®µäºŒè®­ç»ƒ, â†‘ æ•…éšœé¢‘ç‡ |

### 3. æ¨¡å‹æ£€æŸ¥ç‚¹ç­–ç•¥

```python
# è‡ªåŠ¨ä¿å­˜ä»¥ä¸‹æ£€æŸ¥ç‚¹ï¼š
1. å„è¯¾ç¨‹é˜¶æ®µæœ€ä½³æ¨¡å‹
2. åŸºç¡€è®­ç»ƒé˜¶æ®µæœ€ä½³æ¨¡å‹
3. æ³›åŒ–é˜¶æ®µæœ€ä½³æ¨¡å‹
4. åŒè¾¾æ ‡æ¨¡å‹ï¼ˆå®Œæˆç‡100% + æœ€é«˜åˆ†ï¼‰
```

---

## ğŸ› å¸¸è§é—®é¢˜

<details>
<summary><b>Q1: è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°NaNæŸå¤±ï¼Ÿ</b></summary>

**åŸå› **ï¼šæ¢¯åº¦çˆ†ç‚¸æˆ–å¥–åŠ±å°ºåº¦è¿‡å¤§

**è§£å†³**ï¼š
```python
# 1. é™ä½å­¦ä¹ ç‡
LEARNING_RATE_CONFIG["initial_lr"] = 5e-5

# 2. å¢å¼ºæ¢¯åº¦è£å‰ª
PPO_NETWORK_CONFIG["grad_clip_norm"] = 0.5

# 3. æ£€æŸ¥å¥–åŠ±å°ºåº¦
print(f"Max reward: {max(episode_rewards)}")
```
</details>

<details>
<summary><b>Q2: å¤šè¿›ç¨‹é‡‡é›†æŠ¥é”™ "CUDA initialization error"ï¼Ÿ</b></summary>

**åŸå› **ï¼šå­è¿›ç¨‹GPUèµ„æºå†²çª

**è§£å†³**ï¼š
```bash
# æ–¹æ¡ˆ1: å¼ºåˆ¶å­è¿›ç¨‹ä½¿ç”¨CPU
export FORCE_WORKER_CPU=1
python mappo/ppo_marl_train.py

# æ–¹æ¡ˆ2: å‡å°‘workeræ•°é‡
# åœ¨w_factory_config.pyä¸­
SYSTEM_CONFIG["num_parallel_workers"] = 2
```
</details>

<details>
<summary><b>Q3: æ¨¡å‹åŠ è½½å¤±è´¥ "Incompatible model format"ï¼Ÿ</b></summary>

**åŸå› **ï¼šTensorFlowç‰ˆæœ¬ä¸å…¼å®¹

**è§£å†³**ï¼š
```bash
# æ£€æŸ¥TensorFlowç‰ˆæœ¬
python -c "import tensorflow as tf; print(tf.__version__)"

# å¦‚æœç‰ˆæœ¬ä¸åŒ¹é…ï¼Œé‡æ–°å®‰è£…
pip install tensorflow==2.15.0

# å¦‚æœä»ç„¶å¤±è´¥ï¼Œå°è¯•åŠ è½½æƒé‡è€Œéå®Œæ•´æ¨¡å‹
# åœ¨evaluation.pyä¸­ä½¿ç”¨weightsåŠ è½½æ¨¡å¼
```
</details>

<details>
<summary><b>Q4: è®­ç»ƒé€Ÿåº¦å¾ˆæ…¢ï¼ˆ< 1 iter/minï¼‰ï¼Ÿ</b></summary>

**ä¼˜åŒ–å»ºè®®**ï¼š

```python
# 1. å‡å°‘PPO epochs
PPO_NETWORK_CONFIG["ppo_epochs"] = 8

# 2. å‡å°‘æ¯å›åˆæ­¥æ•°
TRAINING_FLOW_CONFIG["general_params"]["steps_per_episode"] = 1000

# 3. å¢åŠ å¹¶è¡Œworkersï¼ˆå¦‚æœCPU/å†…å­˜å……è¶³ï¼‰
SYSTEM_CONFIG["num_parallel_workers"] = 6

# 4. ä½¿ç”¨GPUåŠ é€Ÿ
# ç¡®ä¿CUDAå¯ç”¨: nvidia-smi
```
</details>

<details>
<summary><b>Q5: å¦‚ä½•è°ƒè¯•ç‰¹å®šæ¨¡å—çš„é—®é¢˜ï¼Ÿ</b></summary>

**æ¨¡å—åŒ–è°ƒè¯•ç­–ç•¥**ï¼š

```python
# è°ƒè¯•PPONetwork
from mappo.ppo_network import PPONetwork
network = PPONetwork(...)
# æ·»åŠ æ–­ç‚¹æˆ–æ‰“å°ä¸­é—´å±‚è¾“å‡º

# è°ƒè¯•ExperienceBuffer
from mappo.ppo_buffer import ExperienceBuffer
buffer = ExperienceBuffer()
# æ£€æŸ¥GAEè®¡ç®—é€»è¾‘

# è°ƒè¯•Worker
# è®¾ç½®ç¯å¢ƒå˜é‡å¯ç”¨è¯¦ç»†æ—¥å¿—
export TF_CPP_MIN_LOG_LEVEL=0
# å•ç‹¬è¿è¡Œworkeræµ‹è¯•
```
</details>

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **PPOç®—æ³•**  
   Schulman, J., et al. (2017). "Proximal Policy Optimization Algorithms." arXiv:1707.06347

2. **MAPPO**  
   Yu, C., et al. (2021). "The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games." arXiv:2103.01955

3. **GAE**  
   Schulman, J., et al. (2015). "High-Dimensional Continuous Control Using Generalized Advantage Estimation." arXiv:1506.02438

4. **CTDEèŒƒå¼**  
   Lowe, R., et al. (2017). "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments." NIPS 2017

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

**å¼€å‘æµç¨‹**ï¼š

1. Forkæœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯Pull Request

**ä»£ç è§„èŒƒ**ï¼š

- éµå¾ªPEP 8
- æ·»åŠ ç±»å‹æ³¨è§£
- ç¼–å†™docstring
- é€šè¿‡å•å…ƒæµ‹è¯•

**æ¨¡å—åŒ–å¼€å‘å»ºè®®**ï¼š

- æ–°åŠŸèƒ½ä¼˜å…ˆè€ƒè™‘æ·»åŠ åˆ°ç°æœ‰æ¨¡å—
- å¦‚éœ€æ–°æ¨¡å—ï¼Œç¡®ä¿èŒè´£å•ä¸€
- æ›´æ–°ç›¸åº”çš„READMEæ–‡æ¡£
- æ·»åŠ ä½¿ç”¨ç¤ºä¾‹

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

---

## ğŸ‘¥ ä½œè€…ä¸è‡´è°¢

**é¡¹ç›®ä½œè€…**: [Your Name]

**ç‰¹åˆ«è‡´è°¢**:
- TensorFlowå›¢é˜Ÿæä¾›æ·±åº¦å­¦ä¹ æ¡†æ¶
- PettingZooå›¢é˜Ÿæä¾›å¤šæ™ºèƒ½ä½“ç¯å¢ƒæ¥å£
- SimPyå›¢é˜Ÿæä¾›ç¦»æ•£äº‹ä»¶ä»¿çœŸå¼•æ“

---

## ğŸ“ è”ç³»æ–¹å¼

- **Issues**: [GitHub Issues](https://github.com/your-repo/MARL_FOR_W_Factory/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-repo/MARL_FOR_W_Factory/discussions)
- **Email**: your.email@example.com

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªStarï¼ â­**

Made with â¤ï¸ for Smart Manufacturing

</div>