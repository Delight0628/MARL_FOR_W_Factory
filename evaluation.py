import os
import sys
import numpy as np
import tensorflow as tf
import pandas as pd
from tqdm import tqdm
import argparse
import contextlib
import time # å¯¼å…¥timeæ¨¡å—
import copy

from plotting import generate_gantt_chart

# æ·»åŠ ç¯å¢ƒè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

from environments.w_factory_env import WFactoryEnv
from environments.w_factory_config import (
    get_total_parts_count, SIMULATION_TIME, BASE_ORDERS,
    ACTION_CONFIG_ENHANCED, WORKSTATIONS
)

# =============================================================================
# 1. æ ¸å¿ƒé…ç½® (Core Configuration)
# =============================================================================
NUM_EVAL_EPISODES = 30 

# é™æ€è¯„ä¼°ç¯å¢ƒé…ç½® (ç¡®ä¿å…¬å¹³å¯¹æ¯”)
# ä½¿ç”¨100%è®¢å•ï¼Œæ ‡å‡†æ—¶é—´ï¼Œä¸”ç¦ç”¨æ‰€æœ‰éšæœºäº‹ä»¶
STATIC_EVAL_CONFIG = {
    'orders_scale': 1.0,
    'time_scale': 1.0,
    'disable_failures': True, # æ˜ç¡®ç¦ç”¨è®¾å¤‡æ•…éšœ
    'stage_name': 'é™æ€è¯„ä¼°'
}

# =============================================================================
# ğŸŒŸ æ–°å¢ï¼šæ³›åŒ–èƒ½åŠ›æµ‹è¯•è®¢å•é…ç½® (Generalization Test Configurations) é…ç½®æ˜¯å¦åˆç†
# =============================================================================

# æµ‹è¯•é…ç½®1ï¼šé«˜å‹åŠ›çŸ­äº¤æœŸåœºæ™¯
GENERALIZATION_CONFIG_1 = {
    'custom_orders': [
        # ç´§æ€¥å°æ‰¹é‡è®¢å• - æµ‹è¯•æ¨¡å‹å¯¹æ—¶é—´å‹åŠ›çš„åº”å¯¹
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 8, "priority": 1, "due_date": 200.0},
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 6, "priority": 1, "due_date": 180.0},
        {"product": "æ¾æœ¨åºŠæ¶", "quantity": 10, "priority": 2, "due_date": 250.0},
        {"product": "æ¨±æ¡ƒæœ¨æ¤…å­", "quantity": 12, "priority": 1, "due_date": 300.0},
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 6, "priority": 3, "due_date": 400.0},
    ],
    'disable_failures': True,
    'stage_name': 'æ³›åŒ–æµ‹è¯•1-é«˜å‹åŠ›çŸ­äº¤æœŸ'
}

# æµ‹è¯•é…ç½®2ï¼šæ··åˆä¼˜å…ˆçº§å¤æ‚åœºæ™¯
GENERALIZATION_CONFIG_2 = {
    'custom_orders': [
        # ä¸åŒä¼˜å…ˆçº§å’Œè§„æ¨¡çš„æ··åˆè®¢å• - æµ‹è¯•ä¼˜å…ˆçº§å¹³è¡¡èƒ½åŠ›
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 15, "priority": 2, "due_date": 450.0},
        {"product": "æ¨±æ¡ƒæœ¨æ¤…å­", "quantity": 8, "priority": 1, "due_date": 350.0},
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 20, "priority": 3, "due_date": 600.0},
        {"product": "æ¾æœ¨åºŠæ¶", "quantity": 5, "priority": 1, "due_date": 280.0},
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 12, "priority": 2, "due_date": 520.0},
    ],
    'disable_failures': True,
    'stage_name': 'æ³›åŒ–æµ‹è¯•2-æ··åˆä¼˜å…ˆçº§'
}

# æµ‹è¯•é…ç½®3ï¼šå¤§æ‰¹é‡é•¿å‘¨æœŸåœºæ™¯
GENERALIZATION_CONFIG_3 = {
    'custom_orders': [
        # å¤§æ‰¹é‡é•¿å‘¨æœŸè®¢å• - æµ‹è¯•èµ„æºè°ƒåº¦å’Œé•¿æœŸè§„åˆ’èƒ½åŠ›
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 25, "priority": 2, "due_date": 800.0},
        {"product": "æ¾æœ¨åºŠæ¶", "quantity": 18, "priority": 1, "due_date": 700.0},
        {"product": "æ¨±æ¡ƒæœ¨æ¤…å­", "quantity": 22, "priority": 3, "due_date": 900.0},
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 15, "priority": 2, "due_date": 750.0},
    ],
    'disable_failures': True,
    'stage_name': 'æ³›åŒ–æµ‹è¯•3-å¤§æ‰¹é‡é•¿å‘¨æœŸ'
}

# =============================================================================
# 2. è¯„åˆ†å‡½æ•° (Scoring Function)
# =============================================================================

def calculate_score(kpi_results: dict, config: dict = None) -> float:
    """
    ç»Ÿä¸€è®¡ç®—å›åˆè¯„åˆ†çš„è¾…åŠ©å‡½æ•°ã€‚
    ä¸ ppo_marl_train.py ä¸­çš„è¯„åˆ†é€»è¾‘å®Œå…¨ä¸€è‡´ï¼Œç¡®ä¿è¯„ä¼°æ ‡å‡†ç»Ÿä¸€ã€‚
    """
    makespan = kpi_results.get('makespan', 0)
    completed_parts = kpi_results.get('total_parts', 0)
    utilization = kpi_results.get('mean_utilization', 0)
    tardiness = kpi_results.get('total_tardiness', 0)

    if completed_parts == 0:
        return 0.0
    
    # è¯„åˆ†åŸºå‡†ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
    makespan_score = max(0, 1 - makespan / (SIMULATION_TIME * 1.5))
    utilization_score = utilization
    tardiness_score = max(0, 1 - tardiness / (SIMULATION_TIME * 2.0))

    # ğŸŒŸ æ–°å¢ï¼šæ ¹æ®é…ç½®ç¡®å®šç›®æ ‡é›¶ä»¶æ•°
    if config and 'custom_orders' in config:
        # æ³›åŒ–æµ‹è¯•ï¼šè®¡ç®—è‡ªå®šä¹‰è®¢å•çš„æ€»é›¶ä»¶æ•°
        target_parts = sum(order["quantity"] for order in config['custom_orders'])
    else:
        # æ ‡å‡†æµ‹è¯•ï¼šä½¿ç”¨åŸºç¡€è®¢å•é…ç½®
        target_parts = get_total_parts_count()
    
    completion_score = completed_parts / target_parts if target_parts > 0 else 0
    
    # æƒé‡ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
    current_score = (
        completion_score * 0.5 +
        tardiness_score * 0.25 +
        makespan_score * 0.15 +
        utilization_score * 0.1
    )
    return current_score

# =============================================================================
# 3. ç¯å¢ƒåˆ›å»ºä¸é…ç½® (Environment Creation & Configuration)
# =============================================================================



# =============================================================================
# 4. è¯„ä¼°æ‰§è¡Œå™¨ (Evaluation Runners)
# =============================================================================

def run_single_episode(env: WFactoryEnv, policy_fn, seed: int, config: dict = None):
    """è¿è¡Œå•æ¬¡å›åˆçš„é€šç”¨å‡½æ•°"""
    obs, info = env.reset(seed=seed)
    step_count = 0
    
    while step_count < 1500: # ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´çš„æœ€å¤§æ­¥æ•°
        actions = policy_fn(obs, env)
        obs, rewards, terminations, truncations, info = env.step(actions)
        step_count += 1
        
        if any(terminations.values()) or any(truncations.values()):
            break
            
    final_stats = env.sim.get_final_stats()
    score = calculate_score(final_stats, config)
    
    # ä»…åœ¨ç¬¬ä¸€ä¸ªå›åˆï¼ˆseed=0ï¼‰è¿”å›è¯¦ç»†çš„åŠ å·¥å†å²
    history = env.sim.gantt_chart_history if seed == 0 else None
    
    return final_stats, score, history

def evaluate_marl_model(model_path: str, config: dict = STATIC_EVAL_CONFIG, generate_gantt: bool = False, output_dir: str = None, run_name: str = None, env_config_overrides: dict = None):
    """è¯„ä¼°MARLæ¨¡å‹"""
    config_name = config.get('stage_name', 'æœªçŸ¥é…ç½®')
    print(f"ğŸ§  å¼€å§‹è¯„ä¼°MARLæ¨¡å‹: {model_path}", flush=True)
    print(f"ğŸ“‹ æµ‹è¯•é…ç½®: {config_name}", flush=True)
    
    # ğŸ”§ æ–°å¢ï¼šæ˜¾ç¤ºè‡ªå®šä¹‰è®¢å•ä¿¡æ¯
    if 'custom_orders' in config:
        total_parts = sum(order["quantity"] for order in config['custom_orders'])
        print(f"ğŸ“¦ è‡ªå®šä¹‰è®¢å•: {len(config['custom_orders'])}ä¸ªè®¢å•, æ€»è®¡{total_parts}ä¸ªé›¶ä»¶", flush=True)
    
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ at {model_path}", flush=True)
        return None, None

    try:
        actor_model = tf.keras.models.load_model(model_path)
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}", flush=True)
        return None, None

    def marl_policy(obs, env):
        actions = {}
        for agent in env.agents:
            if agent in obs:
                state = tf.expand_dims(obs[agent], 0)
                action_probs = actor_model(state, training=False)
                # ğŸ”§ é‡è¦ä¿®å¤ï¼šè¯„ä¼°æ—¶ä½¿ç”¨å¾®è½¯éšæœºç­–ç•¥ï¼Œé¿å…å®Œå…¨å¡æ­»
                # æ ¹æ®æ¦‚ç‡åˆ†å¸ƒé‡‡æ ·ï¼Œä½†ä¸»è¦é€‰æ‹©é«˜æ¦‚ç‡åŠ¨ä½œ
                if np.random.random() < 0.2:  # 20%æ¦‚ç‡ä½¿ç”¨æ¦‚ç‡é‡‡æ ·
                    action = tf.random.categorical(tf.math.log(action_probs + 1e-8), 1)[0, 0].numpy()
                else:  # 80%æ¦‚ç‡ä½¿ç”¨ç¡®å®šæ€§
                    action = int(tf.argmax(action_probs[0]))
                actions[agent] = action
        return actions

    # ğŸ”§ V4 ä¿®å¤ï¼šç›´æ¥é€šè¿‡configä¼ é€’è‡ªå®šä¹‰è®¢å•ï¼Œæ— éœ€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    all_kpis = []
    all_scores = []
    first_episode_history = None

    # ğŸ”§ å…³é”®ä¿®å¤ V2: åˆå¹¶æ¥è‡ªä¼˜åŒ–å™¨çš„åŸºç¡€é…ç½®å’Œè¯„ä¼°åœºæ™¯çš„ç‰¹å®šé…ç½®
    final_config_for_eval = copy.deepcopy(env_config_overrides) if env_config_overrides else {}
    final_config_for_eval.update(config)

    env = WFactoryEnv(config=final_config_for_eval)
    
    # åŠ¨æ€é€‰æ‹©è¿­ä»£å™¨ï¼šäº¤äº’å¼ç»ˆç«¯ä½¿ç”¨tqdmï¼Œå¦åˆ™ä½¿ç”¨æ™®é€šrange
    is_tty = sys.stdout.isatty()
    iterator = range(NUM_EVAL_EPISODES)
    if is_tty:
        iterator = tqdm(iterator, desc=f"MARLæ¨¡å‹è¯„ä¼°({config_name})")

    start_time = time.time()
    for i in iterator:
        final_stats, score, history = run_single_episode(env, marl_policy, seed=i, config=config)
        all_kpis.append(final_stats)
        all_scores.append(score)
        if history is not None:
            first_episode_history = history
    
    if not is_tty:
        end_time = time.time()
        duration = end_time - start_time
        it_per_s = NUM_EVAL_EPISODES / duration if duration > 0 else float('inf')
        desc = f"MARLæ¨¡å‹è¯„ä¼°({config_name})"
        # æ‰‹åŠ¨æ ¼å¼åŒ–è¾“å‡ºï¼Œæ¨¡æ‹Ÿtqdmçš„æœ€ç»ˆè¡Œ
        print(f"{desc}: 100%|{'â–ˆ'*10}| {NUM_EVAL_EPISODES}/{NUM_EVAL_EPISODES} [{duration:.2f}s, {it_per_s:.2f}it/s]", file=sys.stdout, flush=True)

    # ç”Ÿæˆç”˜ç‰¹å›¾
    if generate_gantt and first_episode_history:
        generate_gantt_chart(first_episode_history, "MARL_PPO", config_name, output_dir=output_dir, run_name=run_name)

    env.close()
    
    return all_kpis, all_scores

def evaluate_heuristic(heuristic_name: str, config: dict = STATIC_EVAL_CONFIG, generate_gantt: bool = False, output_dir: str = None, run_name: str = None):
    """è¯„ä¼°å¯å‘å¼ç®—æ³•"""
    config_name = config.get('stage_name', 'æœªçŸ¥é…ç½®')
    print(f"âš™ï¸  å¼€å§‹è¯„ä¼°å¯å‘å¼ç®—æ³•: {heuristic_name}", flush=True)
    print(f"ğŸ“‹ æµ‹è¯•é…ç½®: {config_name}", flush=True)
    
    # ğŸ”§ æ–°å¢ï¼šæ˜¾ç¤ºè‡ªå®šä¹‰è®¢å•ä¿¡æ¯
    if 'custom_orders' in config:
        total_parts = sum(order["quantity"] for order in config['custom_orders'])
        print(f"ğŸ“¦ è‡ªå®šä¹‰è®¢å•: {len(config['custom_orders'])}ä¸ªè®¢å•, æ€»è®¡{total_parts}ä¸ªé›¶ä»¶", flush=True)

    def heuristic_policy(obs, env):
        sim = env.sim
        actions = {}
        
        for agent_id in env.agents:
            station_name = agent_id.replace("agent_", "")
            queue = sim.queues[station_name].items
            
            if not queue:
                actions[agent_id] = 0 # IDLE
                continue

            # æ ¹æ®å¯å‘å¼è§„åˆ™é€‰æ‹©é›¶ä»¶
            if heuristic_name == 'FIFO':
                # å…ˆè¿›å…ˆå‡º: ç›´æ¥é€‰æ‹©é˜Ÿåˆ—å¤´çš„ç¬¬ä¸€ä¸ª (index 0)
                best_part_index = 0
            elif heuristic_name == 'EDD':
                # æœ€æ—©äº¤æœŸ: é€‰æ‹©äº¤æœŸæœ€å°çš„
                best_part_index = np.argmin([part.due_date for part in queue])
            elif heuristic_name == 'SPT':
                # æœ€çŸ­å¤„ç†æ—¶é—´: é€‰æ‹©å½“å‰å·¥åºå¤„ç†æ—¶é—´æœ€çŸ­çš„
                best_part_index = np.argmin([part.get_processing_time() for part in queue])
            else:
                raise ValueError(f"æœªçŸ¥çš„å¯å‘å¼è§„åˆ™: {heuristic_name}")

            # åŠ¨ä½œID = é›¶ä»¶ç´¢å¼• + 1
            actions[agent_id] = best_part_index + 1
            
        return actions

    # ğŸ”§ V4 ä¿®å¤ï¼šç›´æ¥é€šè¿‡configä¼ é€’è‡ªå®šä¹‰è®¢å•ï¼Œæ— éœ€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    all_kpis = []
    all_scores = []
    first_episode_history = None

    env = WFactoryEnv(config=config)
    
    # åŠ¨æ€é€‰æ‹©è¿­ä»£å™¨ï¼šäº¤äº’å¼ç»ˆç«¯ä½¿ç”¨tqdmï¼Œå¦åˆ™ä½¿ç”¨æ™®é€šrange
    is_tty = sys.stdout.isatty()
    iterator = range(NUM_EVAL_EPISODES)
    if is_tty:
        iterator = tqdm(iterator, desc=f"{heuristic_name}è¯„ä¼°({config_name})")

    start_time = time.time()
    for i in iterator:
        final_stats, score, history = run_single_episode(env, heuristic_policy, seed=i, config=config)
        all_kpis.append(final_stats)
        all_scores.append(score)
        if history is not None:
            first_episode_history = history

    if not is_tty:
        end_time = time.time()
        duration = end_time - start_time
        it_per_s = NUM_EVAL_EPISODES / duration if duration > 0 else float('inf')
        desc = f"{heuristic_name}è¯„ä¼°({config_name})"
        # æ‰‹åŠ¨æ ¼å¼åŒ–è¾“å‡ºï¼Œæ¨¡æ‹Ÿtqdmçš„æœ€ç»ˆè¡Œ
        print(f"{desc}: 100%|{'â–ˆ'*10}| {NUM_EVAL_EPISODES}/{NUM_EVAL_EPISODES} [{duration:.2f}s, {it_per_s:.2f}it/s]", file=sys.stdout, flush=True)
    
    # ç”Ÿæˆç”˜ç‰¹å›¾
    if generate_gantt and first_episode_history:
        generate_gantt_chart(first_episode_history, heuristic_name, config_name, output_dir=output_dir, run_name=run_name)
        
    env.close()
    return all_kpis, all_scores

# =============================================================================
# 5. ç»“æœæ±‡æ€»ä¸å±•ç¤º (Result Aggregation & Display)
# =============================================================================

def aggregate_results(method_name: str, all_kpis: list, all_scores: list, config: dict = None):
    """æ±‡æ€»å¤šæ¬¡è¿è¡Œçš„ç»“æœï¼Œè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®"""
    if all_kpis is None:
        return {
            "Method": method_name,
            "Avg Score": "N/A",
            "Std Score": "N/A",
            "Avg Completion %": "N/A",
            "Avg Makespan": "N/A",
            "Avg Tardiness": "N/A",
            "Avg Utilization %": "N/A",
        }

    # ğŸŒŸ æ–°å¢ï¼šæ ¹æ®é…ç½®ç¡®å®šç›®æ ‡é›¶ä»¶æ•°
    if config and 'custom_orders' in config:
        target_parts = sum(order["quantity"] for order in config['custom_orders'])
    else:
        target_parts = get_total_parts_count()
        
    completion_rates = [(k['total_parts'] / target_parts) * 100 for k in all_kpis]
    
    return {
        "Method": method_name,
        "Avg Score": f"{np.mean(all_scores):.3f}",
        "Std Score": f"{np.std(all_scores):.3f}",
        "Avg Completion %": f"{np.mean(completion_rates):.1f}",
        "Avg Makespan": f"{np.mean([k['makespan'] for k in all_kpis]):.1f}",
        "Avg Tardiness": f"{np.mean([k['total_tardiness'] for k in all_kpis]):.1f}",
        "Avg Utilization %": f"{np.mean([k['mean_utilization'] for k in all_kpis]) * 100:.1f}",
    }

def run_comprehensive_evaluation(model_path: str, generate_gantt: bool = False, output_dir: str = None, run_name: str = None):
    """è¿è¡Œç»¼åˆè¯„ä¼°ï¼šåŒ…æ‹¬åŸºå‡†æµ‹è¯•å’Œæ³›åŒ–èƒ½åŠ›æµ‹è¯•"""
    
    print("="*80, flush=True)
    print("ğŸš€ å¼€å§‹è¿›è¡Œé™æ€ç¯å¢ƒä¸‹çš„è°ƒåº¦ç­–ç•¥ç»¼åˆè¯„ä¼°", flush=True)
    print(f"ğŸ” æ¯ä¸ªç­–ç•¥å°†ç‹¬ç«‹è¿è¡Œ {NUM_EVAL_EPISODES} æ¬¡ä»¥è·å–å¯é çš„ç»Ÿè®¡ç»“æœã€‚", flush=True)
    print("="*80, flush=True)

    # æµ‹è¯•é…ç½®åˆ—è¡¨
    test_configs = [
        ("åŸºå‡†æµ‹è¯•", STATIC_EVAL_CONFIG),
        ("æ³›åŒ–æµ‹è¯•1-é«˜å‹åŠ›çŸ­äº¤æœŸ", GENERALIZATION_CONFIG_1),
        ("æ³›åŒ–æµ‹è¯•2-æ··åˆä¼˜å…ˆçº§", GENERALIZATION_CONFIG_2),
        ("æ³›åŒ–æµ‹è¯•3-å¤§æ‰¹é‡é•¿å‘¨æœŸ", GENERALIZATION_CONFIG_3),
    ]
    
    all_results = []
    
    for test_name, config in test_configs:
        print(f"\nğŸ”¬ å¼€å§‹ {test_name}", flush=True)
        print("="*60, flush=True)
        
        # ğŸ”§ V4 ä¿®å¤ï¼šç›´æ¥ä¼ é€’configï¼Œæ— éœ€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        # 1. è¯„ä¼°MARLæ¨¡å‹
        marl_kpis, marl_scores = evaluate_marl_model(model_path, config, generate_gantt=generate_gantt, output_dir=output_dir, run_name=run_name)
        
        # 2. è¯„ä¼°å¯å‘å¼ç®—æ³• (ç”˜ç‰¹å›¾ä¿å­˜åˆ°çˆ¶ç›®å½•)
        heuristic_output_dir = os.path.dirname(output_dir) if output_dir else None
        fifo_kpis, fifo_scores = evaluate_heuristic('FIFO', config, generate_gantt=generate_gantt, output_dir=heuristic_output_dir, run_name=run_name)
        edd_kpis, edd_scores = evaluate_heuristic('EDD', config, generate_gantt=generate_gantt, output_dir=heuristic_output_dir, run_name=run_name)
        spt_kpis, spt_scores = evaluate_heuristic('SPT', config, generate_gantt=generate_gantt, output_dir=heuristic_output_dir, run_name=run_name)

        # 3. æ±‡æ€»ç»“æœ
        results = [
            aggregate_results("MARL (PPO)", marl_kpis, marl_scores, config),
            aggregate_results("SPT", spt_kpis, spt_scores, config),
            aggregate_results("EDD", edd_kpis, edd_scores, config),
            aggregate_results("FIFO", fifo_kpis, fifo_scores, config),
        ]
        
        # 4. æ‰“å°å½“å‰æµ‹è¯•ç»“æœ
        df = pd.DataFrame(results)
        print(f"\nğŸ† {test_name} - è¯„ä¼°å¯¹æ¯”ç»“æœ", flush=True)
        print("-"*60, flush=True)
        print(df.to_string(index=False), flush=True)
        
        # ä¿å­˜ç»“æœç”¨äºæœ€ç»ˆæ±‡æ€»
        for result in results:
            result['Test_Config'] = test_name
        all_results.extend(results)
        
        print("\n" + "="*60, flush=True)
    
    # 5. ç”Ÿæˆæœ€ç»ˆæ±‡æ€»æŠ¥å‘Š
    print(f"\nğŸ¯ æœ€ç»ˆæ±‡æ€»æŠ¥å‘Š - æ³›åŒ–èƒ½åŠ›åˆ†æ", flush=True)
    print("="*80, flush=True)
    
    # æŒ‰æ–¹æ³•åˆ†ç»„å±•ç¤ºç»“æœ
    methods = ["MARL (PPO)", "SPT", "EDD", "FIFO"]
    
    for method in methods:
        method_results = [r for r in all_results if r['Method'] == method]
        if method_results:
            print(f"\nğŸ“Š {method} åœ¨ä¸åŒæµ‹è¯•é…ç½®ä¸‹çš„è¡¨ç°:", flush=True)
            method_df = pd.DataFrame(method_results)
            # é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼ŒæŠŠTest_Configæ”¾åœ¨å‰é¢
            cols = ['Test_Config'] + [col for col in method_df.columns if col != 'Test_Config']
            method_df = method_df[cols]
            print(method_df.to_string(index=False), flush=True)

    print("\nğŸ’¡ æŒ‡æ ‡è§£è¯»:", flush=True)
    print("  - Avg Score: ç»¼åˆè¯„åˆ†ï¼Œè¶Šé«˜è¶Šå¥½ (æˆ‘ä»¬çš„æ ¸å¿ƒä¼˜åŒ–ç›®æ ‡)ã€‚", flush=True)
    print("  - Std Score: åˆ†æ•°æ ‡å‡†å·®ï¼Œè¶Šä½è¯´æ˜ç­–ç•¥è¶Šç¨³å®šã€‚", flush=True)
    print("  - Avg Completion %: å¹³å‡ä»»åŠ¡å®Œæˆç‡ï¼Œè¶Šé«˜è¶Šå¥½ã€‚", flush=True)
    print("  - Avg Makespan: å¹³å‡æ€»å®Œå·¥æ—¶é—´ï¼Œè¶Šä½è¶Šå¥½ã€‚", flush=True)
    print("  - Avg Tardiness: å¹³å‡æ€»å»¶æœŸæ—¶é—´ï¼Œè¶Šä½è¶Šå¥½ã€‚", flush=True)
    print("  - Avg Utilization %: å¹³å‡è®¾å¤‡åˆ©ç”¨ç‡ï¼Œè¶Šé«˜è¯´æ˜èµ„æºåˆ©ç”¨è¶Šå……åˆ†ã€‚", flush=True)
    
    print(f"\nğŸ”¬ æ³›åŒ–èƒ½åŠ›åˆ†æç»“è®º:", flush=True)
    print("  è§‚å¯ŸMARLæ¨¡å‹åœ¨ä¸åŒæµ‹è¯•é…ç½®ä¸‹çš„è¯„åˆ†ç¨³å®šæ€§ï¼Œ", flush=True)
    print("  å¯¹æ¯”å¯å‘å¼ç®—æ³•åœ¨é¢å¯¹æ–°è®¢å•é…ç½®æ—¶çš„æ€§èƒ½æ³¢åŠ¨ï¼Œ", flush=True)
    print("  ä»¥æ­¤è¯„ä¼°å„ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚", flush=True)

def main():
    parser = argparse.ArgumentParser(description="è¯„ä¼°MARLæ¨¡å‹ä¸å¯å‘å¼ç®—æ³•çš„æ€§èƒ½")
    parser.add_argument(
        "--model_path", 
        type=str, 
        required=True,
        help="æŒ‡å‘å·²è®­ç»ƒå¥½çš„MARL actoræ¨¡å‹æ–‡ä»¶ (.keras) çš„è·¯å¾„"
    )
    parser.add_argument(
        "--generalization", 
        action="store_true",
        help="æ˜¯å¦è¿›è¡Œæ³›åŒ–èƒ½åŠ›æµ‹è¯• (é»˜è®¤åªè¿›è¡ŒåŸºå‡†æµ‹è¯•)"
    )
    parser.add_argument(
        "--gantt",
        action="store_true",
        help="æ˜¯å¦ä¸ºæ¯ä¸ªè¯„ä¼°åœºæ™¯ç”Ÿæˆè¯¦ç»†çš„è°ƒåº¦ç”˜ç‰¹å›¾"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default=None,
        help="æŒ‡å®šä¸€ä¸ªç›®å½•æ¥å­˜æ”¾æ‰€æœ‰è¾“å‡ºçš„ç”˜ç‰¹å›¾æ–‡ä»¶"
    )
    parser.add_argument(
        "--run_name",
        type=str,
        default=None,
        help="ä¸ºæœ¬æ¬¡è¿è¡Œæä¾›ä¸€ä¸ªåç§°ï¼Œå°†ç”¨ä½œç”˜ç‰¹å›¾æ–‡ä»¶åçš„å‰ç¼€"
    )
    args = parser.parse_args()

    if args.generalization:
        # è¿è¡Œå®Œæ•´çš„æ³›åŒ–èƒ½åŠ›æµ‹è¯•
        run_comprehensive_evaluation(args.model_path, generate_gantt=args.gantt, output_dir=args.output_dir, run_name=args.run_name)
    else:
        # ä»…è¿è¡ŒåŸºå‡†æµ‹è¯• (åŸæœ‰åŠŸèƒ½)
        print("="*80, flush=True)
        print("ğŸš€ å¼€å§‹è¿›è¡Œé™æ€ç¯å¢ƒä¸‹çš„è°ƒåº¦ç­–ç•¥ç»¼åˆè¯„ä¼°", flush=True)
        print(f"ğŸ” æ¯ä¸ªç­–ç•¥å°†ç‹¬ç«‹è¿è¡Œ {NUM_EVAL_EPISODES} æ¬¡ä»¥è·å–å¯é çš„ç»Ÿè®¡ç»“æœã€‚", flush=True)
        print("="*80, flush=True)

        # 1. è¯„ä¼°MARLæ¨¡å‹
        marl_kpis, marl_scores = evaluate_marl_model(args.model_path, generate_gantt=args.gantt, output_dir=args.output_dir, run_name=args.run_name)
        
        # 2. è¯„ä¼°å¯å‘å¼ç®—æ³• (ç”˜ç‰¹å›¾ä¿å­˜åˆ°çˆ¶ç›®å½•)
        heuristic_output_dir = os.path.dirname(args.output_dir) if args.output_dir else None
        fifo_kpis, fifo_scores = evaluate_heuristic('FIFO', generate_gantt=args.gantt, output_dir=heuristic_output_dir, run_name=args.run_name)
        edd_kpis, edd_scores = evaluate_heuristic('EDD', generate_gantt=args.gantt, output_dir=heuristic_output_dir, run_name=args.run_name)
        spt_kpis, spt_scores = evaluate_heuristic('SPT', generate_gantt=args.gantt, output_dir=heuristic_output_dir, run_name=args.run_name)

        # 3. æ±‡æ€»ç»“æœ
        results = [
            aggregate_results("MARL (PPO)", marl_kpis, marl_scores),
            aggregate_results("SPT", spt_kpis, spt_scores),
            aggregate_results("EDD", edd_kpis, edd_scores),
            aggregate_results("FIFO", fifo_kpis, fifo_scores),
        ]
        
        # 4. åˆ›å»ºå¹¶æ‰“å°ç»“æœè¡¨æ ¼
        df = pd.DataFrame(results)
        
        print("\n" + "="*80, flush=True)
        print("ğŸ† æœ€ç»ˆè¯„ä¼°å¯¹æ¯”ç»“æœ", flush=True)
        print("="*80, flush=True)
        print(df.to_string(index=False), flush=True)
        print("="*80, flush=True)
        print("\nğŸ’¡ æŒ‡æ ‡è§£è¯»:", flush=True)
        print("  - Avg Score: ç»¼åˆè¯„åˆ†ï¼Œè¶Šé«˜è¶Šå¥½ (æˆ‘ä»¬çš„æ ¸å¿ƒä¼˜åŒ–ç›®æ ‡)ã€‚", flush=True)
        print("  - Std Score: åˆ†æ•°æ ‡å‡†å·®ï¼Œè¶Šä½è¯´æ˜ç­–ç•¥è¶Šç¨³å®šã€‚", flush=True)
        print("  - Avg Completion %: å¹³å‡ä»»åŠ¡å®Œæˆç‡ï¼Œè¶Šé«˜è¶Šå¥½ã€‚", flush=True)
        print("  - Avg Makespan: å¹³å‡æ€»å®Œå·¥æ—¶é—´ï¼Œè¶Šä½è¶Šå¥½ã€‚", flush=True)
        print("  - Avg Tardiness: å¹³å‡æ€»å»¶æœŸæ—¶é—´ï¼Œè¶Šä½è¶Šå¥½ã€‚", flush=True)
        print("  - Avg Utilization %: å¹³å‡è®¾å¤‡åˆ©ç”¨ç‡ï¼Œè¶Šé«˜è¯´æ˜èµ„æºåˆ©ç”¨è¶Šå……åˆ†ã€‚", flush=True)


if __name__ == "__main__":
    main()
