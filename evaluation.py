import os
import sys

# å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶è¯„ä¼°è„šæœ¬åœ¨CPUä¸Šè¿è¡Œï¼Œé¿å…ä¸è®­ç»ƒè¿›ç¨‹äº‰å¤ºGPUèµ„æº
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # å±è”½TensorFlowçš„INFOçº§åˆ«æ—¥å¿—

import numpy as np
import tensorflow as tf
import pandas as pd
from tqdm import tqdm
import argparse
import contextlib
import time # å¯¼å…¥timeæ¨¡å—
import copy

from plotting import generate_gantt_chart

# æ·»åŠ ç¯å¢ƒè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

from environments.w_factory_env import WFactoryEnv
from environments.w_factory_config import (
    get_total_parts_count, SIMULATION_TIME, BASE_ORDERS,
    calculate_episode_score, EVALUATION_CONFIG
)
# 10201530 æ–°å¢ï¼šå¯¼å…¥gymä»¥è¯†åˆ«MultiDiscreteåŠ¨ä½œç©ºé—´
import gymnasium as gym

# =============================================================================
# 1. æ ¸å¿ƒé…ç½® (Core Configuration)
# =============================================================================
NUM_EVAL_EPISODES = 1 

# é™æ€è¯„ä¼°ç¯å¢ƒé…ç½® (ç¡®ä¿å…¬å¹³å¯¹æ¯”)
# ä½¿ç”¨100%è®¢å•ï¼Œæ ‡å‡†æ—¶é—´ï¼Œä¸”ç¦ç”¨æ‰€æœ‰éšæœºäº‹ä»¶
STATIC_EVAL_CONFIG = {
    'orders_scale': 1.0,
    'time_scale': 1.0,
    'disable_failures': True, # æ˜ç¡®ç¦ç”¨è®¾å¤‡æ•…éšœ
    'stage_name': 'é™æ€è¯„ä¼°'
}

# =============================================================================
# ğŸŒŸ æ–°å¢ï¼šæ³›åŒ–èƒ½åŠ›æµ‹è¯•è®¢å•é…ç½® (Generalization Test Configurations) é…ç½®æ˜¯å¦åˆç†
# =============================================================================

# æµ‹è¯•é…ç½®1ï¼šé«˜å‹åŠ›çŸ­äº¤æœŸåœºæ™¯
GENERALIZATION_CONFIG_1 = {
    'custom_orders': [
        # ç´§æ€¥å°æ‰¹é‡è®¢å• - æµ‹è¯•æ¨¡å‹å¯¹æ—¶é—´å‹åŠ›çš„åº”å¯¹
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 8, "priority": 1, "due_date": 200.0},
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 6, "priority": 1, "due_date": 180.0},
        {"product": "æ¾æœ¨åºŠæ¶", "quantity": 10, "priority": 2, "due_date": 250.0},
        {"product": "æ¨±æ¡ƒæœ¨æ¤…å­", "quantity": 12, "priority": 1, "due_date": 300.0},
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 6, "priority": 3, "due_date": 400.0},
    ],
    'disable_failures': True,
    'stage_name': 'æ³›åŒ–æµ‹è¯•1-é«˜å‹åŠ›çŸ­äº¤æœŸ'
}

# æµ‹è¯•é…ç½®2ï¼šæ··åˆä¼˜å…ˆçº§å¤æ‚åœºæ™¯
GENERALIZATION_CONFIG_2 = {
    'custom_orders': [
        # ä¸åŒä¼˜å…ˆçº§å’Œè§„æ¨¡çš„æ··åˆè®¢å• - æµ‹è¯•ä¼˜å…ˆçº§å¹³è¡¡èƒ½åŠ›
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 15, "priority": 2, "due_date": 450.0},
        {"product": "æ¨±æ¡ƒæœ¨æ¤…å­", "quantity": 8, "priority": 1, "due_date": 350.0},
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 20, "priority": 3, "due_date": 600.0},
        {"product": "æ¾æœ¨åºŠæ¶", "quantity": 5, "priority": 1, "due_date": 280.0},
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 12, "priority": 2, "due_date": 520.0},
    ],
    'disable_failures': True,
    'stage_name': 'æ³›åŒ–æµ‹è¯•2-æ··åˆä¼˜å…ˆçº§'
}

# æµ‹è¯•é…ç½®3ï¼šå¤§æ‰¹é‡é•¿å‘¨æœŸåœºæ™¯
GENERALIZATION_CONFIG_3 = {
    'custom_orders': [
        # å¤§æ‰¹é‡é•¿å‘¨æœŸè®¢å• - æµ‹è¯•èµ„æºè°ƒåº¦å’Œé•¿æœŸè§„åˆ’èƒ½åŠ›
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 25, "priority": 2, "due_date": 800.0},
        {"product": "æ¾æœ¨åºŠæ¶", "quantity": 18, "priority": 1, "due_date": 700.0},
        {"product": "æ¨±æ¡ƒæœ¨æ¤…å­", "quantity": 22, "priority": 3, "due_date": 900.0},
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 15, "priority": 2, "due_date": 750.0},
    ],
    'disable_failures': True,
    'stage_name': 'æ³›åŒ–æµ‹è¯•3-å¤§æ‰¹é‡é•¿å‘¨æœŸ'
}

# =============================================================================
# 3. ç¯å¢ƒåˆ›å»ºä¸é…ç½® (Environment Creation & Configuration)
# =============================================================================



# =============================================================================
# 4. è¯„ä¼°æ‰§è¡Œå™¨ (Evaluation Runners)
# =============================================================================

def run_single_episode(env: WFactoryEnv, policy_fn, seed: int, config: dict = None):
    """è¿è¡Œå•æ¬¡å›åˆçš„é€šç”¨å‡½æ•°"""
    obs, info = env.reset(seed=seed)
    step_count = 0
    
    while step_count < 1500: # ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´çš„æœ€å¤§æ­¥æ•°
        # ä¿®å¤ï¼šå°† info å’Œ step_count ä¼ é€’ç»™ç­–ç•¥å‡½æ•°
        actions = policy_fn(obs, env, info, step_count)
        obs, rewards, terminations, truncations, info = env.step(actions)
        step_count += 1
        
        if any(terminations.values()) or any(truncations.values()):
            break
            
    final_stats = env.sim.get_final_stats()
    score = calculate_episode_score(final_stats, config)
    
    # ä»…åœ¨ç¬¬ä¸€ä¸ªå›åˆï¼ˆseed=0ï¼‰è¿”å›è¯¦ç»†çš„åŠ å·¥å†å²
    history = env.sim.gantt_chart_history if seed == 0 else None
    
    return final_stats, score, history

def evaluate_marl_model(model_path: str, config: dict = STATIC_EVAL_CONFIG, generate_gantt: bool = False, output_dir: str = None, run_name: str = None, env_config_overrides: dict = None):
    """è¯„ä¼°MARLæ¨¡å‹"""
    config_name = config.get('stage_name', 'æœªçŸ¥é…ç½®')
    print(f"ğŸ§  å¼€å§‹è¯„ä¼°MARLæ¨¡å‹: {model_path}", flush=True)
    print(f"ğŸ“‹ æµ‹è¯•é…ç½®: {config_name}", flush=True)
    
    # ğŸ”§ æ–°å¢ï¼šæ˜¾ç¤ºè‡ªå®šä¹‰è®¢å•ä¿¡æ¯
    if 'custom_orders' in config:
        total_parts = sum(order["quantity"] for order in config['custom_orders'])
        print(f"ğŸ“¦ è‡ªå®šä¹‰è®¢å•: {len(config['custom_orders'])}ä¸ªè®¢å•, æ€»è®¡{total_parts}ä¸ªé›¶ä»¶", flush=True)
    
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ at {model_path}", flush=True)
        return None, None

    try:
        actor_model = tf.keras.models.load_model(model_path)
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}", flush=True)
        return None, None

    # 10201530 ä¿®å¤ï¼šMARLç­–ç•¥é€‚é…MultiDiscreteï¼ŒæŒ‰â€œå…±äº«åˆ†å¸ƒÃ—å¹¶è¡Œè®¾å¤‡æ•°â€è¾“å‡ºåŠ¨ä½œæ•°ç»„
    def marl_policy(obs, env, info, step_count):
        actions = {}
        for agent in env.agents:
            if agent in obs:
                state = tf.expand_dims(obs[agent], 0)
                # 10220715 ä¿®å¤ï¼šå…¼å®¹å¤šå¤´/å•å¤´æ¨¡å‹è¾“å‡ºï¼Œå¹¶å±•å¹³ä¸ºä¸€ç»´å‘é‡
                model_out = actor_model(state, training=False)
                if isinstance(model_out, (list, tuple)):
                    probs_vec = np.squeeze(model_out[0].numpy())  # å–ç¬¬ä¸€ä¸ªå¤´ç”¨äºç”Ÿæˆtop-ké›†åˆ
                else:
                    probs_vec = np.squeeze(model_out.numpy()[0])
                space = env.action_space(agent)
                if isinstance(space, gym.spaces.MultiDiscrete):
                    k = len(space.nvec)
                    # 10220715 ä¿®å¤ï¼šå®‰å…¨æ’åºå¹¶é€ä¸ªè½¬ä¸ºintï¼Œé¿å…numpyæ ‡é‡è½¬æ¢é”™è¯¯
                    sorted_idx = np.argsort(probs_vec)[::-1]
                    chosen = []
                    for idx in sorted_idx:
                        idx_int = int(np.asarray(idx).item())
                        if idx_int not in chosen:
                            chosen.append(idx_int)
                        if len(chosen) >= k:
                            break
                    while len(chosen) < k:
                        chosen.append(0)
                    actions[agent] = np.array(chosen, dtype=space.dtype)
                else:
                    actions[agent] = int(np.argmax(probs_vec))
        return actions

    # ğŸ”§ V4 ä¿®å¤ï¼šç›´æ¥é€šè¿‡configä¼ é€’è‡ªå®šä¹‰è®¢å•ï¼Œæ— éœ€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    all_kpis = []
    all_scores = []
    first_episode_history = None

    # ğŸ”§ å…³é”®ä¿®å¤ V2: åˆå¹¶æ¥è‡ªä¼˜åŒ–å™¨çš„åŸºç¡€é…ç½®å’Œè¯„ä¼°åœºæ™¯çš„ç‰¹å®šé…ç½®
    # ä¼˜å…ˆä½¿ç”¨æµ‹è¯•åœºæ™¯é…ç½®ï¼Œç„¶åæ˜¯é€šç”¨çš„è¯„ä¼°é…ç½®ï¼Œæœ€åæ˜¯å¯èƒ½æ¥è‡ªè®­ç»ƒå™¨çš„è¦†ç›–é…ç½®
    final_config_for_eval = copy.deepcopy(EVALUATION_CONFIG)
    final_config_for_eval.update(config)
    if env_config_overrides:
        final_config_for_eval.update(env_config_overrides)

    env = WFactoryEnv(config=final_config_for_eval)
    
    # åŠ¨æ€é€‰æ‹©è¿­ä»£å™¨ï¼šäº¤äº’å¼ç»ˆç«¯ä½¿ç”¨tqdmï¼Œå¦åˆ™ä½¿ç”¨æ™®é€šrange
    is_tty = sys.stdout.isatty()
    iterator = range(NUM_EVAL_EPISODES)
    if is_tty:
        iterator = tqdm(iterator, desc=f"MARLæ¨¡å‹è¯„ä¼°({config_name})")

    start_time = time.time()
    for i in iterator:
        final_stats, score, history = run_single_episode(env, marl_policy, seed=i, config=config)
        all_kpis.append(final_stats)
        all_scores.append(score)
        if history is not None:
            first_episode_history = history
    
    if not is_tty:
        end_time = time.time()
        duration = end_time - start_time
        it_per_s = NUM_EVAL_EPISODES / duration if duration > 0 else float('inf')
        desc = f"MARLæ¨¡å‹è¯„ä¼°({config_name})"
        # æ‰‹åŠ¨æ ¼å¼åŒ–è¾“å‡ºï¼Œæ¨¡æ‹Ÿtqdmçš„æœ€ç»ˆè¡Œ
        print(f"{desc}: 100%|{'â–ˆ'*10}| {NUM_EVAL_EPISODES}/{NUM_EVAL_EPISODES} [{duration:.2f}s, {it_per_s:.2f}it/s]", file=sys.stdout, flush=True)

    # ç”Ÿæˆç”˜ç‰¹å›¾
    if generate_gantt and first_episode_history:
        generate_gantt_chart(first_episode_history, "MARL_PPO", config_name, output_dir=output_dir, run_name=run_name)

    env.close()
    
    return all_kpis, all_scores

def evaluate_heuristic(heuristic_name: str, config: dict = STATIC_EVAL_CONFIG, generate_gantt: bool = False, output_dir: str = None, run_name: str = None):
    """è¯„ä¼°å¯å‘å¼ç®—æ³•"""
    config_name = config.get('stage_name', 'æœªçŸ¥é…ç½®')
    print(f"âš™ï¸  å¼€å§‹è¯„ä¼°å¯å‘å¼ç®—æ³•: {heuristic_name}", flush=True)
    print(f"ğŸ“‹ æµ‹è¯•é…ç½®: {config_name}", flush=True)
    
    # ğŸ”§ æ–°å¢ï¼šæ˜¾ç¤ºè‡ªå®šä¹‰è®¢å•ä¿¡æ¯
    if 'custom_orders' in config:
        total_parts = sum(order["quantity"] for order in config['custom_orders'])
        print(f"ğŸ“¦ è‡ªå®šä¹‰è®¢å•: {len(config['custom_orders'])}ä¸ªè®¢å•, æ€»è®¡{total_parts}ä¸ªé›¶ä»¶", flush=True)

    # 10201530 ä¿®å¤ï¼šå¯å‘å¼ç­–ç•¥é€‚é…MultiDiscreteï¼Œè¿”å›æ¯ä¸ªè®¾å¤‡ä¸€ä¸ªåŠ¨ä½œ
    def heuristic_policy(obs, env, info, step_count):
        """
        ğŸŒŸ æ™ºèƒ½é€‚é…ç‰ˆï¼šè‡ªåŠ¨é€‚é…ä»»ä½•åŠ¨ä½œç©ºé—´ç»“æ„
        
        è®¾è®¡ç†å¿µï¼š
        1. ä¼˜å…ˆæ£€æµ‹åŠ¨ä½œç©ºé—´ä¸­æ˜¯å¦å­˜åœ¨å¯å‘å¼åŠ¨ä½œï¼ˆå‘åå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        2. å¦‚æœä¸å­˜åœ¨ï¼Œç‹¬ç«‹è®¡ç®—å¯å‘å¼é€»è¾‘å¹¶æ˜ å°„åˆ°å€™é€‰åŠ¨ä½œï¼ˆé€‚é…æ–°ç‰ˆæœ¬ï¼‰
        3. å®Œå…¨è§£è€¦å¯å‘å¼ç®—æ³•ä¸åŠ¨ä½œç©ºé—´è®¾è®¡
        
        è‡ªåŠ¨é€‚é…é€»è¾‘ï¼š
        - æ£€æŸ¥ACTION_CONFIG_ENHANCEDä¸­æ˜¯å¦æœ‰å¯¹åº”çš„å¯å‘å¼åŠ¨ä½œåç§°
        - å¦‚æœæœ‰ï¼šç›´æ¥ä½¿ç”¨è¯¥åŠ¨ä½œID
        - å¦‚æœæ²¡æœ‰ï¼šç‹¬ç«‹å®ç°å¯å‘å¼é€»è¾‘ + å€™é€‰æ˜ å°„
        """
        from environments.w_factory_env import calculate_slack_time
        
        sim = env.sim
        actions = {}
        
        # ğŸ”§ è‡ªåŠ¨æ£€æµ‹åŠ¨ä½œç©ºé—´ç»“æ„ï¼šä»ç¯å¢ƒå®ä¾‹è·å–ï¼Œè€Œä¸æ˜¯å…¨å±€å¯¼å…¥
        action_names = []
        
        # ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨ä¼ å…¥çš„infoå­—å…¸
        info_source = info

        if env.agents:
            first_agent = env.agents[0]
            if info_source and first_agent in info_source:
                action_names = info_source[first_agent].get('obs_meta', {}).get('action_names', [])

        action_map = {name: idx for idx, name in enumerate(action_names)}
        
        # å®šä¹‰å¯å‘å¼åç§°åˆ°åŠ¨ä½œåç§°çš„æ˜ å°„
        heuristic_to_action_map = {
            'FIFO': 'FIFO',
            'EDD': 'URGENT_EDD',
            'SPT': 'SHORT_SPT',
        }
        
        target_action_name = heuristic_to_action_map.get(heuristic_name)
        use_direct_action = (target_action_name in action_map)  # åŠ¨ä½œç©ºé—´ä¸­æ˜¯å¦å­˜åœ¨è¯¥å¯å‘å¼
        
        for agent_id in env.agents:
            station_name = agent_id.replace("agent_", "")
            queue = sim.queues[station_name].items
            
            if not queue:
                # 10201530 ä¿®å¤ï¼šMultiDiscreteéœ€è¦è¿”å›æ•°ç»„ï¼Œå…¨é›¶ä»£è¡¨å…¨éƒ¨IDLE
                sp = env.action_space(agent_id)
                if isinstance(sp, gym.spaces.MultiDiscrete):
                    actions[agent_id] = np.zeros(len(sp.nvec), dtype=sp.dtype)
                else:
                    actions[agent_id] = 0
                continue

            # ğŸ”§ åˆ†æ”¯1ï¼šåŠ¨ä½œç©ºé—´ä¸­å­˜åœ¨å¯å‘å¼åŠ¨ä½œï¼ˆæ—§ç‰ˆæœ¬ï¼‰
            if use_direct_action:
                sp = env.action_space(agent_id)
                if isinstance(sp, gym.spaces.MultiDiscrete):
                    k = len(sp.nvec)
                    actions[agent_id] = np.array([action_map[target_action_name]] * k, dtype=sp.dtype)
                else:
                    actions[agent_id] = action_map[target_action_name]
                continue
            
            # ğŸ”§ åˆ†æ”¯2ï¼šåŠ¨ä½œç©ºé—´ä¸­ä¸å­˜åœ¨å¯å‘å¼åŠ¨ä½œï¼ˆæ–°ç‰ˆæœ¬ - ç‹¬ç«‹å®ç°ï¼‰
            selected_parts = []
            
            if heuristic_name == 'FIFO':
                # FIFOï¼šé€‰æ‹©é˜Ÿé¦–å·¥ä»¶
                # FIFOï¼šç›´æ¥å–é˜Ÿé¦–ï¼Œé‡å¤kæ¬¡
                selected_parts = [queue[0]]
                
            elif heuristic_name == 'EDD':
                # EDDï¼šé€‰æ‹©æ¾å¼›æ—¶é—´æœ€å°çš„å·¥ä»¶
                # EDDï¼šæŒ‰slackä»å°åˆ°å¤§æ’åº
                parts_sorted = sorted(queue, key=lambda p: calculate_slack_time(p, sim.env.now, sim.queues))
                selected_parts = parts_sorted
                        
            elif heuristic_name == 'SPT':
                # SPTï¼šé€‰æ‹©åŠ å·¥æ—¶é—´æœ€çŸ­çš„å·¥ä»¶
                # SPTï¼šæŒ‰å½“å‰å·¥åºæ—¶é—´ä»å°åˆ°å¤§æ’åº
                parts_sorted = sorted(queue, key=lambda p: p.get_processing_time())
                selected_parts = parts_sorted
            else:
                raise ValueError(f"æœªçŸ¥çš„å¯å‘å¼è§„åˆ™: {heuristic_name}")
            
            # 10201530 ä¿®å¤ï¼šå°†å‰kä¸ªç›®æ ‡é›¶ä»¶æ˜ å°„ä¸ºMultiDiscreteåŠ¨ä½œæ•°ç»„
            candidates = sim._get_candidate_workpieces(station_name)
            sp = env.action_space(agent_id)
            if isinstance(sp, gym.spaces.MultiDiscrete):
                k = len(sp.nvec)
                chosen_actions = []
                used_part_ids = set()
                # æ˜ å°„ï¼šæ ¹æ®å€™é€‰åˆ—è¡¨æ‰¾åˆ°åŒ¹é…åŠ¨ä½œ
                for target_part in selected_parts:
                    if len(chosen_actions) >= k:
                        break
                    if target_part.part_id in used_part_ids:
                        continue
                    found = 0
                    for idx, cand in enumerate(candidates):
                        cand_part = cand.get("part") if isinstance(cand, dict) else cand[0]
                        if cand_part and cand_part.part_id == target_part.part_id:
                            candidate_action_start = next(
                                (i for i, name in enumerate(action_names) if "CANDIDATE_" in name),
                                1
                            )
                            found = candidate_action_start + idx
                            break
                    if found != 0:
                        chosen_actions.append(int(found))
                        used_part_ids.add(target_part.part_id)
                # è¡¥é½ä¸ºkä¸ªï¼ˆä¸è¶³æ—¶ç”¨IDLE=0ï¼‰
                while len(chosen_actions) < k:
                    chosen_actions.append(0)
                actions[agent_id] = np.array(chosen_actions, dtype=sp.dtype)
            else:
                # å•è®¾å¤‡ç¯å¢ƒï¼šå›é€€ä¸ºåŸæœ‰å•ä¸€åŠ¨ä½œé€»è¾‘
                action = 0
                if selected_parts:
                    target_part = selected_parts[0]
                    for idx, cand in enumerate(candidates):
                        cand_part = cand.get("part") if isinstance(cand, dict) else cand[0]
                        if cand_part and cand_part.part_id == target_part.part_id:
                            candidate_action_start = next(
                                (i for i, name in enumerate(action_names) if "CANDIDATE_" in name),
                                1
                            )
                            action = candidate_action_start + idx
                            break
                actions[agent_id] = action
            
        return actions

    # ğŸ”§ V4 ä¿®å¤ï¼šç›´æ¥é€šè¿‡configä¼ é€’è‡ªå®šä¹‰è®¢å•ï¼Œæ— éœ€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    all_kpis = []
    all_scores = []
    first_episode_history = None

    # åˆå¹¶é…ç½®ï¼Œç¡®ä¿è¯„ä¼°æ—¶ä½¿ç”¨ç¡®å®šæ€§å€™é€‰
    final_config_for_eval = copy.deepcopy(EVALUATION_CONFIG)
    final_config_for_eval.update(config)
    
    env = WFactoryEnv(config=final_config_for_eval)
    
    # åŠ¨æ€é€‰æ‹©è¿­ä»£å™¨ï¼šäº¤äº’å¼ç»ˆç«¯ä½¿ç”¨tqdmï¼Œå¦åˆ™ä½¿ç”¨æ™®é€šrange
    is_tty = sys.stdout.isatty()
    iterator = range(NUM_EVAL_EPISODES)
    if is_tty:
        iterator = tqdm(iterator, desc=f"{heuristic_name}è¯„ä¼°({config_name})")

    start_time = time.time()
    for i in iterator:
        final_stats, score, history = run_single_episode(env, heuristic_policy, seed=i, config=config)
        all_kpis.append(final_stats)
        all_scores.append(score)
        if history is not None:
            first_episode_history = history

    if not is_tty:
        end_time = time.time()
        duration = end_time - start_time
        it_per_s = NUM_EVAL_EPISODES / duration if duration > 0 else float('inf')
        desc = f"{heuristic_name}è¯„ä¼°({config_name})"
        # æ‰‹åŠ¨æ ¼å¼åŒ–è¾“å‡ºï¼Œæ¨¡æ‹Ÿtqdmçš„æœ€ç»ˆè¡Œ
        print(f"{desc}: 100%|{'â–ˆ'*10}| {NUM_EVAL_EPISODES}/{NUM_EVAL_EPISODES} [{duration:.2f}s, {it_per_s:.2f}it/s]", file=sys.stdout, flush=True)
    
    # ç”Ÿæˆç”˜ç‰¹å›¾
    if generate_gantt and first_episode_history:
        generate_gantt_chart(first_episode_history, heuristic_name, config_name, output_dir=output_dir, run_name=run_name)
        
    env.close()
    return all_kpis, all_scores

# =============================================================================
# 5. ç»“æœæ±‡æ€»ä¸å±•ç¤º (Result Aggregation & Display)
# =============================================================================

def aggregate_results(method_name: str, all_kpis: list, all_scores: list, config: dict = None):
    """æ±‡æ€»å¤šæ¬¡è¿è¡Œçš„ç»“æœï¼Œè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®"""
    if all_kpis is None:
        return {
            "Method": method_name,
            "Avg Score": "N/A",
            "Std Score": "N/A",
            "Avg Completion %": "N/A",
            "Avg Makespan": "N/A",
            "Avg Tardiness": "N/A",
            "Avg Utilization %": "N/A",
        }

    # ğŸŒŸ æ–°å¢ï¼šæ ¹æ®é…ç½®ç¡®å®šç›®æ ‡é›¶ä»¶æ•°
    if config and 'custom_orders' in config:
        target_parts = sum(order["quantity"] for order in config['custom_orders'])
    else:
        target_parts = get_total_parts_count()
        
    completion_rates = [(k['total_parts'] / target_parts) * 100 for k in all_kpis]
    
    return {
        "Method": method_name,
        "Avg Score": f"{np.mean(all_scores):.3f}",
        "Std Score": f"{np.std(all_scores):.3f}",
        "Avg Completion %": f"{np.mean(completion_rates):.1f}",
        "Avg Makespan": f"{np.mean([k['makespan'] for k in all_kpis]):.1f}",
        "Avg Tardiness": f"{np.mean([k['total_tardiness'] for k in all_kpis]):.1f}",
        "Avg Utilization %": f"{np.mean([k['mean_utilization'] for k in all_kpis]) * 100:.1f}",
    }

def run_comprehensive_evaluation(model_path: str, generate_gantt: bool = False, output_dir: str = None, run_name: str = None):
    """è¿è¡Œç»¼åˆè¯„ä¼°ï¼šåŒ…æ‹¬åŸºå‡†æµ‹è¯•å’Œæ³›åŒ–èƒ½åŠ›æµ‹è¯•"""
    
    print("="*80, flush=True)
    print("ğŸš€ å¼€å§‹è¿›è¡Œé™æ€ç¯å¢ƒä¸‹çš„è°ƒåº¦ç­–ç•¥ç»¼åˆè¯„ä¼°", flush=True)
    print(f"ğŸ” æ¯ä¸ªç­–ç•¥å°†ç‹¬ç«‹è¿è¡Œ {NUM_EVAL_EPISODES} æ¬¡ä»¥è·å–å¯é çš„ç»Ÿè®¡ç»“æœã€‚", flush=True)
    print("="*80, flush=True)

    # æµ‹è¯•é…ç½®åˆ—è¡¨
    test_configs = [
        ("åŸºå‡†æµ‹è¯•", STATIC_EVAL_CONFIG),
        ("æ³›åŒ–æµ‹è¯•1-é«˜å‹åŠ›çŸ­äº¤æœŸ", GENERALIZATION_CONFIG_1),
        ("æ³›åŒ–æµ‹è¯•2-æ··åˆä¼˜å…ˆçº§", GENERALIZATION_CONFIG_2),
        ("æ³›åŒ–æµ‹è¯•3-å¤§æ‰¹é‡é•¿å‘¨æœŸ", GENERALIZATION_CONFIG_3),
    ]
    
    all_results = []
    
    for test_name, config in test_configs:
        print(f"\nğŸ”¬ å¼€å§‹ {test_name}", flush=True)
        print("="*60, flush=True)
        
        # ğŸ”§ V4 ä¿®å¤ï¼šç›´æ¥ä¼ é€’configï¼Œæ— éœ€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        # 1. è¯„ä¼°MARLæ¨¡å‹
        marl_kpis, marl_scores = evaluate_marl_model(model_path, config, generate_gantt=generate_gantt, output_dir=output_dir, run_name=run_name)
        
        # 2. è¯„ä¼°å¯å‘å¼ç®—æ³• (ç”˜ç‰¹å›¾ä¿å­˜åˆ°çˆ¶ç›®å½•)
        heuristic_output_dir = os.path.dirname(output_dir) if output_dir else None
        fifo_kpis, fifo_scores = evaluate_heuristic('FIFO', config, generate_gantt=generate_gantt, output_dir=heuristic_output_dir, run_name=run_name)
        edd_kpis, edd_scores = evaluate_heuristic('EDD', config, generate_gantt=generate_gantt, output_dir=heuristic_output_dir, run_name=run_name)
        spt_kpis, spt_scores = evaluate_heuristic('SPT', config, generate_gantt=generate_gantt, output_dir=heuristic_output_dir, run_name=run_name)

        # 3. æ±‡æ€»ç»“æœ
        results = [
            aggregate_results("MARL (PPO)", marl_kpis, marl_scores, config),
            aggregate_results("SPT", spt_kpis, spt_scores, config),
            aggregate_results("EDD", edd_kpis, edd_scores, config),
            aggregate_results("FIFO", fifo_kpis, fifo_scores, config),
        ]
        
        # 4. æ‰“å°å½“å‰æµ‹è¯•ç»“æœ
        df = pd.DataFrame(results)
        print(f"\nğŸ† {test_name} - è¯„ä¼°å¯¹æ¯”ç»“æœ", flush=True)
        print("-"*60, flush=True)
        print(df.to_string(index=False), flush=True)
        
        # ä¿å­˜ç»“æœç”¨äºæœ€ç»ˆæ±‡æ€»
        for result in results:
            result['Test_Config'] = test_name
        all_results.extend(results)
        
        print("\n" + "="*60, flush=True)
    
    # 5. ç”Ÿæˆæœ€ç»ˆæ±‡æ€»æŠ¥å‘Š
    print(f"\nğŸ¯ æœ€ç»ˆæ±‡æ€»æŠ¥å‘Š - æ³›åŒ–èƒ½åŠ›åˆ†æ", flush=True)
    print("="*80, flush=True)
    
    # æŒ‰æ–¹æ³•åˆ†ç»„å±•ç¤ºç»“æœ
    methods = ["MARL (PPO)", "SPT", "EDD", "FIFO"]
    
    for method in methods:
        method_results = [r for r in all_results if r['Method'] == method]
        if method_results:
            print(f"\nğŸ“Š {method} åœ¨ä¸åŒæµ‹è¯•é…ç½®ä¸‹çš„è¡¨ç°:", flush=True)
            method_df = pd.DataFrame(method_results)
            # é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼ŒæŠŠTest_Configæ”¾åœ¨å‰é¢
            cols = ['Test_Config'] + [col for col in method_df.columns if col != 'Test_Config']
            method_df = method_df[cols]
            print(method_df.to_string(index=False), flush=True)

def main():
    parser = argparse.ArgumentParser(description="è¯„ä¼°MARLæ¨¡å‹ä¸å¯å‘å¼ç®—æ³•çš„æ€§èƒ½")
    parser.add_argument(
        "--model_path", 
        type=str, 
        required=True,
        help="æŒ‡å‘å·²è®­ç»ƒå¥½çš„MARL actoræ¨¡å‹æ–‡ä»¶ (.keras) çš„è·¯å¾„"
    )
    parser.add_argument(
        "--generalization", 
        action="store_true",
        help="æ˜¯å¦è¿›è¡Œæ³›åŒ–èƒ½åŠ›æµ‹è¯• (é»˜è®¤åªè¿›è¡ŒåŸºå‡†æµ‹è¯•)"
    )
    parser.add_argument(
        "--gantt",
        action="store_true",
        help="æ˜¯å¦ä¸ºæ¯ä¸ªè¯„ä¼°åœºæ™¯ç”Ÿæˆè¯¦ç»†çš„è°ƒåº¦ç”˜ç‰¹å›¾"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default=None,
        help="æŒ‡å®šä¸€ä¸ªç›®å½•æ¥å­˜æ”¾æ‰€æœ‰è¾“å‡ºçš„ç”˜ç‰¹å›¾æ–‡ä»¶"
    )
    parser.add_argument(
        "--run_name",
        type=str,
        default=None,
        help="ä¸ºæœ¬æ¬¡è¿è¡Œæä¾›ä¸€ä¸ªåç§°ï¼Œå°†ç”¨ä½œç”˜ç‰¹å›¾æ–‡ä»¶åçš„å‰ç¼€"
    )
    args = parser.parse_args()

    if args.generalization:
        # è¿è¡Œå®Œæ•´çš„æ³›åŒ–èƒ½åŠ›æµ‹è¯•
        run_comprehensive_evaluation(args.model_path, generate_gantt=args.gantt, output_dir=args.output_dir, run_name=args.run_name)
    else:
        # ä»…è¿è¡ŒåŸºå‡†æµ‹è¯• (åŸæœ‰åŠŸèƒ½)
        print("="*80, flush=True)
        print("ğŸš€ å¼€å§‹è¿›è¡Œé™æ€ç¯å¢ƒä¸‹çš„è°ƒåº¦ç­–ç•¥ç»¼åˆè¯„ä¼°", flush=True)
        print(f"ğŸ” æ¯ä¸ªç­–ç•¥å°†ç‹¬ç«‹è¿è¡Œ {NUM_EVAL_EPISODES} æ¬¡ä»¥è·å–å¯é çš„ç»Ÿè®¡ç»“æœã€‚", flush=True)
        print("="*80, flush=True)

        # 1. è¯„ä¼°MARLæ¨¡å‹
        marl_kpis, marl_scores = evaluate_marl_model(args.model_path, generate_gantt=args.gantt, output_dir=args.output_dir, run_name=args.run_name)
        
        # 2. è¯„ä¼°å¯å‘å¼ç®—æ³• (ç”˜ç‰¹å›¾ä¿å­˜åˆ°çˆ¶ç›®å½•)
        heuristic_output_dir = os.path.dirname(args.output_dir) if args.output_dir else None
        fifo_kpis, fifo_scores = evaluate_heuristic('FIFO', generate_gantt=args.gantt, output_dir=heuristic_output_dir, run_name=args.run_name)
        edd_kpis, edd_scores = evaluate_heuristic('EDD', generate_gantt=args.gantt, output_dir=heuristic_output_dir, run_name=args.run_name)
        spt_kpis, spt_scores = evaluate_heuristic('SPT', generate_gantt=args.gantt, output_dir=heuristic_output_dir, run_name=args.run_name)

        # 3. æ±‡æ€»ç»“æœ
        results = [
            aggregate_results("MARL (PPO)", marl_kpis, marl_scores),
            aggregate_results("SPT", spt_kpis, spt_scores),
            aggregate_results("EDD", edd_kpis, edd_scores),
            aggregate_results("FIFO", fifo_kpis, fifo_scores),
        ]
        
        # 4. åˆ›å»ºå¹¶æ‰“å°ç»“æœè¡¨æ ¼
        df = pd.DataFrame(results)
        
        print("\n" + "="*80, flush=True)
        print("ğŸ† æœ€ç»ˆè¯„ä¼°å¯¹æ¯”ç»“æœ", flush=True)
        print("="*80, flush=True)
        print(df.to_string(index=False), flush=True)
        print("="*80, flush=True)


if __name__ == "__main__":
    main()
