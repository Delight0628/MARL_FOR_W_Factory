import os
import sys

# è®¾å¤‡é€‰æ‹©ï¼šé»˜è®¤å…è®¸ä½¿ç”¨å¯ç”¨GPUï¼›è‹¥éœ€å¼ºåˆ¶CPUï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ FORCE_CPU=1
if os.environ.get('FORCE_CPU', '0') == '1':
    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # å±è”½TensorFlowçš„INFOçº§åˆ«æ—¥å¿—

import numpy as np
import tensorflow as tf
import random
# å…¼å®¹ TF 2.10ï¼šä½¿ç”¨ä¼ ç»Ÿæ–¹å¼è®¾ç§å­ï¼Œé¿å…ä¾èµ– keras3 çš„ stateless RNG
random.seed(42)
np.random.seed(42)
tf.random.set_seed(42)
import pandas as pd
from tqdm import tqdm
import argparse
import contextlib
import time # å¯¼å…¥timeæ¨¡å—
import copy

from plotting import generate_gantt_chart

# æ·»åŠ ç¯å¢ƒè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

from environments.w_factory_env import WFactoryEnv
from environments.w_factory_config import (
    get_total_parts_count, SIMULATION_TIME, BASE_ORDERS,
    calculate_episode_score, EVALUATION_CONFIG
)
# 10201530 æ–°å¢ï¼šå¯¼å…¥gymä»¥è¯†åˆ«MultiDiscreteåŠ¨ä½œç©ºé—´
import gymnasium as gym
import json

# =============================================================================
# 0. TensorFlow 2.15.0 å…¼å®¹ï¼šå¥å£®çš„æ¨¡å‹åŠ è½½å‡½æ•°
# =============================================================================

def load_actor_model_robust(model_path: str):
    """
    å¥å£®çš„æ¨¡å‹åŠ è½½å‡½æ•° - TensorFlow 2.15.0 å…¼å®¹ç‰ˆæœ¬
    æ”¯æŒå¤šç§åŠ è½½ç­–ç•¥ï¼š.keras -> .h5 -> weights+metaé‡å»º
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆå¯ä»¥æ˜¯.kerasæˆ–.h5æˆ–åŸºç¡€è·¯å¾„ï¼‰
    
    Returns:
        åŠ è½½çš„Actoræ¨¡å‹ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
    """
    base_path = model_path.replace('.keras', '').replace('.h5', '').replace('_actor', '')
    
    # ç­–ç•¥1ï¼šä¼˜å…ˆå°è¯•H5æ ¼å¼ï¼ˆæœ€ç¨³å®šï¼‰
    h5_paths = [
        f"{base_path}_actor.h5",
        model_path if model_path.endswith('.h5') else None
    ]
    
    for h5_path in h5_paths:
        if h5_path and os.path.exists(h5_path):
            try:
                print(f"ğŸ”„ ä»H5æ ¼å¼åŠ è½½: {h5_path}", flush=True)
                model = tf.keras.models.load_model(h5_path, compile=False)
                print(f"âœ… æˆåŠŸä»H5æ ¼å¼åŠ è½½æ¨¡å‹", flush=True)
                return model
            except Exception as e:
                print(f"âš ï¸ H5åŠ è½½å¤±è´¥: {e}", flush=True)
    
    # ç­–ç•¥2ï¼šä»æƒé‡+å…ƒæ•°æ®é‡å»º
    meta_path = f"{base_path}_meta.json"
    weights_path = f"{base_path}_actor_weights.h5"
    
    if os.path.exists(meta_path) and os.path.exists(weights_path):
        try:
            print(f"ğŸ”„ ä»æƒé‡+å…ƒæ•°æ®é‡å»ºæ¨¡å‹", flush=True)
            print(f"ğŸ“„ [è°ƒè¯•] metaæ–‡ä»¶: {meta_path}", flush=True)
            print(f"ğŸ“¦ [è°ƒè¯•] weightsæ–‡ä»¶: {weights_path}", flush=True)
            
            with open(meta_path, 'r', encoding='utf-8') as f:
                meta = json.load(f)
            # å…³é”®è°ƒè¯•è¾“å‡ºï¼šæ ¸å¯¹ç»´åº¦ä¸ç½‘ç»œé…ç½®
            try:
                print(
                    "[META] state_dim=", meta.get('state_dim'),
                    " global_state_dim=", meta.get('global_state_dim'),
                    " action_space=", meta.get('action_space'),
                    " hidden_sizes=", (meta.get('network_config') or {}).get('hidden_sizes'),
                    flush=True
                )
            except Exception:
                pass

            # æ–°å¢ï¼šä¸å½“å‰ç¯å¢ƒç»´åº¦åšä¸€è‡´æ€§å¯¹æ¯”ï¼Œè‹¥ä¸ä¸€è‡´åˆ™ç›´æ¥æŠ¥é”™å¹¶ä¸­æ­¢
            try:
                _cmp_env = WFactoryEnv(config=EVALUATION_CONFIG)
                first_agent = _cmp_env.possible_agents[0]
                cur_state_dim = int(_cmp_env.observation_space(first_agent).shape[0])
                cur_action_space = _cmp_env.action_space(first_agent)
                base_global_dim = int(_cmp_env.global_state_space.shape[0])
                num_agents = int(len(_cmp_env.possible_agents))
                conditioned_global_dim = base_global_dim + num_agents
                if isinstance(cur_action_space, gym.spaces.MultiDiscrete):
                    cur_action = { 'type': 'MultiDiscrete', 'nvec': [int(x) for x in cur_action_space.nvec], 'n': None }
                else:
                    cur_action = { 'type': 'Discrete', 'nvec': None, 'n': int(cur_action_space.n) }
                _cmp_env.close()

                mismatches = []
                meta_state_dim = int(meta.get('state_dim'))
                if meta_state_dim != cur_state_dim:
                    mismatches.append(f"state_dim: meta={meta_state_dim}, current={cur_state_dim}")

                meta_global = int(meta.get('global_state_dim'))
                if meta_global != base_global_dim and meta_global != conditioned_global_dim:
                    mismatches.append(
                        f"global_state_dim: meta={meta_global}, current_base={base_global_dim}, current_conditioned={conditioned_global_dim}"
                    )

                meta_action = meta.get('action_space', {})
                meta_type = meta_action.get('type')
                if meta_type != cur_action['type']:
                    mismatches.append(f"action_space.type: meta={meta_type}, current={cur_action['type']}")
                else:
                    if meta_type == 'MultiDiscrete':
                        m_nvec = [int(x) for x in (meta_action.get('nvec') or [])]
                        if m_nvec != cur_action['nvec']:
                            mismatches.append(f"action_space.nvec: meta={m_nvec}, current={cur_action['nvec']}")
                    else:
                        m_n = int(meta_action.get('n')) if meta_action.get('n') is not None else None
                        if m_n != cur_action['n']:
                            mismatches.append(f"action_space.n: meta={m_n}, current={cur_action['n']}")

                if mismatches:
                    print("âŒ ç»´åº¦ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥ï¼Œæ‹’ç»åŠ è½½æ¨¡å‹ä»¥é¿å…å½¢çŠ¶é”™è¯¯:", flush=True)
                    for item in mismatches:
                        print(f"   - {item}", flush=True)
                    print("ğŸ“Œ è¯·ç¡®ä¿è®­ç»ƒä¸è¯„ä¼°ç¯å¢ƒ/ç½‘ç»œé…ç½®å®Œå…¨ä¸€è‡´ï¼Œæˆ–é‡æ–°è®­ç»ƒç”ŸæˆåŒ¹é…çš„æ¨¡å‹ã€‚", flush=True)
                    raise RuntimeError("æ¨¡å‹å…ƒæ•°æ®ä¸å½“å‰ç¯å¢ƒä¸ä¸€è‡´")
            except Exception as _cmp_e:
                # è‹¥å¯¹æ¯”è¿‡ç¨‹è‡ªèº«å‡ºé”™ï¼Œä¹Ÿæ‰“å°å‡ºæ¥ä¾¿äºå®šä½
                print(f"âš ï¸ ç»´åº¦å¯¹æ¯”è¿‡ç¨‹å¼‚å¸¸: {_cmp_e}", flush=True)
            
            # é‡å»ºæ¨¡å‹æ¶æ„
            from mappo.ppo_marl_train import PPONetwork
            
            action_space_meta = meta['action_space']
            if action_space_meta['type'] == 'MultiDiscrete':
                action_space = gym.spaces.MultiDiscrete(action_space_meta['nvec'])
            else:
                action_space = gym.spaces.Discrete(action_space_meta['n'])
            
            def _build_and_load_on(device_ctx=None):
                if device_ctx is None:
                    net = PPONetwork(
                        state_dim=int(meta['state_dim']),
                        action_space=action_space,
                        lr=None,
                        global_state_dim=int(meta['global_state_dim']),
                        network_config=meta.get('network_config')
                    )
                    net.actor.load_weights(weights_path)
                    return net.actor
                else:
                    with device_ctx:
                        net = PPONetwork(
                            state_dim=int(meta['state_dim']),
                            action_space=action_space,
                            lr=None,
                            global_state_dim=int(meta['global_state_dim']),
                            network_config=meta.get('network_config')
                        )
                        net.actor.load_weights(weights_path)
                        return net.actor

            try:
                actor_model = _build_and_load_on()
                print(f"âœ… æˆåŠŸä»æƒé‡+å…ƒæ•°æ®é‡å»ºæ¨¡å‹", flush=True)
                return actor_model
            except Exception as e_build:
                print(f"âš ï¸ CPUé‡å»ºå¤±è´¥: {e_build}", flush=True)
                # é’ˆå¯¹ vector::_M_range_check å°è¯• GPU å›é€€
                if 'vector::_M_range_check' in str(e_build):
                    try:
                        gpus = tf.config.list_physical_devices('GPU')
                        if gpus and os.environ.get('CUDA_VISIBLE_DEVICES', '') != '-1':
                            print("âš¡ å°è¯•åœ¨GPUä¸Šé‡å»ºæ¨¡å‹ä»¥è§„é¿CPUåˆå§‹åŒ–é—®é¢˜...", flush=True)
                            actor_model = _build_and_load_on(tf.device('/GPU:0'))
                            print("âœ… GPUé‡å»ºæˆåŠŸ", flush=True)
                            return actor_model
                    except Exception as e_gpu:
                        print(f"âŒ GPUå›é€€ä¹Ÿå¤±è´¥: {e_gpu}", flush=True)
                # è‹¥ä¸æ˜¯è¯¥é”™è¯¯æˆ–GPUä¹Ÿå¤±è´¥ï¼Œç»§ç»­æŠ›å‡ºè®©å¤–å±‚å¤„ç†
                raise
            
        except Exception as e:
            print(f"âŒ é‡å»ºå¤±è´¥: {e}", flush=True)
            import traceback
            traceback.print_exc()
    else:
        if not os.path.exists(meta_path):
            print(f"âŒ [è°ƒè¯•] metaæ–‡ä»¶ä¸å­˜åœ¨ï¼", flush=True)
        if not os.path.exists(weights_path):
            print(f"âŒ [è°ƒè¯•] weightsæ–‡ä»¶ä¸å­˜åœ¨ï¼", flush=True)
    
    # ç­–ç•¥3ï¼šå°è¯•.kerasæ ¼å¼ï¼ˆæœ€åçš„æ‰‹æ®µï¼‰
    keras_paths = [
        f"{base_path}_actor.keras",
        model_path if model_path.endswith('.keras') else None
    ]
    
    for keras_path in keras_paths:
        if keras_path and os.path.exists(keras_path):
            try:
                print(f"ğŸ”„ å°è¯•Kerasæ ¼å¼: {keras_path}", flush=True)
                model = tf.keras.models.load_model(keras_path, compile=False)
                print(f"âœ… æˆåŠŸä»Kerasæ ¼å¼åŠ è½½æ¨¡å‹", flush=True)
                return model
            except Exception as e:
                print(f"âš ï¸ .kerasæ–‡ä»¶åŠ è½½å¤±è´¥: {e}", flush=True)
    
    print(f"âŒ æ‰€æœ‰åŠ è½½ç­–ç•¥å‡å¤±è´¥", flush=True)
    print(f"ğŸ’¡ æç¤º: è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å®Œæ•´ï¼ŒåŒ…æ‹¬ .h5, _weights.h5, å’Œ _meta.json", flush=True)
    return None

# =============================================================================
# 1. æ ¸å¿ƒé…ç½® (Core Configuration)
# =============================================================================
NUM_EVAL_EPISODES = 1 

# é™æ€è¯„ä¼°ç¯å¢ƒé…ç½® (ç¡®ä¿å…¬å¹³å¯¹æ¯”)
# ä½¿ç”¨100%è®¢å•ï¼Œæ ‡å‡†æ—¶é—´ï¼Œä¸”ç¦ç”¨æ‰€æœ‰éšæœºäº‹ä»¶
STATIC_EVAL_CONFIG = {
    'orders_scale': 1.0,
    'time_scale': 1.0,
    'disable_failures': True, # æ˜ç¡®ç¦ç”¨è®¾å¤‡æ•…éšœ
    'stage_name': 'é™æ€è¯„ä¼°'
}

# =============================================================================
# ğŸŒŸ æ–°å¢ï¼šæ³›åŒ–èƒ½åŠ›æµ‹è¯•è®¢å•é…ç½® (Generalization Test Configurations) é…ç½®æ˜¯å¦åˆç†
# =============================================================================

# æµ‹è¯•é…ç½®1ï¼šé«˜å‹åŠ›çŸ­äº¤æœŸåœºæ™¯
GENERALIZATION_CONFIG_1 = {
    'custom_orders': [
        # ç´§æ€¥å°æ‰¹é‡è®¢å• - æµ‹è¯•æ¨¡å‹å¯¹æ—¶é—´å‹åŠ›çš„åº”å¯¹
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 8, "priority": 1, "due_date": 200.0},
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 6, "priority": 1, "due_date": 180.0},
        {"product": "æ¾æœ¨åºŠæ¶", "quantity": 10, "priority": 2, "due_date": 250.0},
        {"product": "æ¨±æ¡ƒæœ¨æ¤…å­", "quantity": 12, "priority": 1, "due_date": 300.0},
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 6, "priority": 3, "due_date": 400.0},
    ],
    'disable_failures': True,
    'stage_name': 'æ³›åŒ–æµ‹è¯•1-é«˜å‹åŠ›çŸ­äº¤æœŸ'
}

# æµ‹è¯•é…ç½®2ï¼šæ··åˆä¼˜å…ˆçº§å¤æ‚åœºæ™¯
GENERALIZATION_CONFIG_2 = {
    'custom_orders': [
        # ä¸åŒä¼˜å…ˆçº§å’Œè§„æ¨¡çš„æ··åˆè®¢å• - æµ‹è¯•ä¼˜å…ˆçº§å¹³è¡¡èƒ½åŠ›
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 15, "priority": 2, "due_date": 450.0},
        {"product": "æ¨±æ¡ƒæœ¨æ¤…å­", "quantity": 8, "priority": 1, "due_date": 350.0},
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 20, "priority": 3, "due_date": 600.0},
        {"product": "æ¾æœ¨åºŠæ¶", "quantity": 5, "priority": 1, "due_date": 280.0},
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 12, "priority": 2, "due_date": 520.0},
    ],
    'disable_failures': True,
    'stage_name': 'æ³›åŒ–æµ‹è¯•2-æ··åˆä¼˜å…ˆçº§'
}

# æµ‹è¯•é…ç½®3ï¼šå¤§æ‰¹é‡é•¿å‘¨æœŸåœºæ™¯
GENERALIZATION_CONFIG_3 = {
    'custom_orders': [
        # å¤§æ‰¹é‡é•¿å‘¨æœŸè®¢å• - æµ‹è¯•èµ„æºè°ƒåº¦å’Œé•¿æœŸè§„åˆ’èƒ½åŠ›
        {"product": "é»‘èƒ¡æ¡ƒæœ¨é¤æ¡Œ", "quantity": 25, "priority": 2, "due_date": 800.0},
        {"product": "æ¾æœ¨åºŠæ¶", "quantity": 18, "priority": 1, "due_date": 700.0},
        {"product": "æ¨±æ¡ƒæœ¨æ¤…å­", "quantity": 22, "priority": 3, "due_date": 900.0},
        {"product": "æ©¡æœ¨ä¹¦æŸœ", "quantity": 15, "priority": 2, "due_date": 750.0},
    ],
    'disable_failures': True,
    'stage_name': 'æ³›åŒ–æµ‹è¯•3-å¤§æ‰¹é‡é•¿å‘¨æœŸ'
}

# =============================================================================
# 3. ç¯å¢ƒåˆ›å»ºä¸é…ç½® (Environment Creation & Configuration)
# =============================================================================



# =============================================================================
# 4. è¯„ä¼°æ‰§è¡Œå™¨ (Evaluation Runners)
# =============================================================================

def run_single_episode(env: WFactoryEnv, policy_fn, seed: int, config: dict = None):
    """è¿è¡Œå•æ¬¡å›åˆçš„é€šç”¨å‡½æ•°"""
    obs, info = env.reset(seed=seed)
    step_count = 0
    
    while step_count < 1500: # ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´çš„æœ€å¤§æ­¥æ•°
        # ä¿®å¤ï¼šå°† info å’Œ step_count ä¼ é€’ç»™ç­–ç•¥å‡½æ•°
        actions = policy_fn(obs, env, info, step_count)
        obs, rewards, terminations, truncations, info = env.step(actions)
        step_count += 1
        
        if any(terminations.values()) or any(truncations.values()):
            break
            
    final_stats = env.sim.get_final_stats()
    score = calculate_episode_score(final_stats, config)
    
    # ä»…åœ¨ç¬¬ä¸€ä¸ªå›åˆï¼ˆseed=0ï¼‰è¿”å›è¯¦ç»†çš„åŠ å·¥å†å²
    history = env.sim.gantt_chart_history if seed == 0 else None
    
    return final_stats, score, history

def evaluate_marl_model(model_path: str, config: dict = STATIC_EVAL_CONFIG, generate_gantt: bool = False, output_dir: str = None, run_name: str = None, env_config_overrides: dict = None):
    """è¯„ä¼°MARLæ¨¡å‹"""
    config_name = config.get('stage_name', 'æœªçŸ¥é…ç½®')
    print(f"ğŸ§  å¼€å§‹è¯„ä¼°MARLæ¨¡å‹: {model_path}", flush=True)
    print(f"ğŸ“‹ æµ‹è¯•é…ç½®: {config_name}", flush=True)
    
    # ğŸ”§ æ–°å¢ï¼šæ˜¾ç¤ºè‡ªå®šä¹‰è®¢å•ä¿¡æ¯
    if 'custom_orders' in config:
        total_parts = sum(order["quantity"] for order in config['custom_orders'])
        print(f"ğŸ“¦ è‡ªå®šä¹‰è®¢å•: {len(config['custom_orders'])}ä¸ªè®¢å•, æ€»è®¡{total_parts}ä¸ªé›¶ä»¶", flush=True)
    
    # 10-26-16-00 TensorFlow 2.15.0å…¼å®¹ï¼šä½¿ç”¨å¥å£®çš„åŠ è½½å‡½æ•°
    actor_model = load_actor_model_robust(model_path)
    if actor_model is None:
        return None, None

    # 10201530 ä¿®å¤ï¼šMARLç­–ç•¥é€‚é…MultiDiscreteï¼ŒæŒ‰â€œå…±äº«åˆ†å¸ƒÃ—å¹¶è¡Œè®¾å¤‡æ•°â€è¾“å‡ºåŠ¨ä½œæ•°ç»„
    def marl_policy(obs, env, info, step_count):
        def choose_parallel_actions_multihead(head_probs_list, num_heads: int) -> np.ndarray:
            chosen = []
            used = set()
            for i in range(num_heads):
                if isinstance(head_probs_list, (list, tuple)) and len(head_probs_list) > i:
                    p = np.squeeze(np.asarray(head_probs_list[i], dtype=np.float64))
                else:
                    base = head_probs_list[0] if isinstance(head_probs_list, (list, tuple)) else head_probs_list
                    p = np.squeeze(np.asarray(base, dtype=np.float64))
                p = np.clip(p, 1e-12, np.inf)
                if used:
                    idxs = list(used)
                    p[idxs] = 0.0
                s = p.sum()
                if s <= 1e-12:
                    idx = 0
                else:
                    p = p / s
                    idx = int(np.argmax(p))  # è¯„ä¼°ä½¿ç”¨ç¡®å®šæ€§è´ªå¿ƒ
                chosen.append(idx)
                used.add(idx)
            return np.array(chosen, dtype=np.int32)

        actions = {}
        for agent in env.agents:
            if agent in obs:
                state = tf.expand_dims(obs[agent], 0)
                # 10-25-14-30 å…¼å®¹å¤šå¤´/å•å¤´è¾“å‡ºï¼Œæ¨ç†æ¨¡å¼
                model_out = actor_model(state, training=False)
                if isinstance(model_out, (list, tuple)):
                    head_probs_list = [np.squeeze(h.numpy()) for h in model_out]
                else:
                    head_probs_list = [np.squeeze(model_out.numpy()[0])]
                space = env.action_space(agent)
                if isinstance(space, gym.spaces.MultiDiscrete):
                    k = len(space.nvec)
                    chosen = choose_parallel_actions_multihead(head_probs_list, k)
                    actions[agent] = np.array(chosen, dtype=space.dtype)
                else:
                    p = np.asarray(head_probs_list[0], dtype=np.float64)
                    p = np.clip(p, 1e-12, np.inf)
                    actions[agent] = int(np.argmax(p))
        return actions

    # ğŸ”§ V4 ä¿®å¤ï¼šç›´æ¥é€šè¿‡configä¼ é€’è‡ªå®šä¹‰è®¢å•ï¼Œæ— éœ€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    all_kpis = []
    all_scores = []
    first_episode_history = None

    # ğŸ”§ å…³é”®ä¿®å¤ V2: åˆå¹¶æ¥è‡ªä¼˜åŒ–å™¨çš„åŸºç¡€é…ç½®å’Œè¯„ä¼°åœºæ™¯çš„ç‰¹å®šé…ç½®
    # ä¼˜å…ˆä½¿ç”¨æµ‹è¯•åœºæ™¯é…ç½®ï¼Œç„¶åæ˜¯é€šç”¨çš„è¯„ä¼°é…ç½®ï¼Œæœ€åæ˜¯å¯èƒ½æ¥è‡ªè®­ç»ƒå™¨çš„è¦†ç›–é…ç½®
    final_config_for_eval = copy.deepcopy(EVALUATION_CONFIG)
    final_config_for_eval.update(config)
    if env_config_overrides:
        final_config_for_eval.update(env_config_overrides)

    env = WFactoryEnv(config=final_config_for_eval)
    
    # åŠ¨æ€é€‰æ‹©è¿­ä»£å™¨ï¼šäº¤äº’å¼ç»ˆç«¯ä½¿ç”¨tqdmï¼Œå¦åˆ™ä½¿ç”¨æ™®é€šrange
    is_tty = sys.stdout.isatty()
    iterator = range(NUM_EVAL_EPISODES)
    if is_tty:
        iterator = tqdm(iterator, desc=f"MARLæ¨¡å‹è¯„ä¼°({config_name})")

    start_time = time.time()
    for i in iterator:
        final_stats, score, history = run_single_episode(env, marl_policy, seed=i, config=config)
        all_kpis.append(final_stats)
        all_scores.append(score)
        if history is not None:
            first_episode_history = history
    
    if not is_tty:
        end_time = time.time()
        duration = end_time - start_time
        it_per_s = NUM_EVAL_EPISODES / duration if duration > 0 else float('inf')
        desc = f"MARLæ¨¡å‹è¯„ä¼°({config_name})"
        # æ‰‹åŠ¨æ ¼å¼åŒ–è¾“å‡ºï¼Œæ¨¡æ‹Ÿtqdmçš„æœ€ç»ˆè¡Œ
        print(f"{desc}: 100%|{'â–ˆ'*10}| {NUM_EVAL_EPISODES}/{NUM_EVAL_EPISODES} [{duration:.2f}s, {it_per_s:.2f}it/s]", file=sys.stdout, flush=True)

    # ç”Ÿæˆç”˜ç‰¹å›¾
    if generate_gantt and first_episode_history:
        generate_gantt_chart(first_episode_history, "MARL_PPO", config_name, output_dir=output_dir, run_name=run_name)

    env.close()
    
    return all_kpis, all_scores

def evaluate_heuristic(heuristic_name: str, config: dict = STATIC_EVAL_CONFIG, generate_gantt: bool = False, output_dir: str = None, run_name: str = None):
    """è¯„ä¼°å¯å‘å¼ç®—æ³•"""
    config_name = config.get('stage_name', 'æœªçŸ¥é…ç½®')
    print(f"âš™ï¸  å¼€å§‹è¯„ä¼°å¯å‘å¼ç®—æ³•: {heuristic_name}", flush=True)
    print(f"ğŸ“‹ æµ‹è¯•é…ç½®: {config_name}", flush=True)
    
    # ğŸ”§ æ–°å¢ï¼šæ˜¾ç¤ºè‡ªå®šä¹‰è®¢å•ä¿¡æ¯
    if 'custom_orders' in config:
        total_parts = sum(order["quantity"] for order in config['custom_orders'])
        print(f"ğŸ“¦ è‡ªå®šä¹‰è®¢å•: {len(config['custom_orders'])}ä¸ªè®¢å•, æ€»è®¡{total_parts}ä¸ªé›¶ä»¶", flush=True)

    # 10201530 ä¿®å¤ï¼šå¯å‘å¼ç­–ç•¥é€‚é…MultiDiscreteï¼Œè¿”å›æ¯ä¸ªè®¾å¤‡ä¸€ä¸ªåŠ¨ä½œ
    def heuristic_policy(obs, env, info, step_count):
        """
        ğŸŒŸ æ™ºèƒ½é€‚é…ç‰ˆï¼šè‡ªåŠ¨é€‚é…ä»»ä½•åŠ¨ä½œç©ºé—´ç»“æ„
        
        è®¾è®¡ç†å¿µï¼š
        1. ä¼˜å…ˆæ£€æµ‹åŠ¨ä½œç©ºé—´ä¸­æ˜¯å¦å­˜åœ¨å¯å‘å¼åŠ¨ä½œï¼ˆå‘åå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        2. å¦‚æœä¸å­˜åœ¨ï¼Œç‹¬ç«‹è®¡ç®—å¯å‘å¼é€»è¾‘å¹¶æ˜ å°„åˆ°å€™é€‰åŠ¨ä½œï¼ˆé€‚é…æ–°ç‰ˆæœ¬ï¼‰
        3. å®Œå…¨è§£è€¦å¯å‘å¼ç®—æ³•ä¸åŠ¨ä½œç©ºé—´è®¾è®¡
        
        è‡ªåŠ¨é€‚é…é€»è¾‘ï¼š
        - æ£€æŸ¥ACTION_CONFIG_ENHANCEDä¸­æ˜¯å¦æœ‰å¯¹åº”çš„å¯å‘å¼åŠ¨ä½œåç§°
        - å¦‚æœæœ‰ï¼šç›´æ¥ä½¿ç”¨è¯¥åŠ¨ä½œID
        - å¦‚æœæ²¡æœ‰ï¼šç‹¬ç«‹å®ç°å¯å‘å¼é€»è¾‘ + å€™é€‰æ˜ å°„
        """
        from environments.w_factory_env import calculate_slack_time
        
        sim = env.sim
        actions = {}
        
        # ğŸ”§ è‡ªåŠ¨æ£€æµ‹åŠ¨ä½œç©ºé—´ç»“æ„ï¼šä»ç¯å¢ƒå®ä¾‹è·å–ï¼Œè€Œä¸æ˜¯å…¨å±€å¯¼å…¥
        action_names = []
        
        # ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨ä¼ å…¥çš„infoå­—å…¸
        info_source = info

        if env.agents:
            first_agent = env.agents[0]
            if info_source and first_agent in info_source:
                action_names = info_source[first_agent].get('obs_meta', {}).get('action_names', [])

        action_map = {name: idx for idx, name in enumerate(action_names)}
        
        # å®šä¹‰å¯å‘å¼åç§°åˆ°åŠ¨ä½œåç§°çš„æ˜ å°„
        heuristic_to_action_map = {
            'FIFO': 'FIFO',
            'EDD': 'URGENT_EDD',
            'SPT': 'SHORT_SPT',
        }
        
        target_action_name = heuristic_to_action_map.get(heuristic_name)
        use_direct_action = (target_action_name in action_map)  # åŠ¨ä½œç©ºé—´ä¸­æ˜¯å¦å­˜åœ¨è¯¥å¯å‘å¼
        
        for agent_id in env.agents:
            station_name = agent_id.replace("agent_", "")
            queue = sim.queues[station_name].items
            
            if not queue:
                # 10201530 ä¿®å¤ï¼šMultiDiscreteéœ€è¦è¿”å›æ•°ç»„ï¼Œå…¨é›¶ä»£è¡¨å…¨éƒ¨IDLE
                sp = env.action_space(agent_id)
                if isinstance(sp, gym.spaces.MultiDiscrete):
                    actions[agent_id] = np.zeros(len(sp.nvec), dtype=sp.dtype)
                else:
                    actions[agent_id] = 0
                continue

            # ğŸ”§ åˆ†æ”¯1ï¼šåŠ¨ä½œç©ºé—´ä¸­å­˜åœ¨å¯å‘å¼åŠ¨ä½œï¼ˆæ—§ç‰ˆæœ¬ï¼‰
            if use_direct_action:
                sp = env.action_space(agent_id)
                if isinstance(sp, gym.spaces.MultiDiscrete):
                    k = len(sp.nvec)
                    actions[agent_id] = np.array([action_map[target_action_name]] * k, dtype=sp.dtype)
                else:
                    actions[agent_id] = action_map[target_action_name]
                continue
            
            # ğŸ”§ åˆ†æ”¯2ï¼šåŠ¨ä½œç©ºé—´ä¸­ä¸å­˜åœ¨å¯å‘å¼åŠ¨ä½œï¼ˆæ–°ç‰ˆæœ¬ - ç‹¬ç«‹å®ç°ï¼‰
            selected_parts = []
            
            if heuristic_name == 'FIFO':
                # FIFOï¼šé€‰æ‹©é˜Ÿé¦–å·¥ä»¶
                # FIFOï¼šç›´æ¥å–é˜Ÿé¦–ï¼Œé‡å¤kæ¬¡
                selected_parts = [queue[0]]
                
            elif heuristic_name == 'EDD':
                # EDDï¼šé€‰æ‹©æ¾å¼›æ—¶é—´æœ€å°çš„å·¥ä»¶
                # EDDï¼šæŒ‰slackä»å°åˆ°å¤§æ’åº
                parts_sorted = sorted(queue, key=lambda p: calculate_slack_time(p, sim.env.now, sim.queues))
                selected_parts = parts_sorted
                        
            elif heuristic_name == 'SPT':
                # SPTï¼šé€‰æ‹©åŠ å·¥æ—¶é—´æœ€çŸ­çš„å·¥ä»¶
                # SPTï¼šæŒ‰å½“å‰å·¥åºæ—¶é—´ä»å°åˆ°å¤§æ’åº
                parts_sorted = sorted(queue, key=lambda p: p.get_processing_time())
                selected_parts = parts_sorted
            else:
                raise ValueError(f"æœªçŸ¥çš„å¯å‘å¼è§„åˆ™: {heuristic_name}")
            
            # 10201530 ä¿®å¤ï¼šå°†å‰kä¸ªç›®æ ‡é›¶ä»¶æ˜ å°„ä¸ºMultiDiscreteåŠ¨ä½œæ•°ç»„
            candidates = sim._get_candidate_workpieces(station_name)
            sp = env.action_space(agent_id)
            if isinstance(sp, gym.spaces.MultiDiscrete):
                k = len(sp.nvec)
                chosen_actions = []
                used_part_ids = set()
                # æ˜ å°„ï¼šæ ¹æ®å€™é€‰åˆ—è¡¨æ‰¾åˆ°åŒ¹é…åŠ¨ä½œ
                for target_part in selected_parts:
                    if len(chosen_actions) >= k:
                        break
                    if target_part.part_id in used_part_ids:
                        continue
                    found = 0
                    for idx, cand in enumerate(candidates):
                        cand_part = cand.get("part") if isinstance(cand, dict) else cand[0]
                        if cand_part and cand_part.part_id == target_part.part_id:
                            candidate_action_start = next(
                                (i for i, name in enumerate(action_names) if "CANDIDATE_" in name),
                                1
                            )
                            found = candidate_action_start + idx
                            break
                    if found != 0:
                        chosen_actions.append(int(found))
                        used_part_ids.add(target_part.part_id)
                # è¡¥é½ä¸ºkä¸ªï¼ˆä¸è¶³æ—¶ç”¨IDLE=0ï¼‰
                while len(chosen_actions) < k:
                    chosen_actions.append(0)
                actions[agent_id] = np.array(chosen_actions, dtype=sp.dtype)
            else:
                # å•è®¾å¤‡ç¯å¢ƒï¼šå›é€€ä¸ºåŸæœ‰å•ä¸€åŠ¨ä½œé€»è¾‘
                action = 0
                if selected_parts:
                    target_part = selected_parts[0]
                    for idx, cand in enumerate(candidates):
                        cand_part = cand.get("part") if isinstance(cand, dict) else cand[0]
                        if cand_part and cand_part.part_id == target_part.part_id:
                            candidate_action_start = next(
                                (i for i, name in enumerate(action_names) if "CANDIDATE_" in name),
                                1
                            )
                            action = candidate_action_start + idx
                            break
                actions[agent_id] = action
            
        return actions

    # ğŸ”§ V4 ä¿®å¤ï¼šç›´æ¥é€šè¿‡configä¼ é€’è‡ªå®šä¹‰è®¢å•ï¼Œæ— éœ€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    all_kpis = []
    all_scores = []
    first_episode_history = None

    # åˆå¹¶é…ç½®ï¼Œç¡®ä¿è¯„ä¼°æ—¶ä½¿ç”¨ç¡®å®šæ€§å€™é€‰
    final_config_for_eval = copy.deepcopy(EVALUATION_CONFIG)
    final_config_for_eval.update(config)
    
    env = WFactoryEnv(config=final_config_for_eval)
    
    # åŠ¨æ€é€‰æ‹©è¿­ä»£å™¨ï¼šäº¤äº’å¼ç»ˆç«¯ä½¿ç”¨tqdmï¼Œå¦åˆ™ä½¿ç”¨æ™®é€šrange
    is_tty = sys.stdout.isatty()
    iterator = range(NUM_EVAL_EPISODES)
    if is_tty:
        iterator = tqdm(iterator, desc=f"{heuristic_name}è¯„ä¼°({config_name})")

    start_time = time.time()
    for i in iterator:
        final_stats, score, history = run_single_episode(env, heuristic_policy, seed=i, config=config)
        all_kpis.append(final_stats)
        all_scores.append(score)
        if history is not None:
            first_episode_history = history

    if not is_tty:
        end_time = time.time()
        duration = end_time - start_time
        it_per_s = NUM_EVAL_EPISODES / duration if duration > 0 else float('inf')
        desc = f"{heuristic_name}è¯„ä¼°({config_name})"
        # æ‰‹åŠ¨æ ¼å¼åŒ–è¾“å‡ºï¼Œæ¨¡æ‹Ÿtqdmçš„æœ€ç»ˆè¡Œ
        print(f"{desc}: 100%|{'â–ˆ'*10}| {NUM_EVAL_EPISODES}/{NUM_EVAL_EPISODES} [{duration:.2f}s, {it_per_s:.2f}it/s]", file=sys.stdout, flush=True)
    
    # ç”Ÿæˆç”˜ç‰¹å›¾
    if generate_gantt and first_episode_history:
        generate_gantt_chart(first_episode_history, heuristic_name, config_name, output_dir=output_dir, run_name=run_name)
        
    env.close()
    return all_kpis, all_scores

# =============================================================================
# 5. ç»“æœæ±‡æ€»ä¸å±•ç¤º (Result Aggregation & Display)
# =============================================================================

def aggregate_results(method_name: str, all_kpis: list, all_scores: list, config: dict = None):
    """æ±‡æ€»å¤šæ¬¡è¿è¡Œçš„ç»“æœï¼Œè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®"""
    if all_kpis is None:
        return {
            "Method": method_name,
            "Avg Score": "N/A",
            "Std Score": "N/A",
            "Avg Completion %": "N/A",
            "Avg Makespan": "N/A",
            "Avg Tardiness": "N/A",
            "Avg Utilization %": "N/A",
        }

    # ğŸŒŸ æ–°å¢ï¼šæ ¹æ®é…ç½®ç¡®å®šç›®æ ‡é›¶ä»¶æ•°
    if config and 'custom_orders' in config:
        target_parts = sum(order["quantity"] for order in config['custom_orders'])
    else:
        target_parts = get_total_parts_count()
        
    completion_rates = [(k['total_parts'] / target_parts) * 100 for k in all_kpis]
    
    return {
        "Method": method_name,
        "Avg Score": f"{np.mean(all_scores):.3f}",
        "Std Score": f"{np.std(all_scores):.3f}",
        "Avg Completion %": f"{np.mean(completion_rates):.1f}",
        "Avg Makespan": f"{np.mean([k['makespan'] for k in all_kpis]):.1f}",
        "Avg Tardiness": f"{np.mean([k['total_tardiness'] for k in all_kpis]):.1f}",
        "Avg Utilization %": f"{np.mean([k['mean_utilization'] for k in all_kpis]) * 100:.1f}",
    }

def run_comprehensive_evaluation(model_path: str, generate_gantt: bool = False, output_dir: str = None, run_name: str = None):
    """è¿è¡Œç»¼åˆè¯„ä¼°ï¼šåŒ…æ‹¬åŸºå‡†æµ‹è¯•å’Œæ³›åŒ–èƒ½åŠ›æµ‹è¯•"""
    
    print("="*80, flush=True)
    print("ğŸš€ å¼€å§‹è¿›è¡Œé™æ€ç¯å¢ƒä¸‹çš„è°ƒåº¦ç­–ç•¥ç»¼åˆè¯„ä¼°", flush=True)
    print(f"ğŸ” æ¯ä¸ªç­–ç•¥å°†ç‹¬ç«‹è¿è¡Œ {NUM_EVAL_EPISODES} æ¬¡ä»¥è·å–å¯é çš„ç»Ÿè®¡ç»“æœã€‚", flush=True)
    print("="*80, flush=True)

    # æµ‹è¯•é…ç½®åˆ—è¡¨
    test_configs = [
        ("åŸºå‡†æµ‹è¯•", STATIC_EVAL_CONFIG),
        ("æ³›åŒ–æµ‹è¯•1-é«˜å‹åŠ›çŸ­äº¤æœŸ", GENERALIZATION_CONFIG_1),
        ("æ³›åŒ–æµ‹è¯•2-æ··åˆä¼˜å…ˆçº§", GENERALIZATION_CONFIG_2),
        ("æ³›åŒ–æµ‹è¯•3-å¤§æ‰¹é‡é•¿å‘¨æœŸ", GENERALIZATION_CONFIG_3),
    ]
    
    all_results = []
    
    for test_name, config in test_configs:
        print(f"\nğŸ”¬ å¼€å§‹ {test_name}", flush=True)
        print("="*60, flush=True)
        
        # ğŸ”§ V4 ä¿®å¤ï¼šç›´æ¥ä¼ é€’configï¼Œæ— éœ€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        # 1. è¯„ä¼°MARLæ¨¡å‹
        marl_kpis, marl_scores = evaluate_marl_model(model_path, config, generate_gantt=generate_gantt, output_dir=output_dir, run_name=run_name)
        
        # 2. è¯„ä¼°å¯å‘å¼ç®—æ³• (ç”˜ç‰¹å›¾ä¿å­˜åˆ°çˆ¶ç›®å½•)
        heuristic_output_dir = os.path.dirname(output_dir) if output_dir else None
        fifo_kpis, fifo_scores = evaluate_heuristic('FIFO', config, generate_gantt=generate_gantt, output_dir=heuristic_output_dir, run_name=run_name)
        edd_kpis, edd_scores = evaluate_heuristic('EDD', config, generate_gantt=generate_gantt, output_dir=heuristic_output_dir, run_name=run_name)
        spt_kpis, spt_scores = evaluate_heuristic('SPT', config, generate_gantt=generate_gantt, output_dir=heuristic_output_dir, run_name=run_name)

        # 3. æ±‡æ€»ç»“æœ
        results = [
            aggregate_results("MARL (PPO)", marl_kpis, marl_scores, config),
            aggregate_results("SPT", spt_kpis, spt_scores, config),
            aggregate_results("EDD", edd_kpis, edd_scores, config),
            aggregate_results("FIFO", fifo_kpis, fifo_scores, config),
        ]
        
        # 4. æ‰“å°å½“å‰æµ‹è¯•ç»“æœ
        df = pd.DataFrame(results)
        print(f"\nğŸ† {test_name} - è¯„ä¼°å¯¹æ¯”ç»“æœ", flush=True)
        print("-"*60, flush=True)
        print(df.to_string(index=False), flush=True)
        
        # ä¿å­˜ç»“æœç”¨äºæœ€ç»ˆæ±‡æ€»
        for result in results:
            result['Test_Config'] = test_name
        all_results.extend(results)
        
        print("\n" + "="*60, flush=True)
    
    # 5. ç”Ÿæˆæœ€ç»ˆæ±‡æ€»æŠ¥å‘Š
    print(f"\nğŸ¯ æœ€ç»ˆæ±‡æ€»æŠ¥å‘Š - æ³›åŒ–èƒ½åŠ›åˆ†æ", flush=True)
    print("="*80, flush=True)
    
    # æŒ‰æ–¹æ³•åˆ†ç»„å±•ç¤ºç»“æœ
    methods = ["MARL (PPO)", "SPT", "EDD", "FIFO"]
    
    for method in methods:
        method_results = [r for r in all_results if r['Method'] == method]
        if method_results:
            print(f"\nğŸ“Š {method} åœ¨ä¸åŒæµ‹è¯•é…ç½®ä¸‹çš„è¡¨ç°:", flush=True)
            method_df = pd.DataFrame(method_results)
            # é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼ŒæŠŠTest_Configæ”¾åœ¨å‰é¢
            cols = ['Test_Config'] + [col for col in method_df.columns if col != 'Test_Config']
            method_df = method_df[cols]
            print(method_df.to_string(index=False), flush=True)

def main():
    parser = argparse.ArgumentParser(description="è¯„ä¼°MARLæ¨¡å‹ä¸å¯å‘å¼ç®—æ³•çš„æ€§èƒ½")
    parser.add_argument(
        "--model_path", 
        type=str, 
        required=True,
        help="æŒ‡å‘å·²è®­ç»ƒå¥½çš„MARL actoræ¨¡å‹æ–‡ä»¶ (.keras) çš„è·¯å¾„"
    )
    parser.add_argument(
        "--generalization", 
        action="store_true",
        help="æ˜¯å¦è¿›è¡Œæ³›åŒ–èƒ½åŠ›æµ‹è¯• (é»˜è®¤åªè¿›è¡ŒåŸºå‡†æµ‹è¯•)"
    )
    parser.add_argument(
        "--gantt",
        action="store_true",
        help="æ˜¯å¦ä¸ºæ¯ä¸ªè¯„ä¼°åœºæ™¯ç”Ÿæˆè¯¦ç»†çš„è°ƒåº¦ç”˜ç‰¹å›¾"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default=None,
        help="æŒ‡å®šä¸€ä¸ªç›®å½•æ¥å­˜æ”¾æ‰€æœ‰è¾“å‡ºçš„ç”˜ç‰¹å›¾æ–‡ä»¶"
    )
    parser.add_argument(
        "--run_name",
        type=str,
        default=None,
        help="ä¸ºæœ¬æ¬¡è¿è¡Œæä¾›ä¸€ä¸ªåç§°ï¼Œå°†ç”¨ä½œç”˜ç‰¹å›¾æ–‡ä»¶åçš„å‰ç¼€"
    )
    args = parser.parse_args()

    if args.generalization:
        # è¿è¡Œå®Œæ•´çš„æ³›åŒ–èƒ½åŠ›æµ‹è¯•
        run_comprehensive_evaluation(args.model_path, generate_gantt=args.gantt, output_dir=args.output_dir, run_name=args.run_name)
    else:
        # ä»…è¿è¡ŒåŸºå‡†æµ‹è¯• (åŸæœ‰åŠŸèƒ½)
        print("="*80, flush=True)
        print("ğŸš€ å¼€å§‹è¿›è¡Œé™æ€ç¯å¢ƒä¸‹çš„è°ƒåº¦ç­–ç•¥ç»¼åˆè¯„ä¼°", flush=True)
        print(f"ğŸ” æ¯ä¸ªç­–ç•¥å°†ç‹¬ç«‹è¿è¡Œ {NUM_EVAL_EPISODES} æ¬¡ä»¥è·å–å¯é çš„ç»Ÿè®¡ç»“æœã€‚", flush=True)
        print("="*80, flush=True)

        # 1. è¯„ä¼°MARLæ¨¡å‹
        marl_kpis, marl_scores = evaluate_marl_model(args.model_path, generate_gantt=args.gantt, output_dir=args.output_dir, run_name=args.run_name)
        
        # 2. è¯„ä¼°å¯å‘å¼ç®—æ³• (ç”˜ç‰¹å›¾ä¿å­˜åˆ°çˆ¶ç›®å½•)
        heuristic_output_dir = os.path.dirname(args.output_dir) if args.output_dir else None
        fifo_kpis, fifo_scores = evaluate_heuristic('FIFO', generate_gantt=args.gantt, output_dir=heuristic_output_dir, run_name=args.run_name)
        edd_kpis, edd_scores = evaluate_heuristic('EDD', generate_gantt=args.gantt, output_dir=heuristic_output_dir, run_name=args.run_name)
        spt_kpis, spt_scores = evaluate_heuristic('SPT', generate_gantt=args.gantt, output_dir=heuristic_output_dir, run_name=args.run_name)

        # 3. æ±‡æ€»ç»“æœ
        results = [
            aggregate_results("MARL (PPO)", marl_kpis, marl_scores),
            aggregate_results("SPT", spt_kpis, spt_scores),
            aggregate_results("EDD", edd_kpis, edd_scores),
            aggregate_results("FIFO", fifo_kpis, fifo_scores),
        ]
        
        # 4. åˆ›å»ºå¹¶æ‰“å°ç»“æœè¡¨æ ¼
        df = pd.DataFrame(results)
        
        print("\n" + "="*80, flush=True)
        print("ğŸ† æœ€ç»ˆè¯„ä¼°å¯¹æ¯”ç»“æœ", flush=True)
        print("="*80, flush=True)
        print(df.to_string(index=False), flush=True)
        print("="*80, flush=True)


if __name__ == "__main__":
    main()
