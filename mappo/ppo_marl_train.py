"""
MAPPOå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ è®­ç»ƒå…¥å£
=================================
åŸºäºMAPPOç®—æ³•çš„å·¥å‚è°ƒåº¦ç³»ç»Ÿè®­ç»ƒå…¥å£

æ¨¡å—ç»„ç»‡ï¼ˆè‡ªåº•å‘ä¸Šï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ppo_marl_train.py (æœ¬æ–‡ä»¶)         â”‚  â† è®­ç»ƒå…¥å£
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ppo_trainer.py                     â”‚  â† è®­ç»ƒå™¨ä¸»ç±»
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ppo_     â”‚ ppo_     â”‚ ppo_          â”‚
â”‚ buffer.pyâ”‚ network  â”‚ worker.py     â”‚  â† æ ¸å¿ƒç»„ä»¶
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä½¿ç”¨æ–¹å¼ï¼š
    python mappo/ppo_marl_train.py [--models-dir DIR] [--logs-dir DIR]
"""

import os
# è®­ç»ƒæ¨¡å¼é»˜è®¤ä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼Œæé«˜æ¢ç´¢èƒ½åŠ›
os.environ.setdefault('DETERMINISTIC_INIT', '0')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# ğŸ”§ å¼ºåˆ¶workerå­è¿›ç¨‹ä½¿ç”¨CPUï¼Œé¿å…å¤šè¿›ç¨‹GPUèµ„æºç«äº‰å¯¼è‡´BrokenProcessPool
# ä¸»è¿›ç¨‹ï¼ˆè®­ç»ƒå™¨ï¼‰ä»ä½¿ç”¨GPUè¿›è¡Œæ¨¡å‹æ›´æ–°ï¼Œå­è¿›ç¨‹ï¼ˆé‡‡æ ·ï¼‰ç”¨CPU
os.environ['FORCE_WORKER_CPU'] = '1'

import sys
import random
import numpy as np
import tensorflow as tf
import argparse
import multiprocessing

# æ·»åŠ ç¯å¢ƒè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from environments.w_factory_config import *
from mappo.ppo_trainer import SimplePPOTrainer


def main():
    """
    è®­ç»ƒä¸»å…¥å£
    
    æ‰§è¡Œæµç¨‹ï¼š
    1. è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆæ¨¡å‹/æ—¥å¿—ç›®å½•ï¼‰
    2. è®¾ç½®éšæœºç§å­
    3. åŠ è½½è®­ç»ƒé…ç½®
    4. åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹
    5. å¯åŠ¨è‡ªé€‚åº”è®­ç»ƒå¾ªç¯
    6. è¾“å‡ºè®­ç»ƒç»“æœ
    """
    print(f"âœ¨ è®­ç»ƒè¿›ç¨‹PID: {os.getpid()}")

    # è§£æå¤–éƒ¨ä¼ å…¥çš„ç›®å½•å‚æ•°ï¼ˆç”± auto_train.py ä¼ å…¥ï¼‰
    parser = argparse.ArgumentParser(description="MAPPO è®­ç»ƒå…¥å£")
    parser.add_argument("--models-dir", type=str, default=None, help="ç”¨äºä¿å­˜è®­ç»ƒæ¨¡å‹çš„æ ¹ç›®å½•ï¼ˆç”±auto_trainä¼ å…¥ï¼‰")
    parser.add_argument("--logs-dir", type=str, default=None, help="ç”¨äºä¿å­˜TensorBoardæ—¥å¿—çš„æ ¹ç›®å½•ï¼ˆç”±auto_trainä¼ å…¥ï¼‰")
    cli_args, _ = parser.parse_known_args()

    # è®¾ç½®éšæœºç§å­
    random.seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)
    tf.random.set_seed(RANDOM_SEED)
    
    try:
        # ä»é…ç½®æ–‡ä»¶è·å–è®­ç»ƒå‚æ•°
        max_episodes = TRAINING_FLOW_CONFIG["general_params"]["max_episodes"]
        steps_per_episode = TRAINING_FLOW_CONFIG["general_params"]["steps_per_episode"]
        eval_frequency = TRAINING_FLOW_CONFIG["general_params"]["eval_frequency"]
        
        print("=" * 80)
        foundation_criteria = TRAINING_FLOW_CONFIG["foundation_phase"]["graduation_criteria"]
        generalization_criteria = TRAINING_FLOW_CONFIG["generalization_phase"]["completion_criteria"]
        foundation_mixing = TRAINING_FLOW_CONFIG["foundation_phase"]["multi_task_mixing"]
        generalization_mixing = TRAINING_FLOW_CONFIG["generalization_phase"]["multi_task_mixing"]
        dynamic_events = TRAINING_FLOW_CONFIG["generalization_phase"].get("dynamic_events", {})
        
        print(f"\nğŸ“šé˜¶æ®µä¸€ï¼šåŸºç¡€èƒ½åŠ›è®­ç»ƒï¼ˆéšæœºè®¢å•æ³›åŒ–ï¼‰")
        print(f"   ç­–ç•¥: éšæœºè®¢å• + {int(foundation_mixing.get('base_worker_fraction', 0)*100)}% workerä½¿ç”¨BASE_ORDERS")
        print(f"   ç›®æ ‡: ç»¼åˆè¯„åˆ† > {foundation_criteria['target_score']:.2f}, "
              f"å®Œæˆç‡ > {foundation_criteria['min_completion_rate']:.0f}%, "
              f"å»¶æœŸ < {foundation_criteria['tardiness_threshold']:.0f}min, "
              f"è¿ç»­{foundation_criteria['target_consistency']}æ¬¡")
        
        print(f"\nğŸš€é˜¶æ®µäºŒï¼šåŠ¨æ€äº‹ä»¶é²æ£’æ€§è®­ç»ƒï¼ˆåŠ¨æ€äº‹ä»¶é²æ£’æ€§ï¼‰")
        print(f"   ç­–ç•¥: éšæœºè®¢å• + åŠ¨æ€äº‹ä»¶ï¼ˆè®¾å¤‡æ•…éšœ{'âœ“' if dynamic_events.get('equipment_failure_enabled') else 'âœ—'}ã€ç´§æ€¥æ’å•{'âœ“' if dynamic_events.get('emergency_orders_enabled') else 'âœ—'}ï¼‰")
        print(f"        + {int(generalization_mixing.get('base_worker_fraction', 0)*100)}% workerä½¿ç”¨BASE_ORDERS")
        print(f"   ç›®æ ‡: ç»¼åˆè¯„åˆ† > {generalization_criteria['target_score']:.2f}, "
              f"å®Œæˆç‡ > {generalization_criteria['min_completion_rate']:.0f}%, "
              f"è¿ç»­{generalization_criteria['target_consistency']}æ¬¡")

        print(f"ğŸ“Š è½®æ•°ä¸Šé™: {max_episodes}è½®")
        print("=" * 80)
        print("ğŸ”§ æ ¸å¿ƒé…ç½®:")
        print("  å·¥ä½œç«™:")
        for station, config in WORKSTATIONS.items():
            print(f"    - {station}: æ•°é‡={config['count']}, å®¹é‡={config['capacity']}")

        print("  å¥–åŠ±ç³»ç»Ÿ:")
        for key, value in REWARD_CONFIG.items():
            print(f"    - {key}: {value}")
        
        cl_config = TRAINING_FLOW_CONFIG["foundation_phase"]["curriculum_learning"]
        dynamic_events_cfg = TRAINING_FLOW_CONFIG["generalization_phase"].get("dynamic_events", {})
        
        print("  å¯ç”¨/ç¦ç”¨æ¨¡å—:")
        print(f"    - è¯¾ç¨‹å­¦ä¹ : {'å¯ç”¨' if cl_config.get('enabled', False) else 'ç¦ç”¨'}")
        print(f"    - è®¾å¤‡æ•…éšœ: {'å¯ç”¨' if dynamic_events_cfg.get('equipment_failure_enabled', False) else 'ç¦ç”¨'}")
        print(f"    - ç´§æ€¥æ’å•: {'å¯ç”¨' if dynamic_events_cfg.get('emergency_orders_enabled', False) else 'ç¦ç”¨'}")
        print("-" * 40)
        
        trainer = SimplePPOTrainer(
            initial_lr=LEARNING_RATE_CONFIG["initial_lr"],
            total_train_episodes=max_episodes,
            steps_per_episode=steps_per_episode,
            training_targets=None, 
            models_root_dir=cli_args.models_dir,
            logs_root_dir=cli_args.logs_dir
        )
        
        # å¯åŠ¨è‡ªé€‚åº”è®­ç»ƒï¼šç³»ç»Ÿå°†æ ¹æ®æ€§èƒ½è‡ªåŠ¨å†³å®šä½•æ—¶åœæ­¢
        results = trainer.train(
            max_episodes=max_episodes,
            steps_per_episode=steps_per_episode,
            eval_frequency=eval_frequency,
            adaptive_mode=True
        )
        
        if results:
            print("\nğŸ‰ è‡ªé€‚åº”è®­ç»ƒæˆåŠŸå®Œæˆï¼")
            print(f"ğŸ“Š å®é™…è®­ç»ƒè½®æ•°: {len(trainer.iteration_times)}")
            final_completion_rate = (results['best_kpi'].get('mean_completed_parts', 0) / get_total_parts_count()) * 100 if get_total_parts_count() > 0 else 0
            print(f"ğŸ¯ æœ€ç»ˆç›®æ ‡è¾¾æˆ: {trainer.adaptive_state['target_achieved_count']}æ¬¡è¿ç»­è¾¾æ ‡ (åŸºäºæœ€ç»ˆé˜¶æ®µåˆ†æ•°)")
            
            best_episode_final = trainer.best_episode_dual_objective if trainer.best_episode_dual_objective != -1 else trainer.final_stage_best_episode
            print(f"ğŸ“ˆ å†å²æœ€ä½³æ€§èƒ½ (åŒé‡æ ‡å‡†ï¼Œç¬¬ {best_episode_final} å›åˆ): {final_completion_rate:.1f}% ({results['best_kpi'].get('mean_completed_parts', 0):.1f}ä¸ªé›¶ä»¶)")
        else:
            print("\nâŒ è®­ç»ƒå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•ä¸º'spawn'ï¼Œé¿å…TensorFlowçš„forkä¸å®‰å…¨é—®é¢˜
    try:
        multiprocessing.set_start_method('spawn', force=True)
    except RuntimeError:
        pass
    main()

