import os
import sys
import numpy as np
import tensorflow as tf
from collections import Counter
import argparse

# æ·»åŠ ç¯å¢ƒè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

from environments.w_factory_env import WFactoryEnv
from evaluation import (
    STATIC_EVAL_CONFIG, 
    GENERALIZATION_CONFIG_1, GENERALIZATION_CONFIG_2, GENERALIZATION_CONFIG_3
)

def debug_marl_actions(model_path: str, config: dict, max_steps: int = 600, deterministic: bool = False):
    """
    è°ƒè¯•MARLæ¨¡å‹çš„åŠ¨ä½œè¾“å‡ºæ¨¡å¼ã€‚
    
    æ–°å¢åŠŸèƒ½:
    - å¯é€‰æ‹©ç¡®å®šæ€§ç­–ç•¥æˆ–ä¸evaluation.pyå¯¹é½çš„éšæœºç­–ç•¥ã€‚
    - æ›´å…·ä½“çš„æ¨¡å‹åŠ è½½å¼‚å¸¸å¤„ç†ã€‚
    """
    print(f"ğŸ” å¼€å§‹è°ƒè¯•MARLæ¨¡å‹è¡Œä¸º")
    print(f"ğŸ“‹ é…ç½®: {config.get('stage_name', 'æœªçŸ¥')}")
    print(f"ğŸ•¹ï¸  ç­–ç•¥: {'ç¡®å®šæ€§ (Greedy)' if deterministic else 'éšæœº (ä¸evaluation.pyå¯¹é½)'}")
    
    # åŠ è½½æ¨¡å‹
    try:
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨äºè·¯å¾„: {model_path}")
        actor_model = tf.keras.models.load_model(model_path)
        print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_path}")
    except FileNotFoundError as e:
        print(f"âŒ {e}")
        return
    except (IOError, tf.errors.OpError) as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥ï¼Œæ–‡ä»¶å¯èƒ½å·²æŸåæˆ–æ ¼å¼ä¸æ­£ç¡®: {e}")
        return
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return

    # åˆ›å»ºç¯å¢ƒ
    env = WFactoryEnv(config=config)
    obs, info = env.reset(seed=42)
    
    print(f"ğŸ­ ç¯å¢ƒä¿¡æ¯:")
    print(f"   æ™ºèƒ½ä½“æ•°é‡: {len(env.agents)}")
    print(f"   æ™ºèƒ½ä½“åˆ—è¡¨: {env.agents}")
    
    # è®°å½•åŠ¨ä½œç»Ÿè®¡
    action_stats = {agent: Counter() for agent in env.agents}
    step_count = 0
    
    print(f"\nğŸ¯ å¼€å§‹è®°å½•å‰{max_steps}æ­¥çš„åŠ¨ä½œæ¨¡å¼...")
    
    while step_count < max_steps:
        # MARLç­–ç•¥
        actions = {}
        for agent in env.agents:
            if agent in obs:
                state = tf.expand_dims(obs[agent], 0)
                action_probs = actor_model(state, training=False)
                
                # æ˜¾ç¤ºå‰å‡ æ­¥çš„è¯¦ç»†ä¿¡æ¯
                if step_count < 5:
                    print(f"   æ­¥éª¤{step_count+1} {agent}: æ¦‚ç‡åˆ†å¸ƒ {action_probs[0].numpy()}")
                
                if deterministic:
                    # ç¡®å®šæ€§ç­–ç•¥ï¼šæ€»æ˜¯é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„åŠ¨ä½œ
                    action = int(tf.argmax(action_probs[0]))
                else:
                    # éšæœºç­–ç•¥ï¼š80%æ¦‚ç‡é€‰æœ€ä¼˜ï¼Œ20%æ ¹æ®æ¦‚ç‡åˆ†å¸ƒé‡‡æ · (ä¸evaluation.pyå¯¹é½)
                    if np.random.random() < 0.2:
                        action = tf.random.categorical(tf.math.log(action_probs + 1e-8), 1)[0, 0].numpy()
                    else:
                        action = int(tf.argmax(action_probs[0]))

                actions[agent] = action
                action_stats[agent][action] += 1
        
        # æ‰§è¡ŒåŠ¨ä½œ
        obs, rewards, terminations, truncations, info = env.step(actions)
        step_count += 1
        
        # æ£€æŸ¥æ˜¯å¦ç»“æŸ
        if any(terminations.values()) or any(truncations.values()):
            print(f"ğŸ ç¯å¢ƒåœ¨ç¬¬{step_count}æ­¥ç»“æŸ")
            break
    
    # åˆ†æåŠ¨ä½œç»Ÿè®¡
    print(f"\nğŸ“Š åŠ¨ä½œç»Ÿè®¡åˆ†æ (æ€»å…±{step_count}æ­¥):")
    print("-" * 60)
    
    for agent in env.agents:
        print(f"{agent}:")
        total_actions = sum(action_stats[agent].values())
        for action, count in sorted(action_stats[agent].items()):
            percentage = (count / total_actions) * 100 if total_actions > 0 else 0
            action_name = "IDLE" if action == 0 else f"å¤„ç†é›¶ä»¶{action}"
            print(f"   åŠ¨ä½œ{action} ({action_name}): {count}æ¬¡ ({percentage:.1f}%)")
        print()
    
    # è·å–æœ€ç»ˆç»Ÿè®¡
    final_stats = env.sim.get_final_stats()
    print(f"ğŸ“ˆ æœ€ç»ˆKPI:")
    print(f"   å®Œæˆé›¶ä»¶: {final_stats['total_parts']}")
    print(f"   æ€»å·¥æœŸ: {final_stats['makespan']:.1f}")
    print(f"   å»¶æœŸæ—¶é—´: {final_stats['total_tardiness']:.1f}")
    print(f"   è®¾å¤‡åˆ©ç”¨ç‡: {final_stats['mean_utilization']:.1%}")
    
    env.close()

def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶è¿è¡Œè°ƒè¯•è„šæœ¬"""
    parser = argparse.ArgumentParser(
        description="è°ƒè¯•å’Œåˆ†æMARLæ¨¡å‹çš„è¡Œä¸ºï¼Œæ£€æŸ¥å…¶åœ¨ä¸åŒé…ç½®ä¸‹çš„åŠ¨ä½œæ¨¡å¼å’Œæ€§èƒ½ã€‚",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "--model_path",
        type=str,
        required=True,
        help="æŒ‡å‘å·²è®­ç»ƒå¥½çš„MARL actoræ¨¡å‹æ–‡ä»¶ (.keras) çš„è·¯å¾„"
    )
    parser.add_argument(
        "--config",
        type=str,
        default="all",
        choices=["static", "gen1", "gen2", "gen3", "all"],
        help="è¦è¿è¡Œçš„æµ‹è¯•é…ç½®åç§°ã€‚'all'ä¼šè¿è¡Œæ‰€æœ‰å¯ç”¨çš„é…ç½®ã€‚"
    )
    parser.add_argument(
        "--max_steps",
        type=int,
        default=600,
        help="æ¯ä¸ªç¯å¢ƒå›åˆçš„æœ€å¤§ä»¿çœŸæ­¥æ•°ã€‚"
    )
    parser.add_argument(
        "--deterministic",
        action="store_true",
        help="å¦‚æœè®¾ç½®æ­¤æ ‡å¿—ï¼Œå°†ä½¿ç”¨ç¡®å®šæ€§ç­–ç•¥ï¼ˆæ€»æ˜¯é€‰æ‹©æœ€ä¼˜åŠ¨ä½œï¼‰ã€‚å¦åˆ™ï¼Œä½¿ç”¨ä¸è¯„ä¼°è„šæœ¬ä¸€è‡´çš„éšæœºç­–ç•¥ï¼ˆ80%æœ€ä¼˜ï¼Œ20%é‡‡æ ·ï¼‰ã€‚"
    )
    args = parser.parse_args()

    # é…ç½®åç§°åˆ°å¯¹è±¡çš„æ˜ å°„
    config_map = {
        "static": ("åŸºå‡†é…ç½®", STATIC_EVAL_CONFIG),
        "gen1": ("æ³›åŒ–æµ‹è¯•1-é«˜å‹åŠ›çŸ­äº¤æœŸ", GENERALIZATION_CONFIG_1),
        "gen2": ("æ³›åŒ–æµ‹è¯•2-æ··åˆä¼˜å…ˆçº§", GENERALIZATION_CONFIG_2),
        "gen3": ("æ³›åŒ–æµ‹è¯•3-å¤§æ‰¹é‡é•¿å‘¨æœŸ", GENERALIZATION_CONFIG_3),
    }

    if args.config == "all":
        configs_to_run = list(config_map.values())
    else:
        configs_to_run = [config_map[args.config]]

    print("=" * 80)
    print("ğŸ”¬ MARLæ¨¡å‹è¡Œä¸ºåˆ†æ")
    print(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"ç­–ç•¥æ¨¡å¼: {'ç¡®å®šæ€§ (Greedy)' if args.deterministic else 'éšæœº (ä¸evaluation.pyå¯¹é½)'}")
    print(f"æœ€å¤§æ­¥æ•°: {args.max_steps}")
    print("=" * 80)

    for name, config in configs_to_run:
        print(f"\n{'='*20} å¼€å§‹æµ‹è¯•: {name} {'='*20}")
        debug_marl_actions(
            model_path=args.model_path,
            config=config,
            max_steps=args.max_steps,
            deterministic=args.deterministic
        )
        print()

if __name__ == "__main__":
    main()
