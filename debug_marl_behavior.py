import os
import sys

# å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶è°ƒè¯•è„šæœ¬åœ¨CPUä¸Šè¿è¡Œï¼Œé¿å…ä¸è®­ç»ƒè¿›ç¨‹äº‰å¤ºGPUèµ„æº
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # å±è”½TensorFlowçš„INFOçº§åˆ«æ—¥å¿—

import numpy as np
import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import argparse
import random # ç»Ÿä¸€éšæœºç§å­
# 10201530 æ–°å¢ï¼šå¯¼å…¥gymä»¥æ£€æµ‹MultiDiscreteåŠ¨ä½œç©ºé—´
import gymnasium as gym

# æ·»åŠ ç¯å¢ƒè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)
    # å‡è®¾debugè„šæœ¬åœ¨é¡¹ç›®æ ¹ç›®å½•çš„å­ç›®å½•ä¸­
    sys.path.append(os.path.dirname(current_dir))

from environments.w_factory_env import WFactoryEnv, calculate_slack_time
from evaluation import (
    STATIC_EVAL_CONFIG, 
    GENERALIZATION_CONFIG_1, GENERALIZATION_CONFIG_2, GENERALIZATION_CONFIG_3
)


def decode_observation(obs_vector: np.ndarray, agent_id: str, obs_meta: dict) -> str:
    """
    åŠ¨æ€è§£ç è§‚æµ‹å‘é‡ï¼Œå®Œå…¨ä¾èµ–ç¯å¢ƒæä¾›çš„å…ƒä¿¡æ¯(obs_meta)
    """
    decoded_lines = []
    current_idx = 0

    try:
        # --- 1. Agentè‡ªèº«ç‰¹å¾ ---
        num_stations = obs_meta.get('num_stations', 5)
        agent_feature_names = obs_meta.get('agent_feature_names', [])
        
        decoded_lines.append(f"  --- 1. æ™ºèƒ½ä½“è‡ªèº«ç‰¹å¾ ({num_stations + 3}ç»´) ---")
        
        # one-hot
        one_hot_len = min(num_stations, len(obs_vector) - current_idx)
        agent_id_one_hot = obs_vector[current_idx : current_idx + one_hot_len]
        station_idx = int(np.argmax(agent_id_one_hot)) if one_hot_len > 0 else -1
        decoded_lines.append(f"    - {agent_feature_names[0]}: {station_idx}")
        current_idx += one_hot_len

        # capacity
        capacity = obs_vector[current_idx] * 5.0
        decoded_lines.append(f"    - {agent_feature_names[1]}: {capacity:.1f}")
        current_idx += 1
        
        # busy_ratio & is_failed
        busy_ratio = obs_vector[current_idx]
        is_failed = obs_vector[current_idx + 1] > 0.5
        decoded_lines.append(f"    - {agent_feature_names[2]}: {busy_ratio:.1%}")
        decoded_lines.append(f"    - {agent_feature_names[3]}: {'æ˜¯' if is_failed else 'å¦'}")
        current_idx += 2

        # --- 2. å…¨å±€å®è§‚ç‰¹å¾ ---
        global_feature_names = obs_meta.get('global_feature_names', [])
        decoded_lines.append(f"  --- 2. å…¨å±€å®è§‚ç‰¹å¾ ({len(global_feature_names)}ç»´) ---")
        for i, name in enumerate(global_feature_names):
            value = obs_vector[current_idx + i]
            decoded_lines.append(f"    - {name}: {value:.3f}")
        current_idx += len(global_feature_names)

        # --- 3. é˜Ÿåˆ—æ‘˜è¦ç»Ÿè®¡ ---
        queue_feature_names = obs_meta.get('queue_summary_feature_names', [])
        stat_names = obs_meta.get('queue_summary_stat_names', [])
        num_stats = len(stat_names)
        queue_summary_dim = len(queue_feature_names) * num_stats
        decoded_lines.append(f"  --- 3. é˜Ÿåˆ—æ‘˜è¦ç»Ÿè®¡ ({queue_summary_dim}ç»´) ---")
        
        queue_summary_vec = obs_vector[current_idx : current_idx + queue_summary_dim]
        current_idx += queue_summary_dim
        
        for i, feature_name in enumerate(queue_feature_names):
            stats_str_parts = []
            for j, stat_name in enumerate(stat_names):
                value = queue_summary_vec[i * num_stats + j]
                stats_str_parts.append(f"{stat_name}={value:.2f}")
            decoded_lines.append(f"    - {feature_name}: [{', '.join(stats_str_parts)}]")

        # --- 4. å€™é€‰å·¥ä»¶è¯¦ç»†ç‰¹å¾ ---
        candidate_feature_names = obs_meta.get('candidate_feature_names', [])
        candidate_feature_dim = len(candidate_feature_names)
        num_candidates = obs_meta.get('num_candidate_workpieces', 10)
        decoded_lines.append(f"  --- 4. å€™é€‰å·¥ä»¶è¯¦ç»†ç‰¹å¾ ({candidate_feature_dim * num_candidates}ç»´) ---")
        
        for i in range(num_candidates):
            candidate_features_raw = obs_vector[current_idx : current_idx + candidate_feature_dim]
            current_idx += candidate_feature_dim
            
            # æ£€æŸ¥å·¥ä»¶æ˜¯å¦å­˜åœ¨
            if candidate_features_raw[0] < 0.5:
                decoded_lines.append(f"    - [å€™é€‰ {i+1}]: (ç©º)")
                continue
            
            decoded_lines.append(f"    - [å€™é€‰ {i+1}]:")
            for j, feature_name in enumerate(candidate_feature_names):
                value = candidate_features_raw[j]
                # æ ¹æ®ç‰¹å¾åç§°è¿›è¡Œä¸€äº›å¯è¯»æ€§å¤„ç†
                if "norm" in feature_name:
                    formatted_value = f"{value:.3f}"
                elif "ratio" in feature_name:
                    formatted_value = f"{value:.1%}"
                else:
                    norm_constants = obs_meta.get('normalization_constants', {})
                    # ç®€å•çš„åå‘å½’ä¸€åŒ–ï¼Œä»…ä¸ºå¯è¯»æ€§
                    if feature_name == 'remaining_ops':
                        value *= norm_constants.get('max_bom_ops_norm', 1)
                        formatted_value = f"{value:.1f}"
                    elif feature_name == 'total_remaining_time':
                        value *= norm_constants.get('total_remaining_time_norm', 1)
                        formatted_value = f"{value:.1f} min"
                    elif feature_name == 'current_op_duration':
                         value *= norm_constants.get('max_op_duration_norm', 1)
                         formatted_value = f"{value:.1f} min"
                    else:
                        formatted_value = f"{value:.3f}"
                decoded_lines.append(f"      - {feature_name}: {formatted_value}")

    except IndexError:
        decoded_lines.append("  --- !é”™è¯¯: è§‚æµ‹å‘é‡ç»´åº¦ä¸è§£ç é€»è¾‘ä¸åŒ¹é…! ---")
    except Exception as e:
        decoded_lines.append(f"  --- !è§£ç æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}! ---")

    return "\n".join(decoded_lines)

def get_policy_details(policy, state, obs_meta: dict):
    """è·å–ç­–ç•¥åˆ†å¸ƒå’Œé€‰æ‹©çš„åŠ¨ä½œ"""
    action_probs = policy(tf.expand_dims(state, 0))[0].numpy()
    chosen_action = int(np.argmax(action_probs))
    
    # è·å–åŠ¨ä½œåç§°
    action_names = obs_meta.get('action_names', [])
    
    # ç¡®ä¿action_namesçš„é•¿åº¦è‡³å°‘å’Œaction_probsä¸€æ ·é•¿
    if len(action_names) < len(action_probs):
        action_names.extend([f"æœªçŸ¥åŠ¨ä½œ_{i}" for i in range(len(action_names), len(action_probs))])

    policy_dist_str = ", ".join([
        f"{action_names[i]}={prob:.2%}" for i, prob in enumerate(action_probs)
    ])
    chosen_action_name = action_names[chosen_action] if chosen_action < len(action_names) else f"æœªçŸ¥åŠ¨ä½œ_{chosen_action}"
    
    return policy_dist_str, chosen_action_name


def debug_marl_actions(model_path: str, config: dict, max_steps: int = 600, deterministic: bool = False, snapshot_interval: int = 100, seed: int = 42):
    """
    è°ƒè¯•MARLæ¨¡å‹çš„åŠ¨ä½œè¾“å‡ºæ¨¡å¼ã€‚
    
    æ–°å¢åŠŸèƒ½:
    - å¯é€‰æ‹©ç¡®å®šæ€§ç­–ç•¥æˆ–ä¸evaluation.pyå¯¹é½çš„éšæœºç­–ç•¥ã€‚
    - æ›´å…·ä½“çš„æ¨¡å‹åŠ è½½å¼‚å¸¸å¤„ç†ã€‚
    - å¯è§†åŒ–æ™ºèƒ½ä½“è§‚æµ‹å‘é‡(è§†é‡)ã€‚
    - å®šæœŸè¾“å‡ºKPIå¿«ç…§ã€‚
    - ç»Ÿä¸€éšæœºç§å­ã€‚
    """
    print(f"ğŸ” å¼€å§‹è°ƒè¯•MARLæ¨¡å‹è¡Œä¸º")
    print(f"ğŸ“‹ é…ç½®: {config.get('stage_name', 'æœªçŸ¥')}")
    print(f"ğŸ•¹ï¸  ç­–ç•¥: {'ç¡®å®šæ€§ (Greedy)' if deterministic else 'éšæœº (ä¸evaluation.pyå¯¹é½)'}")
    print(f"ğŸŒ± éšæœºç§å­: {seed}")
    
    # åŠ è½½æ¨¡å‹
    try:
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨äºè·¯å¾„: {model_path}")
        actor_model = tf.keras.models.load_model(model_path)
        print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_path}")
    except FileNotFoundError as e:
        print(f"âŒ {e}")
        return
    except (IOError, tf.errors.OpError) as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥ï¼Œæ–‡ä»¶å¯èƒ½å·²æŸåæˆ–æ ¼å¼ä¸æ­£ç¡®: {e}")
        return
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return

    # åˆ›å»ºç¯å¢ƒï¼ˆé»˜è®¤å¯ç”¨ç¡®å®šæ€§å€™é€‰ï¼Œä¿è¯è°ƒè¯•å¯å¤ç°ï¼‰
    config_for_debug = dict(config) if isinstance(config, dict) else {}
    config_for_debug.setdefault('deterministic_candidates', True)
    env = WFactoryEnv(config=config_for_debug)
    obs, info = env.reset(seed=seed)
    
    print(f"ğŸ­ ç¯å¢ƒä¿¡æ¯:")
    print(f"   æ™ºèƒ½ä½“æ•°é‡: {len(env.agents)}")
    print(f"   æ™ºèƒ½ä½“åˆ—è¡¨: {env.agents}")
    
    # 10201530 ä¿®å¤ï¼šä¸ºMultiDiscreteå»ºç«‹æŒ‰è®¾å¤‡ç»´åº¦çš„åŠ¨ä½œç»Ÿè®¡
    heads_map = {}
    for agent in env.agents:
        space = env.action_space(agent)
        if isinstance(space, gym.spaces.MultiDiscrete):
            heads_map[agent] = len(space.nvec)
        else:
            heads_map[agent] = 1

    # 10201530 ä¿®å¤ï¼šåŠ¨ä½œç»Ÿè®¡æ”¹ä¸ºæ¯ä¸ªagentçš„æ¯ä¸ªè®¾å¤‡ä¸€ä»½Counter
    action_stats = {agent: [Counter() for _ in range(heads_map[agent])] for agent in env.agents}
    step_count = 0
    
    print(f"\nğŸ¯ å¼€å§‹è®°å½•å‰{max_steps}æ­¥çš„åŠ¨ä½œæ¨¡å¼...")
    
    # 10201530 æ–°å¢ï¼šä»æ¦‚ç‡åˆ†å¸ƒç”Ÿæˆå¹¶è¡ŒåŠ¨ä½œçš„å·¥å…·å‡½æ•°ï¼ˆå»é‡ã€å¯é€‰é‡‡æ ·ï¼‰
    def choose_parallel_actions_from_probs(probs: np.ndarray, num_heads: int, greedy: bool = True) -> np.ndarray:
        probs = np.asarray(probs, dtype=np.float64)
        probs = np.clip(probs, 1e-12, 1.0)
        probs = probs / probs.sum()

        # è´ªå¿ƒï¼šä»å¤§åˆ°å°é€‰å‰Kä¸ªï¼Œé¿å…é‡å¤
        if greedy:
            sorted_idx = np.argsort(probs)[::-1]
            chosen = []
            for idx in sorted_idx:
                # å…è®¸IDLE(0)è¢«é€‰æ‹©ï¼›å»é‡ç›¸åŒåŠ¨ä½œ
                if idx not in chosen:
                    chosen.append(int(idx))
                if len(chosen) >= num_heads:
                    break
            # å¦‚æœä¸è¶³Kï¼Œè¡¥0
            while len(chosen) < num_heads:
                chosen.append(0)
            return np.array(chosen, dtype=np.int32)

        # éšæœºï¼šæ— æ”¾å›æŠ½æ ·num_headsä¸ªåŠ¨ä½œ
        n = probs.shape[0]
        if num_heads >= n:
            # è¾¹ç•Œï¼šåŠ¨ä½œæ•°ä¸è¶³æ—¶ï¼Œå…è®¸éƒ¨åˆ†é‡å¤
            sampled = np.random.choice(np.arange(n), size=num_heads, replace=True, p=probs)
        else:
            sampled = np.random.choice(np.arange(n), size=num_heads, replace=False, p=probs)
        return sampled.astype(np.int32)

    while step_count < max_steps:
        # MARLç­–ç•¥
        actions = {}
        for agent in env.agents:
            if agent in obs:
                state = tf.expand_dims(obs[agent], 0)
                action_probs_tensor = actor_model(state, training=False)
                action_probs = action_probs_tensor[0].numpy()
                space = env.action_space(agent)
                is_multi = isinstance(space, gym.spaces.MultiDiscrete)
                num_heads = heads_map.get(agent, 1)
                
                # æ˜¾ç¤ºå‰å‡ æ­¥çš„è¯¦ç»†ä¿¡æ¯
                if step_count < 5:
                    print(f"\n--- æ­¥éª¤ {step_count+1}: {agent} ---")
                    # è§£ç å¹¶æ‰“å°è§‚æµ‹å‘é‡
                    # 10201530 ä¿®å¤ï¼šå‘decodeä¼ å…¥obs_meta
                    decoded_obs_str = decode_observation(obs[agent], agent, info[agent].get('obs_meta', {}))
                    print(decoded_obs_str)
                    # æ‰“å°åŠ¨ä½œæ¦‚ç‡
                    action_probs = action_probs
                    
                    # ä»infoä¸­è·å–åŠ¨ä½œåç§°
                    action_names = info[agent].get('obs_meta', {}).get('action_names', [])
                    
                    if action_names:
                        policy_dist_str = ", ".join([f"{name}={prob:.2%}" for name, prob in zip(action_names, action_probs)])
                    else:
                        # Fallback if action_names is not available
                        policy_dist_str = ", ".join([f"Action{i}={prob:.2%}" for i, prob in enumerate(action_probs)])
                    print(f"  - ç­–ç•¥åˆ†å¸ƒ: [{policy_dist_str}]")

                # 10201530 ä¿®å¤ï¼šæ ¹æ®åŠ¨ä½œç©ºé—´ç±»å‹ç”Ÿæˆæ ‡é‡æˆ–å¹¶è¡ŒåŠ¨ä½œæ•°ç»„
                if is_multi:
                    # 80/20ç­–ç•¥ï¼šä¸»è¦è´ªå¿ƒï¼Œå°‘é‡é‡‡æ ·
                    if deterministic:
                        action = choose_parallel_actions_from_probs(action_probs, num_heads, greedy=True)
                    else:
                        if np.random.random() < 0.2:
                            action = choose_parallel_actions_from_probs(action_probs, num_heads, greedy=False)
                        else:
                            action = choose_parallel_actions_from_probs(action_probs, num_heads, greedy=True)
                else:
                    if deterministic:
                        action = int(np.argmax(action_probs))
                    else:
                        if np.random.random() < 0.2:
                            action = int(np.random.choice(np.arange(len(action_probs)), p=action_probs))
                        else:
                            action = int(np.argmax(action_probs))

                # 10201530 ä¿®å¤ï¼šåœ¨è¯¦ç»†é˜¶æ®µæ‰“å°é€‰æ‹©ç»“æœ
                if step_count < 5:
                    if is_multi:
                        decoded = [
                            (info[agent].get('obs_meta', {}).get('action_names', [])[a]
                             if a < len(info[agent].get('obs_meta', {}).get('action_names', [])) else f"Action{a}")
                            for a in list(action)
                        ]
                        print(f"  - æœ€ç»ˆé€‰æ‹©åŠ¨ä½œ(å¹¶è¡Œ): {list(action)} -> {decoded}")
                    else:
                        anames = info[agent].get('obs_meta', {}).get('action_names', [])
                        print(f"  - æœ€ç»ˆé€‰æ‹©åŠ¨ä½œ: {action} ({anames[action] if action < len(anames) else 'æœªçŸ¥'})")

                actions[agent] = action
                # 10201530 ä¿®å¤ï¼šç»Ÿè®¡å¹¶è¡ŒåŠ¨ä½œï¼ˆæŒ‰è®¾å¤‡ç»´åº¦ï¼‰
                if isinstance(action, (list, np.ndarray)):
                    action_list = list(action)
                else:
                    action_list = [int(action)]
                # ç»Ÿä¸€é•¿åº¦
                if len(action_list) < heads_map[agent]:
                    action_list += [0] * (heads_map[agent] - len(action_list))
                for k in range(heads_map[agent]):
                    action_stats[agent][k][int(action_list[k])] += 1
        
        # æ‰§è¡ŒåŠ¨ä½œ
        obs, rewards, terminations, truncations, info = env.step(actions)
        step_count += 1
        
        # KPIå¿«ç…§
        if step_count > 0 and snapshot_interval > 0 and step_count % snapshot_interval == 0:
            print(f"\n--- ğŸ“ˆ KPI å¿«ç…§ (ç¬¬ {step_count} æ­¥) ---")
            current_stats = env.sim.get_final_stats()
            print(f"   å®Œæˆé›¶ä»¶: {current_stats.get('total_parts', 0)}")
            print(f"   åœ¨åˆ¶å“(WIP): {len(env.sim.active_parts)}")
            print(f"   ç´¯è®¡å»¶æœŸ: {current_stats.get('total_tardiness', 0):.1f}")
            print(f"   å½“å‰åˆ©ç”¨ç‡: {current_stats.get('mean_utilization', 0):.1%}")
            print("-" * 35)

        # æ£€æŸ¥æ˜¯å¦ç»“æŸ
        if any(terminations.values()) or any(truncations.values()):
            print(f"ğŸ ç¯å¢ƒåœ¨ç¬¬{step_count}æ­¥ç»“æŸ")
            break
    
    # åˆ†æåŠ¨ä½œç»Ÿè®¡
    print(f"\nğŸ“Š åŠ¨ä½œç»Ÿè®¡åˆ†æ (æ€»å…±{step_count}æ­¥):")
    print("-" * 60)
    
    # 10201530 ä¿®å¤ï¼šæŒ‰è®¾å¤‡ç»´åº¦è¾“å‡ºç»Ÿè®¡
    for agent in env.agents:
        print(f"{agent}:")
        for k, counter in enumerate(action_stats[agent]):
            total = sum(counter.values())
            print(f"  è®¾å¤‡#{k}:")
            for action, count in sorted(counter.items()):
                pct = (count / total) * 100 if total > 0 else 0
                action_names = info[agent].get('obs_meta', {}).get('action_names', [])
                action_name = action_names[action] if action < len(action_names) else f"æœªçŸ¥åŠ¨ä½œ{action}"
                print(f"    - åŠ¨ä½œ{action} ({action_name}): {count}æ¬¡ ({pct:.1f}%)")
        print()
    
    # è·å–æœ€ç»ˆç»Ÿè®¡
    final_stats = env.sim.get_final_stats()
    print(f"ğŸ“ˆ æœ€ç»ˆKPI:")
    print(f"   å®Œæˆé›¶ä»¶: {final_stats['total_parts']}")
    print(f"   æ€»å·¥æœŸ: {final_stats['makespan']:.1f}")
    print(f"   å»¶æœŸæ—¶é—´: {final_stats['total_tardiness']:.1f}")
    print(f"   è®¾å¤‡åˆ©ç”¨ç‡: {final_stats['mean_utilization']:.1%}")
    
    env.close()

def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶è¿è¡Œè°ƒè¯•è„šæœ¬"""
    parser = argparse.ArgumentParser(
        description="è°ƒè¯•å’Œåˆ†æMARLæ¨¡å‹çš„è¡Œä¸ºï¼Œæ£€æŸ¥å…¶åœ¨ä¸åŒé…ç½®ä¸‹çš„åŠ¨ä½œæ¨¡å¼å’Œæ€§èƒ½ã€‚",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "--model_path",
        type=str,
        required=True,
        help="æŒ‡å‘å·²è®­ç»ƒå¥½çš„MARL actoræ¨¡å‹æ–‡ä»¶ (.keras) çš„è·¯å¾„"
    )
    parser.add_argument(
        "--config",
        type=str,
        default="all",
        choices=["static", "gen1", "gen2", "gen3", "all"],
        help="è¦è¿è¡Œçš„æµ‹è¯•é…ç½®åç§°ã€‚'all'ä¼šè¿è¡Œæ‰€æœ‰å¯ç”¨çš„é…ç½®ã€‚"
    )
    parser.add_argument(
        "--max_steps",
        type=int,
        default=600,
        help="æ¯ä¸ªç¯å¢ƒå›åˆçš„æœ€å¤§ä»¿çœŸæ­¥æ•°ã€‚"
    )
    parser.add_argument(
        "--deterministic",
        action="store_true",
        help="å¦‚æœè®¾ç½®æ­¤æ ‡å¿—ï¼Œå°†ä½¿ç”¨ç¡®å®šæ€§ç­–ç•¥ï¼ˆæ€»æ˜¯é€‰æ‹©æœ€ä¼˜åŠ¨ä½œï¼‰ã€‚å¦åˆ™ï¼Œä½¿ç”¨ä¸è¯„ä¼°è„šæœ¬ä¸€è‡´çš„éšæœºç­–ç•¥ï¼ˆ80%æœ€ä¼˜ï¼Œ20%é‡‡æ ·ï¼‰ã€‚"
    )
    parser.add_argument(
        "--snapshot_interval",
        type=int,
        default=100,
        help="æ¯éš”å¤šå°‘æ­¥æ‰“å°ä¸€æ¬¡KPIå¿«ç…§ã€‚è®¾ç½®ä¸º0åˆ™ç¦ç”¨ã€‚"
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§ã€‚"
    )
    args = parser.parse_args()

    # ç»Ÿä¸€è®¾ç½®éšæœºç§å­
    print(f"ğŸŒ± ä½¿ç”¨éšæœºç§å­: {args.seed}")
    random.seed(args.seed)
    np.random.seed(args.seed)
    tf.random.set_seed(args.seed)

    # é…ç½®åç§°åˆ°å¯¹è±¡çš„æ˜ å°„
    config_map = {
        "static": ("åŸºå‡†é…ç½®", STATIC_EVAL_CONFIG),
        "gen1": ("æ³›åŒ–æµ‹è¯•1-é«˜å‹åŠ›çŸ­äº¤æœŸ", GENERALIZATION_CONFIG_1),
        "gen2": ("æ³›åŒ–æµ‹è¯•2-æ··åˆä¼˜å…ˆçº§", GENERALIZATION_CONFIG_2),
        "gen3": ("æ³›åŒ–æµ‹è¯•3-å¤§æ‰¹é‡é•¿å‘¨æœŸ", GENERALIZATION_CONFIG_3),
    }

    if args.config == "all":
        configs_to_run = list(config_map.values())
    else:
        configs_to_run = [config_map[args.config]]

    print("=" * 80)
    print("ğŸ”¬ MARLæ¨¡å‹è¡Œä¸ºåˆ†æ")
    print(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"ç­–ç•¥æ¨¡å¼: {'ç¡®å®šæ€§ (Greedy)' if args.deterministic else 'éšæœº (ä¸evaluation.pyå¯¹é½)'}")
    print(f"æœ€å¤§æ­¥æ•°: {args.max_steps}")
    print("=" * 80)

    for name, config in configs_to_run:
        print(f"\n{'='*20} å¼€å§‹æµ‹è¯•: {name} {'='*20}")
        debug_marl_actions(
            model_path=args.model_path,
            config=config,
            max_steps=args.max_steps,
            deterministic=args.deterministic,
            snapshot_interval=args.snapshot_interval,
            seed=args.seed
        )
        print()

if __name__ == "__main__":
    main()
