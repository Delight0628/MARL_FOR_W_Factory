import os
import sys

# å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶è°ƒè¯•è„šæœ¬åœ¨CPUä¸Šè¿è¡Œï¼Œé¿å…ä¸è®­ç»ƒè¿›ç¨‹äº‰å¤ºGPUèµ„æº
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # å±è”½TensorFlowçš„INFOçº§åˆ«æ—¥å¿—

import numpy as np
import tensorflow as tf
from collections import Counter
import argparse
import random # ç»Ÿä¸€éšæœºç§å­

# æ·»åŠ ç¯å¢ƒè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

from environments.w_factory_env import WFactoryEnv
from evaluation import (
    STATIC_EVAL_CONFIG, 
    GENERALIZATION_CONFIG_1, GENERALIZATION_CONFIG_2, GENERALIZATION_CONFIG_3
)
# å¯¼å…¥é…ç½®ä»¥è§£ç è§‚æµ‹å‘é‡å’ŒåŠ¨ä½œ
from environments.w_factory_config import (
    WORKSTATIONS,
    PRODUCT_ROUTES,
    ENHANCED_OBS_CONFIG,
    ACTION_CONFIG_ENHANCED,
    RANDOM_SEED
)


def decode_observation(obs_vector: np.ndarray, agent_id: str) -> str:
    """å°†æ‰å¹³çš„è§‚æµ‹å‘é‡è§£ç ä¸ºäººç±»å¯è¯»çš„æ ¼å¼"""
    if obs_vector is None or obs_vector.size == 0:
        return "  - è§‚æµ‹å‘é‡ä¸ºç©º"

    decoded_lines = ["[Observation Vector]"]
    
    # ä»é…ç½®ä¸­è·å–ç»´åº¦ä¿¡æ¯
    station_types = list(WORKSTATIONS.keys())
    product_types = list(PRODUCT_ROUTES.keys())
    num_stations = len(station_types)
    obs_slot_size = ENHANCED_OBS_CONFIG["obs_slot_size"]
    workpiece_feature_count = 10  # V3ç‰ˆå·¥ä»¶ç‰¹å¾æ•°é‡ä¸º10

    current_idx = 0
    try:
        # --- 1. Agent Features ---
        decoded_lines.append("  --- 1. æ™ºèƒ½ä½“è‡ªèº«ç‰¹å¾ ---")
        
        # Agent ID (one-hot)
        agent_id_one_hot = obs_vector[current_idx : current_idx + num_stations]
        station_idx = np.argmax(agent_id_one_hot)
        decoded_lines.append(f"    - æ™ºèƒ½ä½“èº«ä»½: {station_types[station_idx]} (one-hot)")
        current_idx += num_stations

        # Capacity
        capacity = obs_vector[current_idx] * 5.0
        decoded_lines.append(f"    - å·¥ä½œç«™å®¹é‡: {capacity:.1f}")
        current_idx += 1
        
        # Status
        busy_ratio = obs_vector[current_idx]
        is_failed = obs_vector[current_idx + 1] > 0.5
        decoded_lines.append(f"    - è®¾å¤‡çŠ¶æ€: [ç¹å¿™ç‡: {busy_ratio:.1%}, æ˜¯å¦æ•…éšœ: {'æ˜¯' if is_failed else 'å¦'}]")
        current_idx += 2
        
        # --- 2. Global Features ---
        decoded_lines.append("  --- 2. å…¨å±€å®è§‚ç‰¹å¾ ---")
        time_prog = obs_vector[current_idx]
        wip_ratio = obs_vector[current_idx + 1]
        decoded_lines.append(f"    - å…¨å±€ä¿¡æ¯: [æ—¶é—´è¿›åº¦: {time_prog:.1%}, WIPç‡: {wip_ratio:.1%}]")
        current_idx += 2
        
        # --- 3. Workpiece Features ---
        decoded_lines.append("  --- 3. é˜Ÿåˆ—ä¸­å·¥ä»¶çš„è¯¦ç»†ç‰¹å¾ ---")
        for i in range(obs_slot_size):
            part_vec = obs_vector[current_idx : current_idx + workpiece_feature_count]
            exists = part_vec[0]

            if exists > 0.5:
                # Unpack all 10 features from V3 state space
                (exists, norm_slack, norm_rem_ops, norm_rem_time, 
                 norm_op_dur, is_late, downstream_cong, priority, 
                 is_final, prod_type_enc) = part_vec
                
                # Decode product type
                prod_idx = int(round(prod_type_enc * len(product_types))) - 1
                product_name = product_types[prod_idx] if 0 <= prod_idx < len(product_types) else "æœªçŸ¥"
                
                # Un-normalize values for readability
                time_slack = norm_slack * ENHANCED_OBS_CONFIG["time_slack_norm"]
                
                decoded_lines.append(
                    f"    æ§½ä½ {i+1} ({product_name}):\n"
                    f"      - çŠ¶æ€: [æ¾å¼›æ—¶é—´: {time_slack:.1f}, å°†å»¶æœŸ: {'æ˜¯' if is_late > 0.5 else 'å¦'}, æœ€ç»ˆå·¥åº: {'æ˜¯' if is_final > 0.5 else 'å¦'}]\n"
                    f"      - å±æ€§: [ä¼˜å…ˆçº§: {priority*5.0:.1f}, ä¸‹æ¸¸æ‹¥å µ: {downstream_cong:.1%}]"
                )
            else:
                decoded_lines.append(f"    æ§½ä½ {i+1}: (ç©º)")
            
            current_idx += workpiece_feature_count

    except IndexError:
        decoded_lines.append("  - (!! è§‚æµ‹å‘é‡ç»´åº¦ä¸åŒ¹é…ï¼Œéƒ¨åˆ†ä¿¡æ¯æ— æ³•è§£æ !!)")
    except Exception as e:
        decoded_lines.append(f"  - (!! è§£ææ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e} !!)")

    return "\n".join(decoded_lines)

def debug_marl_actions(model_path: str, config: dict, max_steps: int = 600, deterministic: bool = False, snapshot_interval: int = 100, seed: int = 42):
    """
    è°ƒè¯•MARLæ¨¡å‹çš„åŠ¨ä½œè¾“å‡ºæ¨¡å¼ã€‚
    
    æ–°å¢åŠŸèƒ½:
    - å¯é€‰æ‹©ç¡®å®šæ€§ç­–ç•¥æˆ–ä¸evaluation.pyå¯¹é½çš„éšæœºç­–ç•¥ã€‚
    - æ›´å…·ä½“çš„æ¨¡å‹åŠ è½½å¼‚å¸¸å¤„ç†ã€‚
    - å¯è§†åŒ–æ™ºèƒ½ä½“è§‚æµ‹å‘é‡(è§†é‡)ã€‚
    - å®šæœŸè¾“å‡ºKPIå¿«ç…§ã€‚
    - ç»Ÿä¸€éšæœºç§å­ã€‚
    """
    print(f"ğŸ” å¼€å§‹è°ƒè¯•MARLæ¨¡å‹è¡Œä¸º")
    print(f"ğŸ“‹ é…ç½®: {config.get('stage_name', 'æœªçŸ¥')}")
    print(f"ğŸ•¹ï¸  ç­–ç•¥: {'ç¡®å®šæ€§ (Greedy)' if deterministic else 'éšæœº (ä¸evaluation.pyå¯¹é½)'}")
    print(f"ğŸŒ± éšæœºç§å­: {seed}")
    
    # åŠ è½½æ¨¡å‹
    try:
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨äºè·¯å¾„: {model_path}")
        actor_model = tf.keras.models.load_model(model_path)
        print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_path}")
    except FileNotFoundError as e:
        print(f"âŒ {e}")
        return
    except (IOError, tf.errors.OpError) as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥ï¼Œæ–‡ä»¶å¯èƒ½å·²æŸåæˆ–æ ¼å¼ä¸æ­£ç¡®: {e}")
        return
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return

    # åˆ›å»ºç¯å¢ƒ
    env = WFactoryEnv(config=config)
    obs, info = env.reset(seed=seed)
    
    print(f"ğŸ­ ç¯å¢ƒä¿¡æ¯:")
    print(f"   æ™ºèƒ½ä½“æ•°é‡: {len(env.agents)}")
    print(f"   æ™ºèƒ½ä½“åˆ—è¡¨: {env.agents}")
    
    # è®°å½•åŠ¨ä½œç»Ÿè®¡
    action_stats = {agent: Counter() for agent in env.agents}
    step_count = 0
    
    print(f"\nğŸ¯ å¼€å§‹è®°å½•å‰{max_steps}æ­¥çš„åŠ¨ä½œæ¨¡å¼...")
    
    while step_count < max_steps:
        # MARLç­–ç•¥
        actions = {}
        for agent in env.agents:
            if agent in obs:
                state = tf.expand_dims(obs[agent], 0)
                action_probs = actor_model(state, training=False)
                
                # æ˜¾ç¤ºå‰å‡ æ­¥çš„è¯¦ç»†ä¿¡æ¯
                if step_count < 5:
                    print(f"\n--- æ­¥éª¤ {step_count+1}: {agent} ---")
                    # è§£ç å¹¶æ‰“å°è§‚æµ‹å‘é‡
                    decoded_obs_str = decode_observation(obs[agent], agent)
                    print(decoded_obs_str)
                    # æ‰“å°åŠ¨ä½œæ¦‚ç‡
                    print(f"[Action Probs]")
                    prob_str = ", ".join([f"{ACTION_CONFIG_ENHANCED['action_names'][i]}: {p:.2%}" for i, p in enumerate(action_probs[0].numpy())])
                    print(f"  - {prob_str}")

                if deterministic:
                    # ç¡®å®šæ€§ç­–ç•¥ï¼šæ€»æ˜¯é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„åŠ¨ä½œ
                    action = int(tf.argmax(action_probs[0]))
                else:
                    # éšæœºç­–ç•¥ï¼š80%æ¦‚ç‡é€‰æœ€ä¼˜ï¼Œ20%æ ¹æ®æ¦‚ç‡åˆ†å¸ƒé‡‡æ · (ä¸evaluation.pyå¯¹é½)
                    if np.random.random() < 0.2:
                        action = tf.random.categorical(tf.math.log(action_probs + 1e-8), 1)[0, 0].numpy()
                    else:
                        action = int(tf.argmax(action_probs[0]))

                actions[agent] = action
                action_stats[agent][action] += 1
        
        # æ‰§è¡ŒåŠ¨ä½œ
        obs, rewards, terminations, truncations, info = env.step(actions)
        step_count += 1
        
        # KPIå¿«ç…§
        if step_count > 0 and snapshot_interval > 0 and step_count % snapshot_interval == 0:
            print(f"\n--- ğŸ“ˆ KPI å¿«ç…§ (ç¬¬ {step_count} æ­¥) ---")
            current_stats = env.sim.get_final_stats()
            print(f"   å®Œæˆé›¶ä»¶: {current_stats.get('total_parts', 0)}")
            print(f"   åœ¨åˆ¶å“(WIP): {len(env.sim.active_parts)}")
            print(f"   ç´¯è®¡å»¶æœŸ: {current_stats.get('total_tardiness', 0):.1f}")
            print(f"   å½“å‰åˆ©ç”¨ç‡: {current_stats.get('mean_utilization', 0):.1%}")
            print("-" * 35)

        # æ£€æŸ¥æ˜¯å¦ç»“æŸ
        if any(terminations.values()) or any(truncations.values()):
            print(f"ğŸ ç¯å¢ƒåœ¨ç¬¬{step_count}æ­¥ç»“æŸ")
            break
    
    # åˆ†æåŠ¨ä½œç»Ÿè®¡
    print(f"\nğŸ“Š åŠ¨ä½œç»Ÿè®¡åˆ†æ (æ€»å…±{step_count}æ­¥):")
    print("-" * 60)
    
    for agent in env.agents:
        print(f"{agent}:")
        total_actions = sum(action_stats[agent].values())
        for action, count in sorted(action_stats[agent].items()):
            percentage = (count / total_actions) * 100 if total_actions > 0 else 0
            # ä½¿ç”¨é…ç½®ä¸­çš„åŠ¨ä½œåç§°
            action_name = ACTION_CONFIG_ENHANCED["action_names"][action] if action < len(ACTION_CONFIG_ENHANCED["action_names"]) else f"æœªçŸ¥åŠ¨ä½œ{action}"
            print(f"   åŠ¨ä½œ{action} ({action_name}): {count}æ¬¡ ({percentage:.1f}%)")
        print()
    
    # è·å–æœ€ç»ˆç»Ÿè®¡
    final_stats = env.sim.get_final_stats()
    print(f"ğŸ“ˆ æœ€ç»ˆKPI:")
    print(f"   å®Œæˆé›¶ä»¶: {final_stats['total_parts']}")
    print(f"   æ€»å·¥æœŸ: {final_stats['makespan']:.1f}")
    print(f"   å»¶æœŸæ—¶é—´: {final_stats['total_tardiness']:.1f}")
    print(f"   è®¾å¤‡åˆ©ç”¨ç‡: {final_stats['mean_utilization']:.1%}")
    
    env.close()

def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶è¿è¡Œè°ƒè¯•è„šæœ¬"""
    parser = argparse.ArgumentParser(
        description="è°ƒè¯•å’Œåˆ†æMARLæ¨¡å‹çš„è¡Œä¸ºï¼Œæ£€æŸ¥å…¶åœ¨ä¸åŒé…ç½®ä¸‹çš„åŠ¨ä½œæ¨¡å¼å’Œæ€§èƒ½ã€‚",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "--model_path",
        type=str,
        required=True,
        help="æŒ‡å‘å·²è®­ç»ƒå¥½çš„MARL actoræ¨¡å‹æ–‡ä»¶ (.keras) çš„è·¯å¾„"
    )
    parser.add_argument(
        "--config",
        type=str,
        default="all",
        choices=["static", "gen1", "gen2", "gen3", "all"],
        help="è¦è¿è¡Œçš„æµ‹è¯•é…ç½®åç§°ã€‚'all'ä¼šè¿è¡Œæ‰€æœ‰å¯ç”¨çš„é…ç½®ã€‚"
    )
    parser.add_argument(
        "--max_steps",
        type=int,
        default=600,
        help="æ¯ä¸ªç¯å¢ƒå›åˆçš„æœ€å¤§ä»¿çœŸæ­¥æ•°ã€‚"
    )
    parser.add_argument(
        "--deterministic",
        action="store_true",
        help="å¦‚æœè®¾ç½®æ­¤æ ‡å¿—ï¼Œå°†ä½¿ç”¨ç¡®å®šæ€§ç­–ç•¥ï¼ˆæ€»æ˜¯é€‰æ‹©æœ€ä¼˜åŠ¨ä½œï¼‰ã€‚å¦åˆ™ï¼Œä½¿ç”¨ä¸è¯„ä¼°è„šæœ¬ä¸€è‡´çš„éšæœºç­–ç•¥ï¼ˆ80%æœ€ä¼˜ï¼Œ20%é‡‡æ ·ï¼‰ã€‚"
    )
    parser.add_argument(
        "--snapshot_interval",
        type=int,
        default=100,
        help="æ¯éš”å¤šå°‘æ­¥æ‰“å°ä¸€æ¬¡KPIå¿«ç…§ã€‚è®¾ç½®ä¸º0åˆ™ç¦ç”¨ã€‚"
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=RANDOM_SEED,
        help="è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§ã€‚"
    )
    args = parser.parse_args()

    # ç»Ÿä¸€è®¾ç½®éšæœºç§å­
    print(f"ğŸŒ± ä½¿ç”¨éšæœºç§å­: {args.seed}")
    random.seed(args.seed)
    np.random.seed(args.seed)
    tf.random.set_seed(args.seed)

    # é…ç½®åç§°åˆ°å¯¹è±¡çš„æ˜ å°„
    config_map = {
        "static": ("åŸºå‡†é…ç½®", STATIC_EVAL_CONFIG),
        "gen1": ("æ³›åŒ–æµ‹è¯•1-é«˜å‹åŠ›çŸ­äº¤æœŸ", GENERALIZATION_CONFIG_1),
        "gen2": ("æ³›åŒ–æµ‹è¯•2-æ··åˆä¼˜å…ˆçº§", GENERALIZATION_CONFIG_2),
        "gen3": ("æ³›åŒ–æµ‹è¯•3-å¤§æ‰¹é‡é•¿å‘¨æœŸ", GENERALIZATION_CONFIG_3),
    }

    if args.config == "all":
        configs_to_run = list(config_map.values())
    else:
        configs_to_run = [config_map[args.config]]

    print("=" * 80)
    print("ğŸ”¬ MARLæ¨¡å‹è¡Œä¸ºåˆ†æ")
    print(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"ç­–ç•¥æ¨¡å¼: {'ç¡®å®šæ€§ (Greedy)' if args.deterministic else 'éšæœº (ä¸evaluation.pyå¯¹é½)'}")
    print(f"æœ€å¤§æ­¥æ•°: {args.max_steps}")
    print("=" * 80)

    for name, config in configs_to_run:
        print(f"\n{'='*20} å¼€å§‹æµ‹è¯•: {name} {'='*20}")
        debug_marl_actions(
            model_path=args.model_path,
            config=config,
            max_steps=args.max_steps,
            deterministic=args.deterministic,
            snapshot_interval=args.snapshot_interval,
            seed=args.seed
        )
        print()

if __name__ == "__main__":
    main()
