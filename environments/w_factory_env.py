"""
Wå·¥å‚ç”Ÿäº§è°ƒåº¦ç³»ç»Ÿ - ä»¿çœŸç¯å¢ƒæ ¸å¿ƒ
åŒ…å«SimPyä»¿çœŸé€»è¾‘å’ŒPettingZooå¤šæ™ºèƒ½ä½“ç¯å¢ƒæ¥å£
"""

import simpy
import numpy as np
import random
from typing import Dict, List, Tuple, Any, Optional
from collections import defaultdict, deque
import gymnasium as gym
from pettingzoo import ParallelEnv
from pettingzoo.utils import parallel_to_aec, wrappers

# Ray RLlib imports
try:
    from ray.rllib.env.multi_agent_env import MultiAgentEnv
    RAY_AVAILABLE = True
except ImportError:
    # å¦‚æœRayä¸å¯ç”¨ï¼Œåˆ›å»ºä¸€ä¸ªè™šæ‹ŸåŸºç±»
    class MultiAgentEnv:
        pass
    RAY_AVAILABLE = False

from .w_factory_config import *

# =============================================================================
# 1. æ•°æ®ç»“æ„å®šä¹‰ (Data Structures)
# =============================================================================

class Part:
    """é›¶ä»¶ç±» - è¡¨ç¤ºç”Ÿäº§ä¸­çš„ä¸€ä¸ªé›¶ä»¶"""
    def __init__(self, part_id: int, product_type: str, order_id: int, 
                 due_date: float, priority: int):
        self.part_id = part_id
        self.product_type = product_type
        self.order_id = order_id
        self.due_date = due_date
        self.priority = priority
        self.current_step = 0
        self.start_time = 0
        self.completion_time = None
        self.processing_history = []
        
    def get_current_station(self) -> Optional[str]:
        """è·å–å½“å‰éœ€è¦åŠ å·¥çš„å·¥ä½œç«™"""
        route = get_route_for_product(self.product_type)
        if self.current_step < len(route):
            return route[self.current_step]["station"]
        return None
    
    def get_processing_time(self) -> float:
        """è·å–å½“å‰å·¥åºçš„åŠ å·¥æ—¶é—´"""
        route = get_route_for_product(self.product_type)
        if self.current_step < len(route):
            return route[self.current_step]["time"]
        return 0
    
    def is_completed(self) -> bool:
        """æ£€æŸ¥é›¶ä»¶æ˜¯å¦å®Œæˆæ‰€æœ‰å·¥åº"""
        route = get_route_for_product(self.product_type)
        return self.current_step >= len(route)

class Order:
    """è®¢å•ç±»"""
    def __init__(self, order_id: int, product: str, quantity: int, 
                 priority: int, due_date: float, arrival_time: float = 0):
        self.order_id = order_id
        self.product = product
        self.quantity = quantity
        self.priority = priority
        self.due_date = due_date
        self.arrival_time = arrival_time
        self.parts = []
        self.completed_parts = 0
        
    def create_parts(self) -> List[Part]:
        """ä¸ºè®¢å•åˆ›å»ºé›¶ä»¶"""
        self.parts = []
        for i in range(self.quantity):
            part_id = self.order_id * 1000 + i
            part = Part(part_id, self.product, self.order_id, 
                       self.due_date, self.priority)
            part.start_time = self.arrival_time
            self.parts.append(part)
        return self.parts

# =============================================================================
# 2. SimPyä»¿çœŸæ ¸å¿ƒ (SimPy Simulation Core)
# =============================================================================

class WFactorySim:
    """Wå·¥å‚ä»¿çœŸæ ¸å¿ƒç±» - åŸºäºSimPyçš„ç¦»æ•£äº‹ä»¶ä»¿çœŸ"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        
        # è°ƒè¯•çº§åˆ«æ§åˆ¶
        self.debug_level = self.config.get('debug_level', 'INFO')  # DEBUG, INFO, WARNING, ERROR
        
        # ä»¿çœŸç¯å¢ƒ
        self.env = simpy.Environment()
        self.current_time = 0
        self.simulation_ended = False
        
        # è®¾å¤‡å’Œé˜Ÿåˆ—
        self.resources = {}
        self.queues = {}
        self.equipment_status = {}
        
        # è®¢å•å’Œé›¶ä»¶ç®¡ç†
        self.orders = []
        self.active_parts = []
        self.completed_parts = []
        self.part_counter = 0
        
        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            'makespan': 0,
            'total_tardiness': 0,
            'max_tardiness': 0,
            'equipment_utilization': {},
            'queue_lengths': defaultdict(list),
            'completed_orders': 0,
            'total_parts': 0
        }
        
        # æ™ºèƒ½ä½“å†³ç­–æ¥å£
        self.agent_decisions = {}
        self.pending_decisions = set()
        
        self._initialize_resources()
        self._initialize_orders()
    
    def _initialize_resources(self):
        """åˆå§‹åŒ–è®¾å¤‡èµ„æºå’Œé˜Ÿåˆ—"""
        for station_name, station_config in WORKSTATIONS.items():
            # åˆ›å»ºSimPyèµ„æºï¼ˆè®¾å¤‡ï¼‰
            capacity = station_config["count"]
            self.resources[station_name] = simpy.Resource(self.env, capacity=capacity)
            
            # åˆ›å»ºè¾“å…¥é˜Ÿåˆ—
            self.queues[station_name] = simpy.Store(self.env, capacity=QUEUE_CAPACITY)
            
            # åˆå§‹åŒ–è®¾å¤‡çŠ¶æ€
            self.equipment_status[station_name] = {
                'busy_count': 0,
                'total_busy_time': 0,
                'last_status_change': 0,
                'is_failed': False,
                'failure_end_time': 0
            }
            
            # å¯åŠ¨è®¾å¤‡å¤„ç†è¿›ç¨‹
            self.env.process(self._equipment_process(station_name))
    
    def _initialize_orders(self):
        """åˆå§‹åŒ–è®¢å•"""
        for i, order_data in enumerate(BASE_ORDERS):
            order = Order(
                order_id=i,
                product=order_data["product"],
                quantity=order_data["quantity"],
                priority=order_data["priority"],
                due_date=order_data["due_date"],
                arrival_time=0
            )
            self.orders.append(order)
            
            # åˆ›å»ºé›¶ä»¶å¹¶æ·»åŠ åˆ°ä»¿çœŸä¸­
            parts = order.create_parts()
            for part in parts:
                self.env.process(self._part_process(part))
                self.active_parts.append(part)
    
    def _part_process(self, part: Part):
        """é›¶ä»¶çš„ç”Ÿäº§æµç¨‹è¿›ç¨‹ - ç®€åŒ–ç‰ˆæœ¬"""
        # å°†é›¶ä»¶æ”¾å…¥ç¬¬ä¸€ä¸ªå·¥ä½œç«™çš„é˜Ÿåˆ—
        first_station = part.get_current_station()
        if first_station:
            yield self.queues[first_station].put(part)
    

    
    def _equipment_process(self, station_name: str):
        """è®¾å¤‡å¤„ç†è¿›ç¨‹ - å¤„ç†è®¾å¤‡æ•…éšœç­‰äº‹ä»¶"""
        while True:
            if EQUIPMENT_FAILURE["enabled"]:
                # éšæœºè®¾å¤‡æ•…éšœ
                failure_interval = np.random.exponential(
                    EQUIPMENT_FAILURE["mtbf_hours"] * 60
                )
                yield self.env.timeout(failure_interval)
                
                if random.random() < EQUIPMENT_FAILURE["failure_probability"]:
                    # è®¾å¤‡æ•…éšœ
                    self.equipment_status[station_name]['is_failed'] = True
                    repair_time = np.random.exponential(
                        EQUIPMENT_FAILURE["mttr_minutes"]
                    )
                    self.equipment_status[station_name]['failure_end_time'] = (
                        self.env.now + repair_time
                    )
                    
                    yield self.env.timeout(repair_time)
                    self.equipment_status[station_name]['is_failed'] = False
            else:
                # é™æ€è®­ç»ƒæ¨¡å¼ï¼šè®¾å¤‡ä¸ä¼šæ•…éšœï¼Œåªéœ€è¦ç­‰å¾…ä»¿çœŸç»“æŸ
                yield self.env.timeout(SIMULATION_TIME)  # ç­‰å¾…ä»¿çœŸç»“æŸ
    
    def _update_equipment_status(self, station_name: str, busy: bool):
        """æ›´æ–°è®¾å¤‡çŠ¶æ€"""
        status = self.equipment_status[station_name]
        current_time = self.env.now
        
        if busy:
            status['busy_count'] += 1
        else:
            status['busy_count'] = max(0, status['busy_count'] - 1)
            # ç´¯è®¡å¿™ç¢Œæ—¶é—´
            if status['busy_count'] == 0:
                status['total_busy_time'] += (
                    current_time - status['last_status_change']
                )
        
        status['last_status_change'] = current_time
    
    def _update_completion_stats(self, part: Part):
        """æ›´æ–°å®Œæˆç»Ÿè®¡"""
        # è®¡ç®—å»¶æœŸ
        tardiness = max(0, part.completion_time - part.due_date)
        self.stats['total_tardiness'] += tardiness
        self.stats['max_tardiness'] = max(self.stats['max_tardiness'], tardiness)
        
        # æ›´æ–°makespan
        self.stats['makespan'] = max(self.stats['makespan'], part.completion_time)
        
        self.stats['total_parts'] += 1
    
    def get_state_for_agent(self, agent_id: str) -> np.ndarray:
        """è·å–æ™ºèƒ½ä½“çš„è§‚æµ‹çŠ¶æ€"""
        station_name = agent_id.replace("agent_", "")
        
        # é˜Ÿåˆ—é•¿åº¦ï¼ˆå½’ä¸€åŒ–ï¼‰
        queue_length = len(self.queues[station_name].items)
        normalized_queue_length = min(queue_length / QUEUE_CAPACITY, 1.0)
        
        # è®¾å¤‡çŠ¶æ€ï¼ˆ0=ç©ºé—²ï¼Œ1=å¿™ç¢Œï¼‰
        equipment_busy = float(self.equipment_status[station_name]['busy_count'] > 0)
        
        return np.array([normalized_queue_length, equipment_busy], dtype=np.float32)
    
    def step_with_actions(self, actions: Dict[str, int]) -> Dict[str, float]:
        """æ‰§è¡Œä¸€æ­¥ä»¿çœŸï¼Œä¼ å…¥æ™ºèƒ½ä½“åŠ¨ä½œ"""
        # è®°å½•æ‰§è¡Œå‰çŠ¶æ€
        prev_completed = len(self.completed_parts)
        prev_total_steps = sum(part.current_step for part in self.active_parts)
        
        # æ‰§è¡Œæ™ºèƒ½ä½“åŠ¨ä½œ
        actions_executed = 0
        for agent_id, action in actions.items():
            station_name = agent_id.replace("agent_", "")
            
            if action == 1 and len(self.queues[station_name].items) > 0:
                # å¤„ç†é˜Ÿåˆ—ä¸­çš„ç¬¬ä¸€ä¸ªé›¶ä»¶
                self._process_part_at_station(station_name)
                actions_executed += 1
        
        # æ¨è¿›ä»¿çœŸ - å‡å°‘æ­¥é•¿ä»¥è·å¾—æ›´ç²¾ç»†çš„æ§åˆ¶
        try:
            self.env.run(until=self.env.now + 1)  # æ¯æ­¥æ¨è¿›1åˆ†é’Ÿè€Œä¸æ˜¯5åˆ†é’Ÿ
        except simpy.core.EmptySchedule:
            self.simulation_ended = True
        
        self.current_time = self.env.now
        
        # è®¡ç®—å¥–åŠ±
        rewards = self.get_rewards()
        
        # è°ƒè¯•ä¿¡æ¯
        new_completed = len(self.completed_parts)
        new_total_steps = sum(part.current_step for part in self.active_parts)
        
        if self.debug_level == 'DEBUG' and (new_completed > prev_completed or new_total_steps > prev_total_steps):
            print(f"ğŸ¯ è¿›åº¦æ›´æ–°: å®Œæˆé›¶ä»¶ {prev_completed}->{new_completed}, æ€»å·¥åº {prev_total_steps}->{new_total_steps}")
            print(f"   æ‰§è¡ŒåŠ¨ä½œæ•°: {actions_executed}, å¥–åŠ±: {list(rewards.values())}")
        
        return rewards
    
    def _process_part_at_station(self, station_name: str):
        """åœ¨æŒ‡å®šå·¥ä½œç«™å¤„ç†é›¶ä»¶"""
        if len(self.queues[station_name].items) == 0:
            return
            
        # è·å–é˜Ÿåˆ—ä¸­çš„ç¬¬ä¸€ä¸ªé›¶ä»¶
        part = self.queues[station_name].items[0]
        
        # æ£€æŸ¥è®¾å¤‡æ˜¯å¦å¯ç”¨
        if self.equipment_status[station_name]['busy_count'] < WORKSTATIONS[station_name]['count']:
            # ä»é˜Ÿåˆ—ä¸­ç§»é™¤é›¶ä»¶
            self.queues[station_name].items.remove(part)
            
            # å¯åŠ¨å¤„ç†è¿›ç¨‹
            self.env.process(self._execute_processing(station_name, part))
    
    def _execute_processing(self, station_name: str, part: Part):
        """æ‰§è¡Œé›¶ä»¶åŠ å·¥"""
        # è¯·æ±‚è®¾å¤‡èµ„æº
        with self.resources[station_name].request() as request:
            yield request
            
            # æ›´æ–°è®¾å¤‡çŠ¶æ€
            self._update_equipment_status(station_name, busy=True)
            
            # æ‰§è¡ŒåŠ å·¥
            processing_time = part.get_processing_time()
            yield self.env.timeout(processing_time)
            
            # æ›´æ–°è®¾å¤‡çŠ¶æ€
            self._update_equipment_status(station_name, busy=False)
            
            # é›¶ä»¶å®Œæˆå½“å‰å·¥åº
            part.current_step += 1
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆæ‰€æœ‰å·¥åº
            if part.is_completed():
                part.completion_time = self.env.now
                self.completed_parts.append(part)
                # ğŸ”§ å…³é”®ä¿®å¤ï¼šä»æ´»è·ƒé›¶ä»¶åˆ—è¡¨ä¸­ç§»é™¤å®Œæˆçš„é›¶ä»¶
                if part in self.active_parts:
                    self.active_parts.remove(part)
                self._update_completion_stats(part)
            else:
                # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªå·¥ä½œç«™
                next_station = part.get_current_station()
                if next_station:
                    yield self.queues[next_station].put(part)
    
    def get_rewards(self) -> Dict[str, float]:
        """è®¡ç®—å¥–åŠ± - ğŸ”§ ä¿®å¤ç‰ˆï¼šç§»é™¤è¿‡åº¦å¤æ‚çš„æ—¶é—´å‹åŠ›æœºåˆ¶"""
        rewards = {}
        
        # ğŸ”§ V4ä¿®å¤ï¼šå¤§å¹…æå‡åŸºç¡€å¥–åŠ±ï¼Œç¡®ä¿æ­£å¥–åŠ±åŸºç¡€
        base_reward = REWARD_CONFIG["base_reward"]  # ä»0.01æå‡åˆ°0.5
        
        # å®Œæˆå¥–åŠ±
        new_completions = len(self.completed_parts) - self.stats.get('last_completed_count', 0)
        completion_reward = 0
        if new_completions > 0:
            completion_reward = new_completions * REWARD_CONFIG["completion_reward"]
            self.stats['last_completed_count'] = len(self.completed_parts)
            
            # ğŸ”§ æ–°å¢ï¼šæå‰å®Œæˆå¥–åŠ±
            if self.current_time < SIMULATION_TIME * 0.8:  # åœ¨80%æ—¶é—´å†…å®Œæˆ
                completion_reward += REWARD_CONFIG["early_completion_bonus"]
        
        # ğŸ”§ å¢å¼ºå·¥åºå®Œæˆå¥–åŠ± - ä½¿ç”¨æ–°çš„é…ç½®å€¼
        current_total_steps = sum(part.current_step for part in self.active_parts)
        last_total_steps = self.stats.get('last_total_steps', 0)
        step_progress = current_total_steps - last_total_steps
        step_reward = 0
        if step_progress > 0:
            step_reward = step_progress * REWARD_CONFIG["step_reward"]  # ğŸ”§ ä½¿ç”¨é…ç½®ä¸­çš„3.0
            self.stats['last_total_steps'] = current_total_steps
        
        # ğŸ”§ æ–°å¢ï¼šæ•ˆç‡å¥–åŠ± - åŸºäºè®¾å¤‡åˆ©ç”¨ç‡
        efficiency_reward = 0
        total_utilization = 0
        for station_name, status in self.equipment_status.items():
            if status['busy_count'] > 0:
                utilization = min(status['busy_count'] / WORKSTATIONS[station_name]['count'], 1.0)
                total_utilization += utilization
        
        if len(WORKSTATIONS) > 0:
            avg_utilization = total_utilization / len(WORKSTATIONS)
            if avg_utilization > 0.6:  # é«˜åˆ©ç”¨ç‡å¥–åŠ±
                efficiency_reward = avg_utilization * REWARD_CONFIG["efficiency_bonus"]
        
        # ğŸ”§ V4å…³é”®ä¿®å¤ï¼šå»¶æœŸæƒ©ç½šé€»è¾‘é‡æ„
        tardiness_penalty = 0
        if self.stats['max_tardiness'] > 0:
            # åªæœ‰å½“å»¶æœŸè¶…è¿‡é˜ˆå€¼æ—¶æ‰æƒ©ç½šï¼Œä¸”ä¸å½±å“æ‰€æœ‰æ™ºèƒ½ä½“
            if REWARD_CONFIG.get("tardiness_penalty_per_agent", True):
                # æ—§é€»è¾‘ï¼šå½±å“æ‰€æœ‰æ™ºèƒ½ä½“
                tardiness_penalty = REWARD_CONFIG["tardiness_penalty"] * min(self.stats['max_tardiness'] / 60, 2.0)
            else:
                # ğŸ”§ æ–°é€»è¾‘ï¼šå»¶æœŸæƒ©ç½šåªå½±å“ç›¸å…³å·¥ä½œç«™ï¼Œä¸”å¤§å¹…å‡å°‘
                tardiness_penalty = REWARD_CONFIG["tardiness_penalty"] * REWARD_CONFIG["penalty_scale_factor"]
        
        # ğŸ”§ V4å…³é”®ä¿®å¤ï¼šç©ºé—²æƒ©ç½šé¢‘ç‡æ§åˆ¶
        # åˆå§‹åŒ–ç©ºé—²è®¡æ•°å™¨
        if not hasattr(self, 'idle_counters'):
            self.idle_counters = {station: 0 for station in WORKSTATIONS.keys()}
        
        # ğŸ”§ æ™ºèƒ½å¥–åŠ±åˆ†é…æœºåˆ¶ - V4å¹³è¡¡ç‰ˆ
        for station_name in WORKSTATIONS.keys():
            agent_id = f"agent_{station_name}"
            agent_reward = base_reward  # ğŸ”§ æ‰€æœ‰æ™ºèƒ½ä½“éƒ½æœ‰å¤§å¹…æå‡çš„åŸºç¡€å¥–åŠ±
            
            # æ£€æŸ¥å·¥ä½œç«™æ˜¯å¦æ´»è·ƒ
            is_active = (len(self.queues[station_name].items) > 0 or 
                        self.equipment_status[station_name]['busy_count'] > 0)
            
            if is_active:
                # é‡ç½®ç©ºé—²è®¡æ•°å™¨
                self.idle_counters[station_name] = 0
                
                # å·¥åºå¥–åŠ±ï¼šåªç»™æœ‰æ´»åŠ¨çš„å·¥ä½œç«™
                if step_reward > 0:
                    agent_reward += step_reward / len(WORKSTATIONS)  # å¹³å‡åˆ†é…å·¥åºå¥–åŠ±
                
                # ğŸ”§ æ•ˆç‡å¥–åŠ±ï¼šç»™æ´»è·ƒçš„å·¥ä½œç«™
                if efficiency_reward > 0:
                    station_utilization = min(self.equipment_status[station_name]['busy_count'] / WORKSTATIONS[station_name]['count'], 1.0)
                    agent_reward += efficiency_reward * station_utilization
            else:
                # ğŸ”§ V4ä¿®å¤ï¼šç©ºé—²æƒ©ç½šé¢‘ç‡æ§åˆ¶
                self.idle_counters[station_name] += 1
                
                # åªæœ‰è¿ç»­ç©ºé—²è¶…è¿‡é˜ˆå€¼æ‰å¼€å§‹æƒ©ç½š
                if self.idle_counters[station_name] > REWARD_CONFIG["idle_penalty_threshold"]:
                    # åº”ç”¨æƒ©ç½šç¼©æ”¾å› å­ï¼Œå¤§å¹…å‡å°‘æƒ©ç½š
                    scaled_idle_penalty = REWARD_CONFIG["idle_penalty"] * REWARD_CONFIG["penalty_scale_factor"]
                    agent_reward += scaled_idle_penalty
            
            # ğŸ”§ å®Œæˆå¥–åŠ±ï¼šåªç»™æœ€åå®Œæˆå·¥åºçš„å·¥ä½œç«™ (åŒ…è£…å°)
            if completion_reward > 0 and station_name == "åŒ…è£…å°":
                agent_reward += completion_reward  # åªæœ‰åŒ…è£…å°è·å¾—å®Œæˆå¥–åŠ±
            
            # ğŸ”§ V4ä¿®å¤ï¼šå»¶æœŸæƒ©ç½šä¸å†å½±å“æ‰€æœ‰æ™ºèƒ½ä½“
            if not REWARD_CONFIG.get("tardiness_penalty_per_agent", True):
                # æ–°é€»è¾‘ï¼šå»¶æœŸæƒ©ç½šåªå½±å“åŒ…è£…å°ï¼ˆæœ€ç»ˆè´Ÿè´£äº¤ä»˜çš„å·¥ä½œç«™ï¼‰
                if station_name == "åŒ…è£…å°" and tardiness_penalty != 0:
                    agent_reward += tardiness_penalty
            else:
                # æ—§é€»è¾‘ï¼šæ‰€æœ‰æ™ºèƒ½ä½“å…±åŒæ‰¿æ‹…ï¼ˆå·²å¤§å¹…å‡å°‘ï¼‰
                agent_reward += tardiness_penalty
            
            # ğŸ”§ åº”ç”¨æ•´ä½“å¥–åŠ±ç¼©æ”¾
            agent_reward *= REWARD_CONFIG["reward_scale_factor"]
            
            rewards[agent_id] = agent_reward
        
        # ğŸ”§ V4è°ƒè¯•ä¿¡æ¯ - æ˜¾ç¤ºå¹³è¡¡æ•ˆæœ
        if self.debug_level == 'DEBUG' and (new_completions > 0 or step_progress > 0 or efficiency_reward > 0):
            total_positive = base_reward * len(WORKSTATIONS) + completion_reward + step_reward + efficiency_reward
            total_negative = abs(tardiness_penalty * len(WORKSTATIONS)) + abs(REWARD_CONFIG["idle_penalty"] * REWARD_CONFIG["penalty_scale_factor"])
            print(f"ğŸ† V4å¹³è¡¡å¥–åŠ±è¯¦æƒ…:")
            print(f"   æ­£å¥–åŠ±: åŸºç¡€={base_reward:.2f}Ã—{len(WORKSTATIONS)}, å®Œæˆ={completion_reward:.1f}, å·¥åº={step_reward:.1f}, æ•ˆç‡={efficiency_reward:.1f}")
            print(f"   è´Ÿå¥–åŠ±: å»¶æœŸ={tardiness_penalty:.1f}, ç©ºé—²æƒ©ç½š={REWARD_CONFIG['idle_penalty'] * REWARD_CONFIG['penalty_scale_factor']:.3f}")
            print(f"   å¹³è¡¡æ¯”ä¾‹: æ­£å¥–åŠ±={total_positive:.1f} vs è´Ÿå¥–åŠ±={total_negative:.1f}")
            if completion_reward > 0:
                print(f"   ğŸ‰ å®Œæˆå¥–åŠ±åªç»™åŒ…è£…å°æ™ºèƒ½ä½“: {completion_reward:.1f}")
        
        # ğŸ”§ V5æ–°å¢ï¼šæ—¶é—´å‹åŠ›å¥–åŠ±æœºåˆ¶
        
        return rewards
    
    def is_done(self) -> bool:
        """æ£€æŸ¥ä»¿çœŸæ˜¯å¦ç»“æŸ - ä¼˜å…ˆä»»åŠ¡å®Œæˆï¼Œæ—¶é—´ä½œä¸ºå¤‡ç”¨æ¡ä»¶"""
        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆæ£€æŸ¥ä»»åŠ¡å®Œæˆï¼Œè€Œä¸æ˜¯æ—¶é—´è€—å°½
        
        # æ¡ä»¶1: æ‰€æœ‰è®¢å•å®Œæˆ (ä¸»è¦å®Œæˆæ¡ä»¶)
        total_required = sum(order.quantity for order in self.orders)
        if len(self.completed_parts) >= total_required:
            if not hasattr(self, '_completion_logged'):
                print(f"ğŸ‰ æ‰€æœ‰è®¢å•å®Œæˆ! å®Œæˆ{len(self.completed_parts)}/{total_required}ä¸ªé›¶ä»¶ï¼Œç”¨æ—¶{self.current_time:.1f}åˆ†é’Ÿ")
                self._completion_logged = True
            return True
        
        # æ¡ä»¶2: æ‰‹åŠ¨ç»“æŸä»¿çœŸ
        if self.simulation_ended:
            return True
        
        # æ¡ä»¶3: æ—¶é—´è€—å°½ (å¤‡ç”¨æ¡ä»¶ï¼Œå¢åŠ æ—¶é—´é™åˆ¶)
        # ğŸ”§ å¢åŠ æ—¶é—´é™åˆ¶ï¼Œç»™ä»»åŠ¡å®Œæˆæ›´å¤šæœºä¼š
        max_time = SIMULATION_TIME * 1.5  # å¢åŠ 50%æ—¶é—´ç¼“å†²
        if self.current_time >= max_time:
            if not hasattr(self, '_timeout_logged'):
                print(f"â° æ—¶é—´è€—å°½! å®Œæˆ{len(self.completed_parts)}/{total_required}ä¸ªé›¶ä»¶ï¼Œç”¨æ—¶{self.current_time:.1f}åˆ†é’Ÿ")
                self._timeout_logged = True
            return True
        
        return False
    
    def get_final_stats(self) -> Dict[str, Any]:
        """è·å–æœ€ç»ˆç»Ÿè®¡ç»“æœ"""
        # è®¡ç®—è®¾å¤‡åˆ©ç”¨ç‡
        for station_name, status in self.equipment_status.items():
            if self.current_time > 0:
                utilization = status['total_busy_time'] / self.current_time
                self.stats['equipment_utilization'][station_name] = utilization
        
        return self.stats

    def get_completion_stats(self) -> Dict[str, Any]:
        """è·å–å®Œæˆç»Ÿè®¡ä¿¡æ¯ - V5æ–°å¢"""
        total_required = sum(order.quantity for order in self.orders)
        completed_count = len(self.completed_parts)
        completion_rate = (completed_count / total_required) * 100 if total_required > 0 else 0
        
        # è®¾å¤‡åˆ©ç”¨ç‡ç»Ÿè®¡
        utilization_stats = {}
        for station_name, status in self.equipment_status.items():
            if self.current_time > 0:
                utilization = status['total_busy_time'] / self.current_time
                utilization_stats[station_name] = utilization
        
        # æŒ‰äº§å“ç±»å‹ç»Ÿè®¡å®Œæˆæƒ…å†µ
        product_completion = {}
        for order in self.orders:
            product_type = order.product
            if product_type not in product_completion:
                product_completion[product_type] = {'required': 0, 'completed': 0}
            product_completion[product_type]['required'] += order.quantity
        
        for part in self.completed_parts:
            product_type = part.product_type
            if product_type in product_completion:
                product_completion[product_type]['completed'] += 1
        
        # ğŸ”§ æ–°å¢ï¼šå»¶æœŸåˆ†æ (é¡¹ç›®æ ¸å¿ƒç›®æ ‡)
        tardiness_info = {
            'late_orders': 0,
            'max_tardiness': 0,
            'total_tardiness': 0,
            'on_time_orders': 0
        }
        
        # åˆ†æè®¢å•å»¶æœŸæƒ…å†µ
        for order in self.orders:
            order_completion_time = self.current_time  # å½“å‰æ—¶é—´ä½œä¸ºå®Œæˆæ—¶é—´
            if order_completion_time > order.due_date:
                tardiness = order_completion_time - order.due_date
                tardiness_info['late_orders'] += 1
                tardiness_info['total_tardiness'] += tardiness
                tardiness_info['max_tardiness'] = max(tardiness_info['max_tardiness'], tardiness)
            else:
                tardiness_info['on_time_orders'] += 1
        
        # è®¡ç®—å¹³å‡å»¶æœŸæ—¶é—´
        if tardiness_info['late_orders'] > 0:
            tardiness_info['avg_tardiness'] = tardiness_info['total_tardiness'] / tardiness_info['late_orders']
        else:
            tardiness_info['avg_tardiness'] = 0
        
        return {
            'total_required': total_required,
            'completed_count': completed_count,
            'completion_rate': completion_rate,
            'current_time': self.current_time,
            'utilization_stats': utilization_stats,
            'product_completion': product_completion,
            'is_naturally_done': self.is_done(),
            'tardiness_info': tardiness_info,  # ğŸ”§ æ–°å¢å»¶æœŸåˆ†æ
            'total_orders': len(self.orders),  # ğŸ”§ æ–°å¢è®¢å•æ€»æ•°
            'makespan': self.current_time  # ğŸ”§ æ–°å¢MakespanæŒ‡æ ‡
        }

# =============================================================================
# 3. PettingZooå¤šæ™ºèƒ½ä½“ç¯å¢ƒæ¥å£ (PettingZoo Multi-Agent Environment)
# =============================================================================

class WFactoryEnv(ParallelEnv):
    """Wå·¥å‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ - åŸºäºPettingZoo"""
    
    metadata = {
        "render_modes": ["human", "rgb_array"],
        "name": "w_factory_v1",
    }
    
    def __init__(self, config: Dict[str, Any] = None):
        super().__init__()
        self.config = config or {}
        
        # æ™ºèƒ½ä½“å®šä¹‰
        self.possible_agents = [f"agent_{station}" for station in WORKSTATIONS.keys()]
        self.agents = self.possible_agents[:]
        
        # åŠ¨ä½œå’Œè§‚æµ‹ç©ºé—´
        self.action_spaces = {
            agent: gym.spaces.Discrete(ACTION_CONFIG["action_space_size"])
            for agent in self.possible_agents
        }
        
        self.observation_spaces = {
            agent: gym.spaces.Box(
                low=0.0, high=1.0, shape=(2,), dtype=np.float32
            )
            for agent in self.possible_agents
        }
        
        # ä»¿çœŸç¯å¢ƒ
        self.sim = None
        self.episode_count = 0
        
    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):
        """é‡ç½®ç¯å¢ƒ"""
        if seed is not None:
            random.seed(seed)
            np.random.seed(seed)
        
        # åˆ›å»ºæ–°çš„ä»¿çœŸå®ä¾‹
        self.sim = WFactorySim(self.config)
        self.agents = self.possible_agents[:]
        self.episode_count += 1
        
        # è·å–åˆå§‹è§‚æµ‹
        observations = {
            agent: self.sim.get_state_for_agent(agent)
            for agent in self.agents
        }
        
        infos = {agent: {} for agent in self.agents}
        
        return observations, infos
    
    def step(self, actions: Dict[str, int]):
        """æ‰§è¡Œä¸€æ­¥"""
        if not self.sim:
            raise RuntimeError("Environment not initialized. Call reset() first.")
        
        # æ‰§è¡Œä»¿çœŸæ­¥éª¤
        rewards = self.sim.step_with_actions(actions)
        
        # è·å–æ–°çš„è§‚æµ‹
        observations = {
            agent: self.sim.get_state_for_agent(agent)
            for agent in self.agents
        }
        
        # æ£€æŸ¥æ˜¯å¦ç»“æŸ
        terminations = {agent: self.sim.is_done() for agent in self.agents}
        truncations = {agent: False for agent in self.agents}
        
        # ä¿¡æ¯
        infos = {agent: {} for agent in self.agents}
        if self.sim.is_done():
            final_stats = self.sim.get_final_stats()
            for agent in self.agents:
                infos[agent]["final_stats"] = final_stats
        
        return observations, rewards, terminations, truncations, infos
    
    def render(self, mode="human"):
        """æ¸²æŸ“ç¯å¢ƒï¼ˆå¯é€‰å®ç°ï¼‰"""
        if mode == "human":
            print(f"ä»¿çœŸæ—¶é—´: {self.sim.current_time:.1f}")
            print(f"å®Œæˆé›¶ä»¶æ•°: {len(self.sim.completed_parts)}")
            for station_name in WORKSTATIONS.keys():
                queue_len = len(self.sim.queues[station_name].items)
                busy_count = self.sim.equipment_status[station_name]['busy_count']
                print(f"{station_name}: é˜Ÿåˆ—={queue_len}, å¿™ç¢Œè®¾å¤‡={busy_count}")
    
    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        pass

# =============================================================================
# 4. ç¯å¢ƒå·¥å‚å‡½æ•° (Environment Factory Functions)
# =============================================================================

def make_env(config: Dict[str, Any] = None):
    """åˆ›å»ºWå·¥å‚ç¯å¢ƒå®ä¾‹"""
    env = WFactoryEnv(config)
    return env

class WFactoryGymEnv(MultiAgentEnv):
    """Wå·¥å‚ç¯å¢ƒçš„Ray RLlib MultiAgentEnvé€‚é…å™¨"""
    
    def __init__(self, config: Dict[str, Any] = None):
        super().__init__()
        self.config = config or {}
        
        # åˆ›å»ºPettingZooç¯å¢ƒ
        self.pz_env = WFactoryEnv(config)
        
        # Ray RLlib MultiAgentEnvå¿…éœ€å±æ€§
        self._agent_ids = set(self.pz_env.possible_agents)
        self._spaces_in_preferred_format = True
        
        # è®¾ç½®åŠ¨ä½œå’Œè§‚æµ‹ç©ºé—´
        self.action_spaces = self.pz_env.action_spaces
        self.observation_spaces = self.pz_env.observation_spaces
        
        # å…¼å®¹æ€§å±æ€§
        self.agents = self.pz_env.possible_agents
        self.possible_agents = self.pz_env.possible_agents
        self._num_agents = len(self.agents)
        
        # å•æ™ºèƒ½ä½“å…¼å®¹æ€§ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªæ™ºèƒ½ä½“çš„ç©ºé—´ï¼‰
        first_agent = self.pz_env.possible_agents[0]
        self.action_space = self.pz_env.action_spaces[first_agent]
        self.observation_space = self.pz_env.observation_spaces[first_agent]
        
    def reset(self, seed=None, options=None):
        """é‡ç½®ç¯å¢ƒ"""
        observations, infos = self.pz_env.reset(seed=seed, options=options)
        
        # ç¡®ä¿è¿”å›çš„è§‚æµ‹åŒ…å«æ‰€æœ‰æ´»è·ƒæ™ºèƒ½ä½“
        # Ray RLlibæœŸæœ›è§‚æµ‹å­—å…¸åŒ…å«æ‰€æœ‰æ™ºèƒ½ä½“
        for agent in self.possible_agents:
            if agent not in observations:
                # å¦‚æœæŸä¸ªæ™ºèƒ½ä½“ä¸åœ¨è§‚æµ‹ä¸­ï¼Œæ·»åŠ é»˜è®¤è§‚æµ‹
                observations[agent] = self.observation_spaces[agent].sample() * 0  # é›¶è§‚æµ‹
            if agent not in infos:
                infos[agent] = {}
        
        return observations, infos
    
    def step(self, action_dict):
        """æ‰§è¡Œä¸€æ­¥"""
        # Ray RLlibç›´æ¥ä¼ é€’æ™ºèƒ½ä½“åç§°ä½œä¸ºé”®çš„åŠ¨ä½œå­—å…¸
        # å¦‚æœä¼ å…¥çš„æ˜¯æ•°å­—ç´¢å¼•ï¼Œéœ€è¦è½¬æ¢
        if action_dict and isinstance(list(action_dict.keys())[0], int):
            # æ•°å­—ç´¢å¼•æ ¼å¼ï¼Œè½¬æ¢ä¸ºæ™ºèƒ½ä½“åç§°
            actions = {}
            for i, agent in enumerate(self.agents):
                if i in action_dict:
                    actions[agent] = action_dict[i]
                else:
                    actions[agent] = 0  # é»˜è®¤åŠ¨ä½œ
        else:
            # å·²ç»æ˜¯æ™ºèƒ½ä½“åç§°æ ¼å¼
            actions = action_dict
        
        # æ‰§è¡Œæ­¥éª¤
        observations, rewards, terminations, truncations, infos = self.pz_env.step(actions)
        
        # ç¡®ä¿æ‰€æœ‰æ™ºèƒ½ä½“éƒ½æœ‰å¯¹åº”çš„è¿”å›å€¼
        for agent in self.possible_agents:
            if agent not in observations:
                observations[agent] = self.observation_spaces[agent].sample() * 0
            if agent not in rewards:
                rewards[agent] = 0.0
            if agent not in terminations:
                terminations[agent] = False
            if agent not in truncations:
                truncations[agent] = False
            if agent not in infos:
                infos[agent] = {}
        
        # Ray RLlibéœ€è¦ç‰¹æ®Šçš„ç»ˆæ­¢çŠ¶æ€å¤„ç†
        # æ·»åŠ "__all__"é”®æ¥æŒ‡ç¤ºæ˜¯å¦æ‰€æœ‰æ™ºèƒ½ä½“éƒ½å®Œæˆ
        terminations["__all__"] = all(terminations.values()) if terminations else False
        truncations["__all__"] = all(truncations.values()) if truncations else False
        
        return observations, rewards, terminations, truncations, infos
    
    def render(self, mode="human"):
        """æ¸²æŸ“ç¯å¢ƒ"""
        return self.pz_env.render(mode)
    
    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        self.pz_env.close()
    
    # Ray RLlib 2.48.0 MultiAgentEnvå¿…éœ€æ–¹æ³•
    def get_agent_ids(self):
        """è·å–æ™ºèƒ½ä½“IDé›†åˆ"""
        return self._agent_ids
    
    def get_observation_space(self, agent_id: str = None):
        """è·å–è§‚æµ‹ç©ºé—´"""
        if agent_id is None:
            return self.observation_spaces
        return self.observation_spaces.get(agent_id)
    
    def get_action_space(self, agent_id: str = None):
        """è·å–åŠ¨ä½œç©ºé—´"""
        if agent_id is None:
            return self.action_spaces
        return self.action_spaces.get(agent_id)
    
    def observation_space_contains(self, x: dict):
        """æ£€æŸ¥è§‚æµ‹æ˜¯å¦åœ¨è§‚æµ‹ç©ºé—´å†…"""
        for agent_id, obs in x.items():
            if agent_id not in self.observation_spaces:
                return False
            if not self.observation_spaces[agent_id].contains(obs):
                return False
        return True
    
    def action_space_contains(self, x: dict):
        """æ£€æŸ¥åŠ¨ä½œæ˜¯å¦åœ¨åŠ¨ä½œç©ºé—´å†…"""
        for agent_id, action in x.items():
            if agent_id not in self.action_spaces:
                return False
            if not self.action_spaces[agent_id].contains(action):
                return False
        return True
    
    def action_space_sample(self, agent_ids: list = None):
        """ä»åŠ¨ä½œç©ºé—´é‡‡æ ·"""
        if agent_ids is None:
            agent_ids = list(self._agent_ids)
        return {
            agent_id: self.action_spaces[agent_id].sample()
            for agent_id in agent_ids
            if agent_id in self.action_spaces
        }
    
    def observation_space_sample(self, agent_ids: list = None):
        """ä»è§‚æµ‹ç©ºé—´é‡‡æ ·"""
        if agent_ids is None:
            agent_ids = list(self._agent_ids)
        return {
            agent_id: self.observation_spaces[agent_id].sample()
            for agent_id in agent_ids
            if agent_id in self.observation_spaces
        }
    
    @property
    def num_agents(self):
        """æ™ºèƒ½ä½“æ•°é‡å±æ€§ï¼ˆåªè¯»ï¼‰"""
        return self._num_agents
    
    @num_agents.setter
    def num_agents(self, value):
        """å…è®¸Ray RLlibè®¾ç½®num_agentså±æ€§"""
        self._num_agents = value

def make_parallel_env(config: Dict[str, Any] = None):
    """åˆ›å»ºå¹¶è¡Œç¯å¢ƒï¼ˆç”¨äºè®­ç»ƒï¼‰"""
    # æ£€æŸ¥æ˜¯å¦éœ€è¦Ray RLlibå…¼å®¹çš„ç¯å¢ƒ
    import inspect
    frame = inspect.currentframe()
    try:
        # æ£€æŸ¥è°ƒç”¨æ ˆä¸­æ˜¯å¦æœ‰Rayç›¸å…³çš„æ¨¡å—
        caller_frame = frame.f_back
        while caller_frame:
            caller_filename = caller_frame.f_code.co_filename
            if 'ray' in caller_filename.lower() or 'rllib' in caller_filename.lower():
                # Ray RLlibè°ƒç”¨ï¼Œè¿”å›Gymnasiumå…¼å®¹ç¯å¢ƒ
                return WFactoryGymEnv(config)
            caller_frame = caller_frame.f_back
        
        # éRayè°ƒç”¨ï¼Œè¿”å›åŸå§‹PettingZooç¯å¢ƒ
        return WFactoryEnv(config)
    finally:
        del frame

def make_parallel_env_for_ray(config: Dict[str, Any] = None):
    """ä¸“é—¨ä¸ºRay RLlibåˆ›å»ºç¯å¢ƒ"""
    return WFactoryGymEnv(config)

def make_parallel_env_pettingzoo(config: Dict[str, Any] = None):
    """åˆ›å»ºåŸå§‹PettingZooç¯å¢ƒ"""
    return WFactoryEnv(config)

def make_aec_env(config: Dict[str, Any] = None):
    """åˆ›å»ºAECç¯å¢ƒï¼ˆAgent-Environment-Cycleï¼‰"""
    env = make_env(config)
    env = parallel_to_aec(env)
    return env 