"""
WSL Ubuntuä¸“ç”¨çš„Ray RLlibå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ è®­ç»ƒè„šæœ¬
é’ˆå¯¹WSLç¯å¢ƒä¼˜åŒ–ï¼Œè§£å†³Windows Rayå…¼å®¹æ€§é—®é¢˜
"""

import os
import sys
import time
import json
import tempfile
import subprocess
from typing import Dict, Any
from pathlib import Path

# WSLç¯å¢ƒä¼˜åŒ–è®¾ç½®
os.environ['RAY_DISABLE_IMPORT_WARNING'] = '1'
os.environ['RAY_DEDUP_LOGS'] = '0'
os.environ['RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE'] = '1'
os.environ['RAY_DISABLE_PYARROW_TENSOR_EXTENSION'] = '1'
# ç¦ç”¨ä¸€äº›å¯èƒ½åœ¨WSLä¸­æœ‰é—®é¢˜çš„åŠŸèƒ½
os.environ['RAY_DISABLE_IMPORT_WARNING'] = '1'
os.environ['RAY_USAGE_STATS_ENABLED'] = '0'

print("ğŸ§ WSL Ubuntuç¯å¢ƒæ£€æµ‹...")

# æ£€æŸ¥æ˜¯å¦åœ¨WSLç¯å¢ƒä¸­
def check_wsl_environment():
    """æ£€æŸ¥WSLç¯å¢ƒ"""
    try:
        # æ£€æŸ¥/proc/versionæ–‡ä»¶
        with open('/proc/version', 'r') as f:
            version_info = f.read().lower()
            if 'microsoft' in version_info or 'wsl' in version_info:
                print("âœ… æ£€æµ‹åˆ°WSLç¯å¢ƒ")
                return True
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        if 'WSL_DISTRO_NAME' in os.environ:
            print("âœ… æ£€æµ‹åˆ°WSLç¯å¢ƒ (é€šè¿‡ç¯å¢ƒå˜é‡)")
            return True
            
        print("âš ï¸  æœªæ£€æµ‹åˆ°WSLç¯å¢ƒï¼Œä½†ç»§ç»­æ‰§è¡Œ...")
        return False
        
    except Exception as e:
        print(f"âš ï¸  WSLæ£€æµ‹å¤±è´¥: {e}")
        return False

# æ£€æŸ¥WSLç¯å¢ƒ
is_wsl = check_wsl_environment()

try:
    import ray
    from ray import tune
    from ray.rllib.algorithms.ppo import PPOConfig
    from ray.rllib.policy.policy import PolicySpec
    from ray.rllib.env import PettingZooEnv
    from ray.tune.registry import register_env
    import numpy as np
    import gymnasium as gym
    print("âœ… Rayåº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ Rayåº“å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·åœ¨WSLä¸­å®‰è£…Ray:")
    print("pip install ray[rllib] gymnasium pettingzoo")
    sys.exit(1)

# æ·»åŠ ç¯å¢ƒè·¯å¾„ - WSLè·¯å¾„å¤„ç†
current_dir = Path(__file__).parent.absolute()
parent_dir = current_dir.parent  # ä¸Šä¸€çº§ç›®å½•ï¼ŒåŒ…å«environments
sys.path.append(str(current_dir))
sys.path.append(str(parent_dir))

print(f"ğŸ” è„šæœ¬ç›®å½•: {current_dir}")
print(f"ğŸ” é¡¹ç›®æ ¹ç›®å½•: {parent_dir}")
print(f"ğŸ” æŸ¥æ‰¾environmentsç›®å½•: {parent_dir / 'environments'}")

try:
    from environments.w_factory_env import WFactoryGymEnv  # ä¿®å¤ï¼šå¯¼å…¥æ­£ç¡®çš„ç±»
    from environments.w_factory_config import *
    print("âœ… å·¥å‚ç¯å¢ƒå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å·¥å‚ç¯å¢ƒå¯¼å…¥å¤±è´¥: {e}")
    print(f"è¯·ç¡®ä¿environmentsç›®å½•å­˜åœ¨äº: {parent_dir}")
    print("ç›®å½•ç»“æ„åº”è¯¥æ˜¯:")
    print("  MARL_FOR_W_Factory/")
    print("  â”œâ”€â”€ environments/")
    print("  â”‚   â”œâ”€â”€ w_factory_env.py")
    print("  â”‚   â””â”€â”€ w_factory_config.py")
    print("  â””â”€â”€ wsl/")
    print("      â””â”€â”€ wsl_ray_marl_train.py")
    sys.exit(1)

def get_wsl_system_info():
    """è·å–WSLç³»ç»Ÿä¿¡æ¯"""
    info = {
        "platform": "WSL",
        "python_version": sys.version,
        "ray_version": ray.__version__,
    }
    
    try:
        # è·å–CPUä¿¡æ¯
        with open('/proc/cpuinfo', 'r') as f:
            cpu_info = f.read()
            cpu_count = cpu_info.count('processor')
            info["cpu_count"] = cpu_count
        
        # è·å–å†…å­˜ä¿¡æ¯
        with open('/proc/meminfo', 'r') as f:
            mem_info = f.read()
            for line in mem_info.split('\n'):
                if 'MemTotal' in line:
                    mem_total = int(line.split()[1]) // 1024  # Convert to MB
                    info["memory_mb"] = mem_total
                    break
        
        # è·å–WSLç‰ˆæœ¬
        if 'WSL_DISTRO_NAME' in os.environ:
            info["wsl_distro"] = os.environ['WSL_DISTRO_NAME']
            
    except Exception as e:
        print(f"âš ï¸  ç³»ç»Ÿä¿¡æ¯è·å–å¤±è´¥: {e}")
    
    return info

def env_creator(config):
    """ç¯å¢ƒåˆ›å»ºå‡½æ•°"""
    return WFactoryGymEnv(config)  # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„ç±»å

# æ³¨å†Œç¯å¢ƒ
register_env("w_factory", env_creator)

def get_wsl_ray_config():
    """è·å–WSLä¼˜åŒ–çš„Rayé…ç½®"""
    system_info = get_wsl_system_info()
    
    # æ ¹æ®ç³»ç»Ÿèµ„æºåŠ¨æ€è°ƒæ•´
    cpu_count = system_info.get("cpu_count", 4)
    memory_mb = system_info.get("memory_mb", 4096)
    
    # WSLç¯å¢ƒä¸‹çš„ä¿å®ˆé…ç½®
    num_cpus = min(cpu_count, 6)  # é™åˆ¶CPUä½¿ç”¨
    object_store_memory = min(memory_mb * 1024 * 1024 // 4, 500_000_000)  # 1/4å†…å­˜æˆ–500MB
    
    print(f"ğŸ”§ WSLç³»ç»Ÿé…ç½®:")
    print(f"   CPUæ ¸å¿ƒ: {cpu_count} (ä½¿ç”¨: {num_cpus})")
    print(f"   å†…å­˜: {memory_mb}MB (å¯¹è±¡å­˜å‚¨: {object_store_memory//1024//1024}MB)")
    
    # åˆ›å»ºWSLå‹å¥½çš„ä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp(prefix="ray_wsl_")
    
    return {
        "local_mode": False,
        "ignore_reinit_error": True,
        "include_dashboard": False,  # WSLä¸­ç¦ç”¨dashboard
        "_temp_dir": temp_dir,
        "object_store_memory": object_store_memory,
        "num_cpus": num_cpus,
        # WSLç‰¹å®šé…ç½®
        "log_to_driver": True,
        "configure_logging": True,
        "logging_level": "ERROR",
    }

def create_ray_config():
    """åˆ›å»ºRay RLlibé…ç½® - Ray 2.48.0å…¼å®¹ç‰ˆæœ¬"""
    config = (
        PPOConfig()
        .environment(
            env="w_factory",
            env_config={
                'debug_level': 'WARNING'  # å‡å°‘ç¯å¢ƒè¾“å‡º
            }
        )
        .framework("torch")
        .api_stack(
            # ç¦ç”¨æ–°APIæ ˆï¼Œä½¿ç”¨æ—§ç‰ˆæœ¬å…¼å®¹æ¨¡å¼
            enable_rl_module_and_learner=False,
            enable_env_runner_and_connector_v2=False,
        )
        .training(
            train_batch_size=2000,  # å¢åŠ æ‰¹æ¬¡å¤§å°ï¼Œæé«˜å®Œæˆepisodeçš„æ¦‚ç‡
            minibatch_size=128,
            num_epochs=5,
            lr=5e-4,
            gamma=0.99,
            lambda_=0.95,
            clip_param=0.2,
            vf_clip_param=10.0,
            entropy_coeff=0.01,
            vf_loss_coeff=0.5,
        )
        .env_runners(
            # Ray 2.48.0å¼ºåˆ¶ä½¿ç”¨env_runners
            num_env_runners=0,  # ä½¿ç”¨æœ¬åœ°æ¨¡å¼é¿å…åºåˆ—åŒ–é—®é¢˜
            rollout_fragment_length=200,  # å¢åŠ ç‰‡æ®µé•¿åº¦
        )
        .resources(
            num_gpus=0,
        )
        .multi_agent(
            policies={"shared_policy": PolicySpec()},
            policy_mapping_fn=lambda agent_id, *args, **kwargs: "shared_policy",
        )
        .evaluation(
            evaluation_interval=10,
            evaluation_duration=5,
        )
        .debugging(
            log_level="WARNING",  # å‡å°‘Rayæ—¥å¿—
        )
    )
    
    return config

def get_wsl_training_config():
    """è·å–WSLä¼˜åŒ–çš„è®­ç»ƒé…ç½®"""
    system_info = get_wsl_system_info()
    cpu_count = system_info.get("cpu_count", 4)
    
    # æ ¹æ®CPUæ•°é‡è°ƒæ•´workeræ•°é‡
    num_workers = max(1, min(cpu_count - 1, 4))  # ä¿ç•™1ä¸ªCPUç»™ä¸»è¿›ç¨‹
    
    config = (
        PPOConfig()
        .environment(
            env="w_factory",
            env_config={},
            disable_env_checking=True
        )
        .framework("torch") 
        .env_runners(
            # æœ¬åœ°æ¨¡å¼é…ç½® (é¿å…ç¯å¢ƒæ³¨å†Œé—®é¢˜)
            num_env_runners=0,  # æœ¬åœ°æ¨¡å¼ä¸ä½¿ç”¨è¿œç¨‹runner
            rollout_fragment_length=500,  # å¢åŠ rollouté•¿åº¦
            batch_mode="truncate_episodes",  # æ”¹ä¸ºæˆªæ–­æ¨¡å¼ï¼Œé¿å…ç­‰å¾…å®Œæ•´episode
        )
        .training(
            # PPOè®­ç»ƒå‚æ•° (Ray 2.48 API)
            train_batch_size=4000,  # å¢åŠ è®­ç»ƒæ‰¹æ¬¡å¤§å°
            lr=3e-4,
            gamma=0.99,
        )
        .multi_agent(
            # å¤šæ™ºèƒ½ä½“é…ç½® (æŒ‰ç…§main.pyæ¨¡å¼)
            policies={"shared_policy": PolicySpec()},
            policy_mapping_fn=(lambda agent_id, *args, **kwargs: "shared_policy"),
        )
        .resources(
            # WSLèµ„æºé…ç½® (Ray 2.48 API)
            num_gpus=0  # WSLé€šå¸¸ä¸æ”¯æŒGPUï¼Œç§»é™¤è¿‡æ—¶å‚æ•°
        )
        .evaluation(
            # è¯„ä¼°é…ç½® (ç®€åŒ–ç‰ˆæœ¬)
            evaluation_interval=25,
            evaluation_duration=10,
            evaluation_config={
                "explore": False,
                "render_env": False,
            }
        )
        .debugging(
            # WSLè°ƒè¯•é…ç½®
            log_level="INFO",  # WSLä¸­å¯ä»¥æ˜¾ç¤ºæ›´å¤šæ—¥å¿—
        )
        .experimental(
            # å®éªŒæ€§é…ç½®
            _disable_preprocessor_api=True,
        )
    )
    
    # è®¾ç½®PPOç‰¹å®šçš„è¶…å‚æ•° (Ray 2.48æ–¹å¼)
    config.lambda_ = 0.95
    config.clip_param = 0.2
    config.vf_loss_coeff = 0.5
    config.entropy_coeff = 0.01
    config.minibatch_size = 128  # Ray 2.48.0ä¸­çš„æ­£ç¡®å‚æ•°å
    config.num_sgd_iter = 10
    config.horizon = 1000  # å¢åŠ episodeé•¿åº¦ï¼Œç¡®ä¿é›¶ä»¶èƒ½å®Œæˆ
    
    print(f"ğŸ”§ è®­ç»ƒé…ç½®:")
    print(f"   æ¨¡å¼: æœ¬åœ°æ¨¡å¼ (é¿å…ç¯å¢ƒæ³¨å†Œé—®é¢˜)")
    print(f"   Env Runners: 0 (æœ¬åœ°æ¨¡å¼)")
    print(f"   è®­ç»ƒæ‰¹æ¬¡å¤§å°: 4000")
    print(f"   Episodeé•¿åº¦: 1000æ­¥")
    print(f"   Rollouté•¿åº¦: 500æ­¥")
    print(f"   SGDè¿­ä»£æ¬¡æ•°: 10")
    print(f"   SGDå°æ‰¹æ¬¡å¤§å°: 128")
    
    return config

def run_wsl_ray_training(num_iterations=20):
    """è¿è¡ŒWSL Ray RLlibè®­ç»ƒ"""
    print("ğŸš€ å¼€å§‹WSL Ray RLlibè®­ç»ƒ...")
    
    # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
    training_start_time = time.time()
    
    try:
        # åˆå§‹åŒ–Ray
        if not ray.is_initialized():
            ray.init(
                num_cpus=4,
                num_gpus=0,
                object_store_memory=1000000000,  # 1GB
                ignore_reinit_error=True,
                log_to_driver=False,  # å‡å°‘æ—¥å¿—è¾“å‡º
            )
        
        # æ³¨å†Œç¯å¢ƒ
        register_env("w_factory", lambda config: WFactoryGymEnv(config))
        
        # åˆ›å»ºé…ç½®
        config = create_ray_config()
        
        # åˆ›å»ºç®—æ³•
        algo = config.build()
        
        # åˆ›å»ºæ£€æŸ¥ç‚¹ç›®å½•
        checkpoint_dir = r"D:\MPU\æ¯•ä¸šè®ºæ–‡\MARL_FOR_W_Factory\wsl\ray_result"
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        # è®­ç»ƒå¾ªç¯
        print(f"ğŸ¯ å¼€å§‹è®­ç»ƒ {num_iterations} è½®...")
        print(f"â° è®­ç»ƒå¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(training_start_time))}")
        print("=" * 70)
        
        best_reward = float('-inf')
        best_checkpoint = None
        total_episodes_completed = 0
        iteration_times = []  # è®°å½•æ¯è½®è®­ç»ƒæ—¶é—´
        
        for i in range(num_iterations):
            iteration_start_time = time.time()
            
            print(f"\nğŸ“Š è®­ç»ƒè½®æ¬¡ {i+1}/{num_iterations}")
            print("-" * 50)
            
            result = algo.train()
            
            iteration_end_time = time.time()
            iteration_duration = iteration_end_time - iteration_start_time
            iteration_times.append(iteration_duration)
            
            # è·å–å…³é”®æŒ‡æ ‡ - Ray 2.48.0å…¼å®¹
            episode_reward_mean = result.get("episode_reward_mean", 0)
            episodes_this_iter = result.get("episodes_this_iter", 0)
            episode_len_mean = result.get("episode_len_mean", 0)
            
            # Ray 2.48.0ä¸­ç»Ÿè®¡æ•°æ®å¯èƒ½åœ¨env_runnersä¸­
            if episodes_this_iter == 0 and 'env_runners' in result:
                env_stats = result['env_runners']
                episode_reward_mean = env_stats.get("episode_reward_mean", episode_reward_mean)
                episodes_this_iter = env_stats.get("episodes_this_iter", episodes_this_iter)
                episode_len_mean = env_stats.get("episode_len_mean", episode_len_mean)
            
            total_episodes_completed += episodes_this_iter
            
            # æ˜¾ç¤ºè®­ç»ƒç»“æœ
            print(f"   å¹³å‡å¥–åŠ±: {episode_reward_mean:.2f}")
            print(f"   å®Œæˆepisodeæ•°: {episodes_this_iter}")
            print(f"   å¹³å‡episodeé•¿åº¦: {episode_len_mean:.1f}")
            print(f"   ç´¯è®¡å®Œæˆepisode: {total_episodes_completed}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ”¹è¿›
            if episode_reward_mean > best_reward:
                best_reward = episode_reward_mean
                print(f"   ğŸ‰ æ–°çš„æœ€ä½³å¥–åŠ±: {best_reward:.2f}")
                
                # ä¿å­˜æ£€æŸ¥ç‚¹ - åªæ˜¾ç¤ºç®€æ´ä¿¡æ¯
                best_checkpoint = algo.save(checkpoint_dir)
                if hasattr(best_checkpoint, 'path'):
                    checkpoint_path = best_checkpoint.path
                else:
                    # ä»å­—ç¬¦ä¸²ä¸­æå–è·¯å¾„
                    checkpoint_str = str(best_checkpoint)
                    if 'path=' in checkpoint_str:
                        path_start = checkpoint_str.find('path=') + 5
                        path_end = checkpoint_str.find(')', path_start)
                        if path_end == -1:
                            path_end = checkpoint_str.find(',', path_start)
                        checkpoint_path = checkpoint_str[path_start:path_end]
                    else:
                        checkpoint_path = "wsl_ray_results/checkpoints"
                
                print(f"   ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
            else:
                print(f"   ğŸ“Š å½“å‰å¥–åŠ±: {episode_reward_mean:.2f} (æœ€ä½³: {best_reward:.2f})")
            
            # æ˜¾ç¤ºå­¦ä¹ è¿›åº¦
            if "info" in result and "learner" in result["info"]:
                learner_info = result["info"]["learner"]["shared_policy"]
                if "learner_stats" in learner_info:
                    stats = learner_info["learner_stats"]
                    policy_loss = stats.get("policy_loss", 0)
                    vf_loss = stats.get("vf_loss", 0)
                    print(f"   ç­–ç•¥æŸå¤±: {policy_loss:.4f}, ä»·å€¼æŸå¤±: {vf_loss:.4f}")
            
            # æ—¶é—´ç»Ÿè®¡å’Œé¢„æµ‹
            elapsed_time = time.time() - training_start_time
            avg_iteration_time = sum(iteration_times) / len(iteration_times)
            remaining_iterations = num_iterations - (i + 1)
            estimated_remaining_time = remaining_iterations * avg_iteration_time
            
            print(f"   â±ï¸  æœ¬è½®ç”¨æ—¶: {iteration_duration:.1f}ç§’")
            print(f"   ğŸ“ˆ å¹³å‡æ¯è½®: {avg_iteration_time:.1f}ç§’")
            print(f"   â° å·²ç”¨æ—¶é—´: {elapsed_time/60:.1f}åˆ†é’Ÿ")
            
            if remaining_iterations > 0:
                print(f"   ğŸ”® é¢„è®¡å‰©ä½™: {estimated_remaining_time/60:.1f}åˆ†é’Ÿ")
                estimated_finish_time = time.time() + estimated_remaining_time
                finish_time_str = time.strftime('%H:%M:%S', time.localtime(estimated_finish_time))
                print(f"   ğŸ é¢„è®¡å®Œæˆ: {finish_time_str}")
            
            # å¦‚æœæ²¡æœ‰å®Œæˆä»»ä½•episodeï¼Œç»™å‡ºæç¤º
            if episodes_this_iter == 0:
                print("   â³ æœ¬è½®æœªå®Œæˆepisodeï¼Œç»§ç»­è®­ç»ƒ...")
        
        # è®­ç»ƒå®Œæˆç»Ÿè®¡
        training_end_time = time.time()
        total_training_time = training_end_time - training_start_time
        
        print("\n" + "=" * 70)
        print(f"ğŸ è®­ç»ƒå®Œæˆï¼")
        print(f"   æœ€ä½³å¹³å‡å¥–åŠ±: {best_reward:.2f}")
        print(f"   æ€»å®Œæˆepisodeæ•°: {total_episodes_completed}")
        print(f"   æ€»è®­ç»ƒæ—¶é—´: {total_training_time/60:.1f}åˆ†é’Ÿ ({total_training_time:.1f}ç§’)")
        print(f"   å¹³å‡æ¯è½®æ—¶é—´: {total_training_time/num_iterations:.1f}ç§’")
        print(f"   æœ€å¿«å•è½®: {min(iteration_times):.1f}ç§’")
        print(f"   æœ€æ…¢å•è½®: {max(iteration_times):.1f}ç§’")
        
        if total_episodes_completed == 0:
            print("âš ï¸  è­¦å‘Š: è®­ç»ƒæœŸé—´æ²¡æœ‰å®Œæˆä»»ä½•episode")
            print("ğŸ’¡ å»ºè®®: å¢åŠ è®­ç»ƒè½®æ¬¡æˆ–è°ƒæ•´ç¯å¢ƒå‚æ•°")
        
        # åˆ›å»ºæœ€ä½³ç»“æœå¯¹è±¡
        class BestResult:
            def __init__(self, reward, checkpoint, training_time, iteration_times):
                self.metrics = {
                    "episode_reward_mean": reward, 
                    "training_iteration": num_iterations,
                    "total_training_time": training_time,
                    "avg_iteration_time": sum(iteration_times) / len(iteration_times),
                    "total_episodes": total_episodes_completed
                }
                self.checkpoint = checkpoint
        
        # å¦‚æœæ²¡æœ‰ä¿å­˜è¿‡æ£€æŸ¥ç‚¹ï¼Œä¿å­˜æœ€åä¸€ä¸ª
        if best_checkpoint is None:
            best_checkpoint = algo.save(checkpoint_dir)
            print(f"ğŸ’¾ ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹: {best_checkpoint}")
        
        best_result = BestResult(best_reward, best_checkpoint, total_training_time, iteration_times)
        
        # æ¸…ç†
        algo.stop()
        
        return best_result
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None

def create_wsl_setup_script():
    """åˆ›å»ºWSLç¯å¢ƒè®¾ç½®è„šæœ¬"""
    setup_script = """#!/bin/bash
# WSL Ubuntuç¯å¢ƒè®¾ç½®è„šæœ¬

echo "ğŸ§ è®¾ç½®WSL Ubuntuç¯å¢ƒç”¨äºRay MARLè®­ç»ƒ"

# æ›´æ–°ç³»ç»Ÿ
echo "ğŸ“¦ æ›´æ–°ç³»ç»ŸåŒ…..."
sudo apt update && sudo apt upgrade -y

# å®‰è£…Pythonå’Œpip
echo "ğŸ å®‰è£…Pythonç¯å¢ƒ..."
sudo apt install -y python3 python3-pip python3-venv

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
echo "ğŸ”§ åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ..."
python3 -m venv marl_env
source marl_env/bin/activate

# å®‰è£…ä¾èµ–
echo "ğŸ“š å®‰è£…Pythonä¾èµ–..."
pip install --upgrade pip
pip install ray[rllib]
pip install gymnasium
pip install pettingzoo
pip install simpy
pip install numpy
pip install tensorflow

echo "âœ… WSLç¯å¢ƒè®¾ç½®å®Œæˆï¼"
echo "ä½¿ç”¨æ–¹æ³•:"
echo "1. æ¿€æ´»ç¯å¢ƒ: source marl_env/bin/activate"
echo "2. è¿è¡Œè®­ç»ƒ: python3 wsl_ray_marl_train.py"
"""
    
    setup_file = Path("setup_wsl_env.sh")
    with open(setup_file, 'w') as f:
        f.write(setup_script)
    
    # è®¾ç½®æ‰§è¡Œæƒé™
    os.chmod(setup_file, 0o755)
    
    print(f"ğŸ“„ WSLè®¾ç½®è„šæœ¬å·²åˆ›å»º: {setup_file}")
    return setup_file

def main():
    """ä¸»å‡½æ•°"""
    # è®°å½•è„šæœ¬å¼€å§‹æ—¶é—´
    script_start_time = time.time()
    script_start_datetime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(script_start_time))
    
    print("ğŸ§ Wå·¥å‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿ - WSLç‰ˆæœ¬")
    print("=" * 70)
    print(f"ğŸ• è„šæœ¬å¯åŠ¨æ—¶é—´: {script_start_datetime}")
    
    # æ£€æŸ¥WSLç¯å¢ƒ
    if not is_wsl:
        print("âš ï¸  å»ºè®®åœ¨WSLç¯å¢ƒä¸­è¿è¡Œæ­¤è„šæœ¬ä»¥è·å¾—æœ€ä½³æ€§èƒ½")
    
    # åˆ›å»ºè®¾ç½®è„šæœ¬
    setup_file = create_wsl_setup_script()
    
    try:
        # è¿è¡ŒRayè®­ç»ƒ
        ray_result = run_wsl_ray_training(num_iterations=10)  # å¢åŠ åˆ°10è½®ï¼Œæé«˜å®Œæˆepisodeæ¦‚ç‡
        
        # è®¡ç®—è„šæœ¬æ€»è¿è¡Œæ—¶é—´
        script_end_time = time.time()
        script_end_datetime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(script_end_time))
        total_script_time = script_end_time - script_start_time
        
        if ray_result:
            print("\nğŸ‰ WSL Ray RLlibè®­ç»ƒæˆåŠŸå®Œæˆï¼")
            
            # æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
            print(f"\nâ° æ—¶é—´ç»Ÿè®¡:")
            print(f"   è„šæœ¬å¼€å§‹: {script_start_datetime}")
            print(f"   è„šæœ¬ç»“æŸ: {script_end_datetime}")
            print(f"   è„šæœ¬æ€»è¿è¡Œæ—¶é—´: {total_script_time/60:.1f}åˆ†é’Ÿ ({total_script_time:.1f}ç§’)")
            
            # ä»è®­ç»ƒç»“æœä¸­è·å–çº¯è®­ç»ƒæ—¶é—´
            if hasattr(ray_result, 'metrics') and 'total_training_time' in ray_result.metrics:
                training_time = ray_result.metrics['total_training_time']
                setup_time = total_script_time - training_time
                print(f"   çº¯è®­ç»ƒæ—¶é—´: {training_time/60:.1f}åˆ†é’Ÿ ({training_time:.1f}ç§’)")
                print(f"   ç¯å¢ƒåˆå§‹åŒ–æ—¶é—´: {setup_time/60:.1f}åˆ†é’Ÿ ({setup_time:.1f}ç§’)")
                print(f"   è®­ç»ƒæ•ˆç‡: {training_time/total_script_time*100:.1f}%")
            
            # æ˜¾ç¤ºåç»­æ­¥éª¤
            print("\nğŸ“‹ åç»­æ­¥éª¤:")
            print("1. æŸ¥çœ‹è®­ç»ƒç»“æœ: ls D:\\MPU\\æ¯•ä¸šè®ºæ–‡\\MARL_FOR_W_Factory\\wsl\\ray_result\\")
            print("2. åŠ è½½æ¨¡å‹è¿›è¡Œæ¨ç†")
            print("3. å¯è§†åŒ–è®­ç»ƒæ›²çº¿")
            
        else:
            print("\nâŒ WSL Rayè®­ç»ƒå¤±è´¥")
            print(f"ğŸ’¡ è¯·å…ˆè¿è¡Œè®¾ç½®è„šæœ¬: bash {setup_file}")
            print(f"â° è„šæœ¬è¿è¡Œæ—¶é—´: {total_script_time/60:.1f}åˆ†é’Ÿ")
            
    except Exception as e:
        script_end_time = time.time()
        total_script_time = script_end_time - script_start_time
        print(f"âŒ ä¸»ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print(f"â° è„šæœ¬è¿è¡Œæ—¶é—´: {total_script_time/60:.1f}åˆ†é’Ÿ")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 